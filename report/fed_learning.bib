@misc{14NeuralNetworks2021,
  title = {6.14 - {{Neural Networks}} - {{Output Layer}} - {{Activation Functions}}},
  year = {2021},
  month = nov,
  journal = {Carraig AI Machine Learning},
  urldate = {2024-04-08},
  abstract = {In this post we're going to have a more detailed look at the output layer. We'll be discussing the appropriate activation functions to use for both regression and classification problems, including binary classification, multi-class classification and multi-label classification. We'll also discuss the appropriate loss function to use for each problem type.}
}

@book{1611Convnet,
  title = {16.11 {{Convnet Models Pretrained}} on {{ImageNet}}},
  urldate = {2024-04-15},
  abstract = {16.11 Convnet Models Pretrained on ImageNet With deep learning, rather than starting fresh on every project with costly training, validating and testing, you can use pretrained deep neural...},
  isbn = {978-0-13-540479-9}
}

@book{1ProjectManagement,
  title = {1. {{Project Management Overview}}},
  urldate = {2024-10-26},
  abstract = {1 Project Management Overview In this Chapter Clarify what project management is and ``is not'' (it's likely more than you think) Learn why projects are challenging to manage Understand why...},
  isbn = {978-0-13-764691-3},
  langid = {english},
  file = {/home/james/Zotero/storage/MZ7ZL2HX/ch01.html}
}

@book{6LeaderDrivenTheories,
  title = {6 {{Leader}}-{{Driven Theories}}},
  urldate = {2024-10-28},
  abstract = {6Leader-Driven Theories    ``People who go about seeking to change the world, to diminish suffering, to demonstrate any kind of enlightenment, are often as flawed as anybody else. Sometimes...},
  isbn = {978-1-394-15210-0},
  langid = {english},
  file = {/home/james/Zotero/storage/UBS9B7HB/c06.html}
}

@article{abhishekMultisampleDocumentclass12ptminimalUsepackageamsmath2024,
  title = {Multi-Sample {\textbackslash}documentclass[12pt]\{minimal\} 				{\textbackslash}usepackage\{amsmath\} 				{\textbackslash}usepackage\{wasysym\}  				{\textbackslash}usepackage\{amsfonts\}  				{\textbackslash}usepackage\{amssymb\}  				{\textbackslash}usepackage\{amsbsy\} 				{\textbackslash}usepackage\{mathrsfs\} 				{\textbackslash}usepackage\{upgreek\} 				{\textbackslash}setlength\{{\textbackslash}oddsidemargin\}\{-69pt\} 				{\textbackslash}begin\{document\}\$\${\textbackslash}zeta \$\${\textbackslash}end\{document\}{$\zeta$}-Mixup: Richer, More Realistic Synthetic Samples from a p-Series Interpolant},
  shorttitle = {Multi-Sample {\textbackslash}documentclass[12pt]\{minimal\} 				{\textbackslash}usepackage\{amsmath\} 				{\textbackslash}usepackage\{wasysym\}  				{\textbackslash}usepackage\{amsfonts\}  				{\textbackslash}usepackage\{amssymb\}  				{\textbackslash}usepackage\{amsbsy\} 				{\textbackslash}usepackage\{mathrsfs\} 				{\textbackslash}usepackage\{upgreek\} 				{\textbackslash}setlength\{{\textbackslash}oddsidemargin\}\{-69pt\} 				{\textbackslash}begin\{document\}\$\${\textbackslash}zeta \$\${\textbackslash}end\{document\}{$\zeta$}-Mixup},
  author = {Abhishek, Kumar and Brown, Colin J. and Hamarneh, Ghassan},
  year = {2024},
  journal = {Journal of Big Data},
  volume = {11},
  number = {1},
  pages = {43},
  issn = {2196-1115},
  doi = {10.1186/s40537-024-00898-6},
  urldate = {2024-09-30},
  abstract = {Modern deep learning training procedures rely on model regularization techniques such as data augmentation methods, which generate training samples that increase the diversity of data and richness of label information. A popular recent method, mixup, uses convex combinations of pairs of original samples to generate new samples. However, as we show in our experiments, mixup ~can produce undesirable synthetic samples, where the data is sampled off the manifold and can contain incorrect labels. We propose {\textbackslash}documentclass[12pt]\{minimal\} 				{\textbackslash}usepackage\{amsmath\} 				{\textbackslash}usepackage\{wasysym\}  				{\textbackslash}usepackage\{amsfonts\}  				{\textbackslash}usepackage\{amssymb\}  				{\textbackslash}usepackage\{amsbsy\} 				{\textbackslash}usepackage\{mathrsfs\} 				{\textbackslash}usepackage\{upgreek\} 				{\textbackslash}setlength\{{\textbackslash}oddsidemargin\}\{-69pt\} 				{\textbackslash}begin\{document\}\$\${\textbackslash}zeta \$\${\textbackslash}end\{document\}{$\zeta$}-mixup, a generalization of mixup ~with provably and demonstrably desirable properties that allows convex combinations of {\textbackslash}documentclass[12pt]\{minimal\} 				{\textbackslash}usepackage\{amsmath\} 				{\textbackslash}usepackage\{wasysym\}  				{\textbackslash}usepackage\{amsfonts\}  				{\textbackslash}usepackage\{amssymb\}  				{\textbackslash}usepackage\{amsbsy\} 				{\textbackslash}usepackage\{mathrsfs\} 				{\textbackslash}usepackage\{upgreek\} 				{\textbackslash}setlength\{{\textbackslash}oddsidemargin\}\{-69pt\} 				{\textbackslash}begin\{document\}\$\$\{T\} {\textbackslash}ge 2\$\${\textbackslash}end\{document\}T{$\geq$}2 samples, leading to more realistic and diverse outputs that incorporate information from {\textbackslash}documentclass[12pt]\{minimal\} 				{\textbackslash}usepackage\{amsmath\} 				{\textbackslash}usepackage\{wasysym\}  				{\textbackslash}usepackage\{amsfonts\}  				{\textbackslash}usepackage\{amssymb\}  				{\textbackslash}usepackage\{amsbsy\} 				{\textbackslash}usepackage\{mathrsfs\} 				{\textbackslash}usepackage\{upgreek\} 				{\textbackslash}setlength\{{\textbackslash}oddsidemargin\}\{-69pt\} 				{\textbackslash}begin\{document\}\$\$\{T\}\$\${\textbackslash}end\{document\}T original samples by using a p-series interpolant. We show that, compared to mixup, {\textbackslash}documentclass[12pt]\{minimal\} 				{\textbackslash}usepackage\{amsmath\} 				{\textbackslash}usepackage\{wasysym\}  				{\textbackslash}usepackage\{amsfonts\}  				{\textbackslash}usepackage\{amssymb\}  				{\textbackslash}usepackage\{amsbsy\} 				{\textbackslash}usepackage\{mathrsfs\} 				{\textbackslash}usepackage\{upgreek\} 				{\textbackslash}setlength\{{\textbackslash}oddsidemargin\}\{-69pt\} 				{\textbackslash}begin\{document\}\$\${\textbackslash}zeta \$\${\textbackslash}end\{document\}{$\zeta$}-mixup ~better preserves the intrinsic dimensionality of the original datasets, which is a desirable property for training generalizable models. Furthermore, we show that our implementation of {\textbackslash}documentclass[12pt]\{minimal\} 				{\textbackslash}usepackage\{amsmath\} 				{\textbackslash}usepackage\{wasysym\}  				{\textbackslash}usepackage\{amsfonts\}  				{\textbackslash}usepackage\{amssymb\}  				{\textbackslash}usepackage\{amsbsy\} 				{\textbackslash}usepackage\{mathrsfs\} 				{\textbackslash}usepackage\{upgreek\} 				{\textbackslash}setlength\{{\textbackslash}oddsidemargin\}\{-69pt\} 				{\textbackslash}begin\{document\}\$\${\textbackslash}zeta \$\${\textbackslash}end\{document\}{$\zeta$}-mixup ~is faster than mixup, and extensive evaluation on controlled synthetic and 26 diverse real-world natural and medical image classification datasets shows that {\textbackslash}documentclass[12pt]\{minimal\} 				{\textbackslash}usepackage\{amsmath\} 				{\textbackslash}usepackage\{wasysym\}  				{\textbackslash}usepackage\{amsfonts\}  				{\textbackslash}usepackage\{amssymb\}  				{\textbackslash}usepackage\{amsbsy\} 				{\textbackslash}usepackage\{mathrsfs\} 				{\textbackslash}usepackage\{upgreek\} 				{\textbackslash}setlength\{{\textbackslash}oddsidemargin\}\{-69pt\} 				{\textbackslash}begin\{document\}\$\${\textbackslash}zeta \$\${\textbackslash}end\{document\}{$\zeta$}-mixup ~outperforms mixup, CutMix,~and traditional data augmentation techniques. The code will be released at https://github.com/kakumarabhishek/zeta-mixup.},
  pmcid = {PMC10960781},
  pmid = {38528850}
}

@book{AdvancedHTMLParsing,
  title = {5. {{Advanced HTML Parsing}}},
  urldate = {2024-04-08},
  abstract = {Chapter 5. Advanced HTML Parsing When Michelangelo was asked how he could sculpt a work of art as masterful as his David, he is famously reported to have said, ``It is easy. You just chip away...},
  isbn = {978-1-09-814534-7}
}

@article{ahmadTransferLearningassistedMultiresolution2022,
  title = {Transfer Learning-Assisted Multi-Resolution Breast Cancer Histopathological Images Classification},
  author = {Ahmad, Nouman and Asghar, Sohail and Gillani, Saira Andleeb},
  year = {2022},
  month = aug,
  journal = {The Visual Computer},
  volume = {38},
  number = {8},
  pages = {2751--2770},
  issn = {1432-2315},
  doi = {10.1007/s00371-021-02153-y},
  urldate = {2024-11-01},
  abstract = {Breast cancer is one of the leading death cause among women nowadays. Several methods have been proposed for the detection of breast cancer. Various machine learning-based automatic diagnosis systems have been developed known as Computer Aided Diagnostics (CAD) systems. Initial CAD systems were based on machine learning algorithms however due to the automatic feature extraction ability of convolutional neural networks (CNN)-based deep learning models are widely adopted. Deep learning is widely used in various fields. Healthcare is one of the essential field that deep learning has transformed. Another common issue faced by the patients is difference of opinion among different pathologists and medical practitioners. Such human errors often lead to misleading or delayed judgment, which may be fatal to human life. To improve decision consistency, efficiency, and error reduction, researchers in the field of healthcare are using deep learning-based approaches and achieved state of art results. In this study, a deep learning (DL) and transfer learning-based approach is proposed to classify histopathological images for breast cancer diagnosis. In this study, we have adopted patch selection approach to classify breast histopathological images on small number of training images using transfer learning without losing the performance. Initially, patches are extracted from Whole Slide Images and fed into the CNN for features extraction. Based on these features, the discriminative patches are selected and then fed to Efficient-Net architecture pre-trained on ImageNet dataset. Features extracted from Efficient-Net architecture are also used to train a SVM classifier. The proposed model outperforms the baseline methods in terms of multiple performance measures.},
  langid = {english},
  keywords = {Artificial Intelligence,Breast cancer,Convolution neural network,Deep learning,Histopathological images,Transfer learning},
  file = {/home/james/Zotero/storage/VYZVTV4R/Ahmad et al. - 2022 - Transfer learning-assisted multi-resolution breast cancer histopathological images classification.pdf}
}

@article{ajaniGastricCancerVersion2022,
  title = {Gastric {{Cancer}}, {{Version}} 2.2022, {{NCCN Clinical Practice Guidelines}} in {{Oncology}}},
  author = {Ajani, Jaffer A. and D'Amico, Thomas A. and Bentrem, David J. and Chao, Joseph and Cooke, David and Corvera, Carlos and Das, Prajnan and Enzinger, Peter C. and Enzler, Thomas and Fanta, Paul and Farjah, Farhood and Gerdes, Hans and Gibson, Michael K. and Hochwald, Steven and Hofstetter, Wayne L. and Ilson, David H. and Keswani, Rajesh N. and Kim, Sunnie and Kleinberg, Lawrence R. and Klempner, Samuel J. and Lacy, Jill and Ly, Quan P. and Matkowskyj, Kristina A. and McNamara, Michael and Mulcahy, Mary F. and Outlaw, Darryl and Park, Haeseong and Perry, Kyle A. and Pimiento, Jose and Poultsides, George A. and Reznik, Scott and Roses, Robert E. and Strong, Vivian E. and Su, Stacey and Wang, Hanlin L. and Wiesner, Georgia and Willett, Christopher G. and Yakoub, Danny and Yoon, Harry and McMillian, Nicole and Pluchino, Lenora A.},
  year = {2022},
  month = feb,
  journal = {Journal of the National Comprehensive Cancer Network},
  volume = {20},
  number = {2},
  pages = {167--192},
  publisher = {National Comprehensive Cancer Network},
  issn = {1540-1405, 1540-1413},
  doi = {10.6004/jnccn.2022.0008},
  urldate = {2024-08-23},
  abstract = {Gastric cancer is the third leading cause of cancer-related deaths worldwide. Over 95\% of gastric cancers are adenocarcinomas, which are typically classified based on anatomic location and histologic type. Gastric cancer generally carries a poor prognosis because it is often diagnosed at an advanced stage. Systemic therapy can provide palliation, improved survival, and enhanced quality of life in patients with locally advanced or metastatic disease. The implementation of biomarker testing, especially analysis of HER2 status, microsatellite instability (MSI) status, and the expression of programmed death-ligand 1 (PD-L1), has had a significant impact on clinical practice and patient care. Targeted therapies including trastuzumab, nivolumab, and pembrolizumab have produced encouraging results in clinical trials for the treatment of patients with locally advanced or metastatic disease. Palliative management, which may include systemic therapy, chemoradiation, and/or best supportive care, is recommended for all patients with unresectable or metastatic cancer. Multidisciplinary team management is essential for all patients with localized gastric cancer. This selection from the NCCN Guidelines for Gastric Cancer focuses on the management of unresectable locally advanced, recurrent, or metastatic disease.},
  chapter = {Journal of the National Comprehensive Cancer Network}
}

@article{aledhariFederatedLearningSurvey2020,
  title = {Federated {{Learning}}: {{A Survey}} on {{Enabling Technologies}}, {{Protocols}}, and {{Applications}}},
  shorttitle = {Federated {{Learning}}},
  author = {Aledhari, Mohammed and Razzak, Rehma and Parizi, Reza M. and Saeed, Fahad},
  year = {2020},
  month = jul,
  journal = {IEEE access : practical innovations, open solutions},
  volume = {8},
  pages = {140699},
  doi = {10.1109/access.2020.3013541},
  urldate = {2024-10-22},
  abstract = {This paper provides a comprehensive study of Federated Learning (FL) with an emphasis on enabling software and hardware platforms, protocols, real-life applications and use-cases. FL can be applicable to multiple domains but applying it to different ...},
  langid = {english},
  pmid = {32999795}
}

@article{almeidaComputedTomographyStomach2018,
  title = {Computed {{Tomography}} with a {{Stomach Protocol}} and {{Virtual Gastroscopy}} in the {{Staging}} of {{Gastric Cancer}}: {{An Initial Experience}}},
  shorttitle = {Computed {{Tomography}} with a {{Stomach Protocol}} and {{Virtual Gastroscopy}} in the {{Staging}} of {{Gastric Cancer}}},
  author = {Almeida, Maria Fernanda Arruda and Verza, Leonardo and Bitencourt, Almir Galv{\~a}o Vieira and Boaventura, Camila Silva and Barbosa, Paula Nicole Vieira Pinto and Chojniak, Rubens},
  year = {2018},
  journal = {Radiologia Brasileira},
  volume = {51},
  number = {4},
  pages = {211--217},
  issn = {0100-3984},
  doi = {10.1590/0100-3984.2017.0097},
  urldate = {2024-08-23},
  abstract = {Objective To evaluate the accuracy of multidetector computed tomography with a stomach protocol in staging of gastric cancer. Materials and Methods We evaluated 14 patients who underwent computed tomography in a 16-channel scanner for preoperative staging of gastric adenocarcinoma between September 2015 and December 2016. All images were analyzed by the same radiologist, who had extensive experience in abdominal cancer imaging. The sensitivity, specificity, and accuracy of the method were calculated by comparing it with the pathology result. All patients underwent partial or total gastrectomy. Results The mean age was 61.5 years, and 53.8\% of the patients were male. The gastric lesions were classified as T1/T2 in 35.7\% of the cases, as T3 in 28.5\%, and as T4 in 35.7\%. Eleven patients (68.7\%) had suspicious (N positive) lymph nodes. The accuracy of the T1/T2, T3, T4, and lymph node staging tests was 85\%, 78\%, 90\%, and 78\%, respectively. The respective sensitivity and specificity values were 71\% and 100\% for T1/T2, 66\% and 81\% for T3, 100\% and 90\% for T4, and 88\% and 60\% for lymph nodes. Conclusion Multidetector computed tomography with a stomach protocol, used in conjunction with virtual gastroscopy, shows good accuracy in the tumor and lymph node staging of gastric adenocarcinoma.},
  pmcid = {PMC6124583},
  pmid = {30202123}
}

@article{almufarehFederatedLearningApproach2023,
  title = {A {{Federated Learning Approach}} to {{Breast Cancer Prediction}} in a {{Collaborative Learning Framework}}},
  author = {Almufareh, Maram Fahaad and Tariq, Noshina and Humayun, Mamoona and Almas, Bushra},
  year = {2023},
  month = dec,
  journal = {Healthcare},
  volume = {11},
  number = {24},
  pages = {3185},
  issn = {2227-9032},
  doi = {10.3390/healthcare11243185},
  urldate = {2024-09-06},
  abstract = {Breast cancer continues to pose a substantial worldwide public health concern, necessitating the use of sophisticated diagnostic methods to enable timely identification and management. The present research utilizes an iterative methodology for collaborative learning, using Deep Neural Networks (DNN) to construct a breast cancer detection model with a high level of accuracy. By leveraging Federated Learning (FL), this collaborative framework effectively utilizes the combined knowledge and data assets of several healthcare organizations while ensuring the protection of patient privacy and data security. The model described in this study showcases significant progress in the field of breast cancer diagnoses, with a maximum accuracy rate of 97.54\%, precision of 96.5\%, and recall of 98.0\%, by using an optimum feature selection technique. Data augmentation approaches play a crucial role in decreasing loss and improving model performance. Significantly, the F1-Score, a comprehensive metric for evaluating performance, turns out to be 97\%. This study signifies a notable advancement in the field of breast cancer screening, fostering hope for improved patient outcomes via increased accuracy and reliability. This study highlights the potential impact of collaborative learning, namely, in the field of FL, in transforming breast cancer detection. The incorporation of privacy considerations and the use of diverse data sources contribute to the advancement of early detection and the treatment of breast cancer, hence yielding significant benefits for patients on a global scale.},
  pmcid = {PMC10743267},
  pmid = {38132075},
  file = {/home/james/Zotero/storage/5X5JB4EC/Almufareh et al. - 2023 - A Federated Learning Approach to Breast Cancer Prediction in a Collaborative Learning Framework.pdf}
}

@misc{alomHistoryBeganAlexNet2018,
  title = {The {{History Began}} from {{AlexNet}}: {{A Comprehensive Survey}} on {{Deep Learning Approaches}}},
  shorttitle = {The {{History Began}} from {{AlexNet}}},
  author = {Alom, Md Zahangir and Taha, Tarek M. and Yakopcic, Christopher and Westberg, Stefan and Sidike, Paheding and Nasrin, Mst Shamima and Van Esesn, Brian C. and Awwal, Abdul A. S. and Asari, Vijayan K.},
  year = {2018},
  month = sep,
  number = {arXiv:1803.01164},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1803.01164},
  urldate = {2024-04-23},
  abstract = {Deep learning has demonstrated tremendous success in variety of application domains in the past few years. This new field of machine learning has been growing rapidly and applied in most of the application domains with some new modalities of applications, which helps to open new opportunity. There are different methods have been proposed on different category of learning approaches, which includes supervised, semi-supervised and un-supervised learning. The experimental results show state-of-the-art performance of deep learning over traditional machine learning approaches in the field of Image Processing, Computer Vision, Speech Recognition, Machine Translation, Art, Medical imaging, Medical information processing, Robotics and control, Bio-informatics, Natural Language Processing (NLP), Cyber security, and many more. This report presents a brief survey on development of DL approaches, including Deep Neural Network (DNN), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN) including Long Short Term Memory (LSTM) and Gated Recurrent Units (GRU), Auto-Encoder (AE), Deep Belief Network (DBN), Generative Adversarial Network (GAN), and Deep Reinforcement Learning (DRL). In addition, we have included recent development of proposed advanced variant DL techniques based on the mentioned DL approaches. Furthermore, DL approaches have explored and evaluated in different application domains are also included in this survey. We have also comprised recently developed frameworks, SDKs, and benchmark datasets that are used for implementing and evaluating deep learning approaches. There are some surveys have published on Deep Learning in Neural Networks [1, 38] and a survey on RL [234]. However, those papers have not discussed the individual advanced techniques for training large scale deep learning models and the recently developed method of generative models [1].},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{alshahraniWhyNotUse2018,
  title = {``{{Why Not Use It More}}?'' {{Sources}} of {{Self-Efficacy}} in {{Researchers}}' {{Use}} of {{Social Media}} for {{Knowledge Sharing}}},
  shorttitle = {``{{Why Not Use It More}}?},
  author = {Alshahrani, Hussain and Pennington, Diane Rasmussen},
  year = {2018},
  journal = {Journal of Documentation},
  volume = {74},
  number = {6},
  pages = {1274--1292},
  publisher = {Emerald Group Publishing Limited},
  address = {Bradford, United Kingdom},
  issn = {00220418},
  doi = {http://dx.doi.org.ezproxy.lib.uts.edu.au/10.1108/JD-04-2018-0051},
  urldate = {2021-08-09},
  abstract = {Purpose The purpose of this paper is to investigate the sources of self-efficacy that researchers rely on when using social media for knowledge sharing and to explore how these sources impact their use. The study employed 30 semi-structured interviews with researchers at a major Scottish university. The authors analysed the interview transcriptions using directed content analysis. The researchers relied on the four sources of self-efficacy proposed by Bandura (1977) when using social media for knowledge sharing. These sources lead researchers to use social media effectively and frequently for sharing knowledge, although some may discourage its use. It extends the self-efficacy integrative theoretical framework of Bandura (1977) by presenting the relative amount of the influence of these sources for researchers to share their ideas, experiences, questions and research outputs on social media. While the participants included academic staff, postdoctoral researchers, and PhD students, the majority were PhD students. The findings can help universities understand how to promote productive use of social media. For example, academic staff who have high personal mastery experience could mentor those who do not. This is the first known study to investigate the sources of self-efficacy that impact researchers' use of social media for knowledge sharing.},
  copyright = {{\textbackslash}copyright Emerald Publishing Limited 2018},
  keywords = {Business And Economics-Labor And Industrial Relations,Colleges \textbackslash& universities,Colleges & universities,Content analysis,Digital media,Effectiveness,Knowledge sharing,Library And Information Sciences,Literature reviews,Media,Research,Researchers,Social networks,Students,User behavior}
}

@article{amazeenReinforcingAttitudesGatewatching2019,
  title = {Reinforcing {{Attitudes}} in a {{Gatewatching News Era}}: {{Individual-level Antecedents}} to {{Sharing Fact-Checks}} on {{Social Media}}},
  shorttitle = {Reinforcing {{Attitudes}} in a {{Gatewatching News Era}}},
  author = {Amazeen, Michelle A. and Vargo, Chris J. and Hopp, Toby},
  year = {2019},
  month = mar,
  journal = {Communication Monographs},
  volume = {86},
  number = {1},
  pages = {112--132},
  publisher = {Taylor \& Francis Ltd},
  issn = {03637751},
  doi = {10.1080/03637751.2018.1521984},
  urldate = {2021-08-07},
  abstract = {Despite the prevalence of fact-checking, little is known about who posts fact-checks online. Based upon a content analysis of Facebook and Twitter digital trace data and a linked online survey (N{\textbackslash},={\textbackslash},783), this study reveals that sharing fact-checks in political conversations on social media is linked to age, ideology, and political behaviors. Moreover, an individual's need for orientation (NFO) is an even stronger predictor of sharing a fact-check than ideological intensity or relevance, alone, and also influences the type of fact-check format (with or without a rating scale) that is shared. Finally, participants generally shared fact-checks to reinforce their existing attitudes. Consequently, concerns over the effects of fact-checking should move beyond a limited-effects approach (e.g., changing attitudes) to also include reinforcing accurate beliefs.},
  keywords = {Accuracy in journalism,Content analysis,Fact checking in politics,Fact-checking,Fake news,Ideology,inoculation theory,need for orientation,News websites,persuasion,Political communication,social media,Social media \textbackslash& politics,Social media & politics}
}

@misc{andrewsEthicalConsiderationsResponsible2023,
  title = {Ethical {{Considerations}} for {{Responsible Data Curation}}},
  author = {Andrews, Jerone T. A. and Zhao, Dora and Thong, William and Modas, Apostolos and Papakyriakopoulos, Orestis and Xiang, Alice},
  year = {2023},
  month = dec,
  number = {arXiv:2302.03629},
  publisher = {arXiv},
  urldate = {2024-05-23},
  abstract = {Human-centric computer vision (HCCV) data curation practices often neglect privacy and bias concerns, leading to dataset retractions and unfair models. HCCV datasets constructed through nonconsensual web scraping lack crucial metadata for comprehensive fairness and robustness evaluations. Current remedies are post hoc, lack persuasive justification for adoption, or fail to provide proper contextualization for appropriate application. Our research focuses on proactive, domainspecific recommendations, covering purpose, privacy and consent, and diversity, for curating HCCV evaluation datasets, addressing privacy and bias concerns. We adopt an ante hoc reflective perspective, drawing from current practices, guidelines, dataset withdrawals, and audits, to inform our considerations and recommendations.},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Databases,Computer Science - Machine Learning}
}

@inproceedings{anithakumariAutomatedImageCaptioning2020,
  title = {Automated {{Image Captioning}} for {{Flickr8K Dataset}}},
  booktitle = {Proceedings of {{International Conference}} on {{Artificial Intelligence}}, {{Smart Grid}} and {{Smart City Applications}}},
  author = {Anitha Kumari, K. and Mouneeshwari, C. and Udhaya, R. B. and Jasmitha, R.},
  editor = {Kumar, L. Ashok and Jayashree, L. S. and Manimegalai, R.},
  year = {2020},
  pages = {679--687},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-24051-6_62},
  abstract = {Automated, accurate image captioning is currently a hot topic in the field of deep learning. The model must have the capability to generate human-readable sentences for regions in the image. The model must understand the image to find the words that string together to be comprehensive. To achieve this, in this research work, Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) are used on Flickr8K dataset. To identify the regions in the image and to recognize the objects in the regions, an advanced region-based CNN (RCNN) methodology has been used. To generate the caption that is most relevant to the image, RNN is used in this paper. Bilingual evaluation understudy (BLEU) score is considered as the evaluation parameter.},
  isbn = {978-3-030-24051-6},
  keywords = {Automated image captioning,Flickr8K dataset,Recurrent neural network,Region-based CNN}
}

@article{anonymousConsumerDataPrivacy2013,
  title = {Consumer {{Data Privacy}} in a {{Networked World}}: {{A Framework}} for {{Protecting Privacy}} and {{Promoting Innovation}} in the {{Global Digital Economy}}},
  shorttitle = {Consumer {{Data Privacy}} in a {{Networked World}}},
  author = {Anonymous, A.},
  year = {2013},
  month = mar,
  journal = {Journal of Privacy and Confidentiality},
  volume = {4},
  number = {2},
  issn = {2575-8527},
  doi = {10.29012/jpc.v4i2.623},
  urldate = {2024-09-05},
  copyright = {Copyright (c) 2013  Anonymous},
  langid = {english},
  file = {/home/james/Zotero/storage/GJPL5Q6B/Anonymous - 2013 - Consumer Data Privacy in a Networked World A Framework for Protecting Privacy and Promoting Innovat.pdf}
}

@book{aralHypeMachineHow2020,
  title = {The {{Hype Machine}}: {{How Social Media Disrupts Our Elections}}, {{Our Economy}}, and {{Our Health}}--{{And How We Must Adapt}}},
  shorttitle = {The {{Hype Machine}}},
  author = {Aral, Sinan},
  year = {2020},
  month = sep,
  publisher = {Currency},
  address = {New York},
  abstract = {A landmark insider's tour of how social media affects our decision-making and shapes our world in ways both useful and dangerous, with critical insights into the social media trends of the 2020 election and beyond "The book might be described as prophetic. . . . At least two of Aral's three predictions have come to fruition."--New York NAMED ONE OF THE BEST BOOKS OF THE YEAR BY WIRED - LONGLISTED FOR THE PORCHLIGHT BUSINESS BOOK AWARD Social media connected the world--and gave rise to fake news and increasing polarization. It is paramount, MIT professor Sinan Aral says, that we recognize the outsize effect social media has on us--on our politics, our economy, and even our personal health--in order to steer today's social technology toward its great promise while avoiding the ways it can pull us apart. Drawing on decades of his own research and business experience, Aral goes under the hood of the most powerful social networks to tackle the critical question of just how much social media actually shapes our choices, for better or worse. He shows how the tech behind social media offers the same set of behavior influencing levers to everyone who hopes to change the way we think and act--from Russian hackers to brand marketers--which is why its consequences affect everything from elections to business, dating to health. Along the way, he covers a wide array of topics, including how network effects fuel Twitter's and Facebook's massive growth, the neuroscience of how social media affects our brains, the real consequences of fake news, the power of social ratings, and the impact of social media on our kids. In mapping out strategies for being more thoughtful consumers of social media, The Hype Machine offers the definitive guide to understanding and harnessing for good the technology that has redefined our world overnight.},
  isbn = {978-0-525-57451-4}
}

@article{avanzoMachineDeepLearning2020,
  title = {Machine and {{Deep Learning Methods}} for {{Radiomics}}},
  author = {Avanzo, Michele and Wei, Lise and Stancanello, Joseph and Valli{\`e}res, Martin and Rao, Arvind and Morin, Olivier and Mattonen, Sarah A. and El Naqa, Issam},
  year = {2020},
  month = jun,
  journal = {Medical physics},
  volume = {47},
  number = {5},
  pages = {e185-e202},
  issn = {0094-2405},
  doi = {10.1002/mp.13678},
  urldate = {2024-08-23},
  abstract = {Radiomics is an emerging area in quantitative image analysis that aims to relate large-scale extracted imaging information to clinical and biological endpoints. The development of quantitative imaging methods along with machine learning has enabled the opportunity to move data science research towards translation for more personalized cancer treatments. Accumulating evidence has indeed demonstrated that non-invasive advanced imaging analytics, i.e., radiomics, can reveal key components of tumor phenotype for multiple three-dimensional lesions at multiple time points over and beyond the course of treatment. These developments in the use of CT, PET, US and MR imaging could augment patient stratification and prognostication buttressing emerging targeted therapeutic approaches. In recent years, deep learning architectures have demonstrated their tremendous potential for image segmentation, reconstruction, recognition, and classification. Many powerful open-source and commercial platforms are currently available to embark in new research areas of radiomics. Quantitative imaging research, however, is complex and key statistical principles should be followed to realize its full potential. The field of radiomics, in particular, require a renewed focus on optimal study design/reporting practices and standardization of image acquisition, feature calculation and rigorous statistical analysis for the field to move forward. In this article, the role of machine and deep learning as a major computational vehicle for advanced model building of radiomics-based signatures or classifiers, and diverse clinical applications, working principles, research opportunities and available computational platforms for radiomics will be reviewed with examples drawn primarily from oncology. We also address issues related to common applications in medical physics, such as standardization, feature extraction, model building, and validation.},
  pmcid = {PMC8965689},
  pmid = {32418336}
}

@article{bakFederatedLearningNot2024,
  title = {Federated Learning Is Not a Cure-All for Data Ethics},
  author = {Bak, Marieke and Madai, Vince I. and Celi, Leo Anthony and Kaissis, Georgios A. and Cornet, Ronald and Maris, Menno and Rueckert, Daniel and Buyx, Alena and McLennan, Stuart},
  year = {2024},
  month = apr,
  journal = {Nature Machine Intelligence},
  volume = {6},
  number = {4},
  pages = {370--372},
  publisher = {Springer International Publishing},
  issn = {2522-5839},
  doi = {10.1038/s42256-024-00813-x},
  urldate = {2024-09-04},
  langid = {english},
  file = {/home/james/Zotero/storage/39QEFWCK/federated-learning-is-not-a-cure-all-for-data-ethics.html}
}

@article{banksBritishSocietyGastroenterology2019,
  title = {British {{Society}} of {{Gastroenterology Guidelines}} on the {{Diagnosis}} and {{Management}} of {{Patients}} at {{Risk}} of {{Gastric Adenocarcinoma}}},
  author = {Banks, Matthew and Graham, David and Jansen, Marnix and Gotoda, Takuji and Coda, Sergio and Di Pietro, Massimiliano and Uedo, Noriya and Bhandari, Pradeep and Pritchard, D Mark and Kuipers, Ernst J and {Rodriguez-Justo}, Manuel and Novelli, Marco R and Ragunath, Krish and Shepherd, Neil and {Dinis-Ribeiro}, Mario},
  year = {2019},
  month = sep,
  journal = {Gut},
  volume = {68},
  number = {9},
  pages = {1545--1575},
  issn = {0017-5749, 1468-3288},
  doi = {10.1136/gutjnl-2018-318126},
  urldate = {2024-08-21},
  abstract = {Gastric adenocarcinoma carries a poor prognosis, in part due to the late stage of diagnosis. Risk factors include Helicobacter pylori infection, family history of gastric cancer---in particular, hereditary diffuse gastric cancer and pernicious anaemia. The stages in the progression to cancer include chronic gastritis, gastric atrophy (GA), gastric intestinal metaplasia (GIM) and dysplasia. The key to early detection of cancer and improved survival is to non-invasively identify those at risk before endoscopy. However, although biomarkers may help in the detection of patients with chronic atrophic gastritis, there is insufficient evidence to support their use for population screening. High-quality endoscopy with full mucosal visualisation is an important part of improving early detection. Image-enhanced endoscopy combined with biopsy sampling for histopathology is the best approach to detect and accurately risk-stratify GA and GIM. Biopsies following the Sydney protocol from the antrum, incisura, lesser and greater curvature allow both diagnostic confirmation and risk stratification for progression to cancer. Ideally biopsies should be directed to areas of GA or GIM visualised by high-quality endoscopy. There is insufficient evidence to support screening in a low-risk population (undergoing routine diagnostic oesophagogastroduodenoscopy) such as the UK, but endoscopic surveillance every 3{\textbackslash},years should be offered to patients with extensive GA or GIM. Endoscopic mucosal resection or endoscopic submucosal dissection of visible gastric dysplasia and early cancer has been shown to be efficacious with a high success rate and low rate of recurrence, providing that specific quality criteria are met.}
}

@book{bassLeadershipPerformanceExpectations1985,
  title = {Leadership and Performance beyond Expectations},
  author = {Bass, Bernard M.},
  year = {1985},
  publisher = {Collier Macmillan},
  address = {London},
  isbn = {978-0-02-901810-1},
  langid = {english}
}

@book{bassTransformationalLeadership2006,
  title = {Transformational  Leadership},
  author = {Bass, Bernard M.},
  year = {2006},
  edition = {2nd ed.},
  publisher = {L. Erlbaum Associates},
  address = {Mahwah, N.J},
  collaborator = {Riggio, Ronald E.},
  isbn = {978-0-8058-4761-1},
  langid = {english},
  lccn = {658.4092 BASB (ED.2)},
  keywords = {Leadership,Organizational change}
}

@article{beckenBenefitsPitfallsUsing2020,
  title = {Benefits and {{Pitfalls}} of {{Using Tweets}} to {{Assess Destination Sentiment}}},
  author = {Becken, Susanne and Alaei, Ali Reza and Wang, Ying},
  year = {2020},
  journal = {Journal of Hospitality and Tourism Technology},
  volume = {11},
  number = {1},
  pages = {19--34},
  publisher = {Emerald Group Publishing Limited},
  address = {Bingley, United Kingdom},
  issn = {17579880},
  doi = {http://dx.doi.org.ezproxy.lib.uts.edu.au/10.1108/JHTT-09-2017-0090},
  urldate = {2021-08-07},
  abstract = {Purpose Destination monitoring is crucial to understand performance and identify key points of differentiation. Visitor satisfaction is an essential driver of destination performance. With the fast-growing volume of user-generated content through social media, it is now possible to tap into very large amounts of data provided by travellers as they share their experiences. Analysing these data for consumer sentiment has become attractive for destinations and companies. The idea of drawing on social media sentiment for satisfaction monitoring aligns well with the broader move towards smart destinations and real-time information processing. Thus, this paper aims to examine whether the electronic word of mouth originating from Twitter posts offers a useful source for assessing destination sentiment. Importantly, this research examines what caveats need to be considered when interpreting the findings. This research focusses on a prominent tourist destination situated on Australia's East Coast, the Gold Coast. Using a geographically informed filtering process, a collection of tweets posted from within the Gold Coast destination was created and analysed. Metadata were analysed to assess the population of Twitter users, and sentiment analysis, using the Valence Aware Dictionary for Sentiment Reasoning algorithm, was performed. Twitter posts provide considerable information, including about who is visiting and what sentiment visitors and residents express when sending tweets from a destination. They also uncover some challenges, including the ``noise'' of Twitter data and the fact that users are not representative of the broader population, in particular for international visitors. This paper highlights limitations such as lack of representativeness of the Twitter data, positive bias and the generic nature of many tweets. Suggestions for how to improve the analysis and value of tweets as a data source are made. This paper contributes to understanding the value of non-traditional data sources for destination monitoring, in particular by highlighting some of the pitfalls of using information sources, such as Twitter. Further research steps have been identified, especially with a view to improving target-specific sentiment scores and the future employment of big-data approaches that involve integrating multiple data sources for destination performance monitoring. The identification of cost-effective ways of measuring and monitoring guest satisfaction can lead to improvements in destination management. This in turn will enhance customer experience and possibly even resident satisfaction. The social benefits, especially at times of considerable visitation pressure, can be important. The use of Twitter data for the monitoring of visitor sentiment at tourist destinations is novel, and the analysis presented here provides unique insights into the potential, but also the caveats, of developing new, smart systems for tourism.},
  copyright = {{\textbackslash}copyright Emerald Publishing Limited 2019},
  keywords = {Computers-Internet,Decision making,Dictionaries,Internet access,Questionnaires,Sentiment analysis,Social network analysis,Social networks,Tourism,Travel And Tourism,User generated content}
}

@misc{bertelsConvolutionalNeuralNetworks2022,
  title = {Convolutional {{Neural Networks}} for {{Medical Image Segmentation}}},
  author = {Bertels, Jeroen and Robben, David and Lemmens, Robin and Vandermeulen, Dirk},
  year = {2022},
  month = nov,
  number = {arXiv:2211.09562},
  publisher = {arXiv},
  urldate = {2024-08-20},
  abstract = {In this article, we look into some essential aspects of convolutional neural networks (CNNs) with the focus on medical image segmentation. First, we discuss the CNN architecture, thereby highlighting the spatial origin of the data, voxel-wise classification and the receptive field. Second, we discuss the sampling of input-output pairs, thereby highlighting the interaction between voxel-wise classification, patch size and the receptive field. Finally, we give a historical overview of crucial changes to CNN architectures for classification and segmentation, giving insights in the relation between three pivotal CNN architectures: FCN [15], U-Net [18] and DeepMedic [9].},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
}

@misc{bharatiFederatedLearningApplications2022,
  title = {Federated Learning: {{Applications}}, Challenges and Future Directions},
  shorttitle = {Federated Learning},
  author = {Bharati, Subrato and Mondal, M. Rubaiyat Hossain and Podder, Prajoy and Prasath, V. B. Surya},
  year = {2022},
  month = may,
  journal = {arXiv.org},
  doi = {10.3233/HIS-220006},
  urldate = {2024-09-05},
  abstract = {Federated learning (FL) is a system in which a central aggregator coordinates the efforts of multiple clients to solve machine learning problems. This setting allows training data to be dispersed in order to protect privacy. The purpose of this paper is to provide an overview of FL systems with a focus on healthcare. FL is evaluated here based on its frameworks, architectures, and applications. It is shown here that FL solves the preceding issues with a shared global deep learning (DL) model via a central aggregator server. This paper examines recent developments and provides a comprehensive list of unresolved issues, inspired by the rapid growth of FL research. In the context of FL, several privacy methods are described, including secure multiparty computation, homomorphic encryption, differential privacy, and stochastic gradient descent. Furthermore, a review of various FL classes, such as horizontal and vertical FL and federated transfer learning, is provided. FL has applications in wireless communication, service recommendation, intelligent medical diagnosis systems, and healthcare, all of which are discussed in this paper. We also present a thorough review of existing FL challenges, such as privacy protection, communication cost, system heterogeneity, and unreliable model upload, followed by future research directions.},
  howpublished = {https://arxiv.org/abs/2205.09513v2},
  langid = {english},
  file = {/home/james/Zotero/storage/CW48GAGR/Bharati et al. - 2022 - Federated learning Applications, challenges and future directions.pdf}
}

@article{biancoBenchmarkAnalysisRepresentative2018,
  title = {Benchmark {{Analysis}} of {{Representative Deep Neural Network Architectures}}},
  author = {Bianco, Simone and Cadene, Remi and Celona, Luigi and Napoletano, Paolo},
  year = {2018},
  journal = {IEEE Access},
  volume = {6},
  pages = {64270--64277},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2018.2877890},
  urldate = {2024-04-20},
  abstract = {This work presents an in-depth analysis of the majority of the deep neural networks (DNNs) proposed in the state of the art for image recognition. For each DNN multiple performance indices are observed, such as recognition accuracy, model complexity, computational complexity, memory usage, and inference time. The behavior of such performance indices and some combinations of them are analyzed and discussed. To measure the indices we experiment the use of DNNs on two different computer architectures, a workstation equipped with a NVIDIA Titan X Pascal and an embedded system based on a NVIDIA Jetson TX1 board. This experimentation allows a direct comparison between DNNs running on machines with very different computational capacity. This study is useful for researchers to have a complete view of what solutions have been explored so far and in which research directions are worth exploring in the future; and for practitioners to select the DNN architecture(s) that better fit the resource constraints of practical deployments and applications. To complete this work, all the DNNs, as well as the software used for the analysis, are available online.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@book{bishopDeepLearningFoundations2024,
  title = {Deep {{Learning}}: {{Foundations}} and {{Concepts}}},
  shorttitle = {Deep {{Learning}}},
  author = {Bishop, Christopher M. and Bishop, Hugh},
  year = {2024},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-45468-4},
  urldate = {2024-04-17},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {978-3-031-45467-7 978-3-031-45468-4},
  keywords = {Convolutional networks,Decision theory,Deep learning,Directed graphical models,machine learning,Neural networks}
}

@book{boaksLeadershipEthics2017,
  title = {Leadership and {{Ethics}}},
  author = {Boaks, Jacqueline and Levine, Michael P.},
  year = {2017},
  publisher = {Bloomsbury Publishing Plc},
  address = {London, UNITED KINGDOM},
  urldate = {2024-06-19},
  isbn = {978-1-4725-7068-0},
  keywords = {Leadership - Moral and ethical aspects}
}

@incollection{bossardFood101MiningDiscriminative2014,
  title = {Food-101 -- {{Mining Discriminative Components}} with {{Random Forests}}},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2014},
  author = {Bossard, Lukas and Guillaumin, Matthieu and Van Gool, Luc},
  editor = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
  year = {2014},
  volume = {8694},
  pages = {446--461},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-10599-4_29},
  urldate = {2024-04-16},
  abstract = {In this paper we address the problem of automatically recognizing pictured dishes. To this end, we introduce a novel method to mine discriminative parts using Random Forests (rf), which allows us to mine for parts simultaneously for all classes and to share knowledge among them. To improve efficiency of mining and classification, we only consider patches that are aligned with image superpixels, which we call components. To measure the performance of our rf component mining for food recognition, we introduce a novel and challenging dataset of 101 food categories, with 101'000 images. With an average accuracy of 50.76\%, our model outperforms alternative classification methods except for cnn, including svm classification on Improved Fisher Vectors and existing discriminative part-mining algorithms by 11.88\% and 8.13\%, respectively. On the challenging mit-Indoor dataset, our method compares nicely to other s-o-a component-based classification methods.},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-319-10598-7 978-3-319-10599-4}
}

@article{brownMyersBriggsTypeIndicator2009,
  title = {The {{Myers-Briggs}} Type Indicator and Transformational Leadership},
  author = {Brown, F. William and Reilly, Michael D.},
  year = {2009},
  journal = {The Journal of Management Development},
  volume = {28},
  number = {10},
  pages = {916--932},
  publisher = {Emerald Group Publishing Limited},
  address = {Bradford, United Kingdom},
  issn = {02621711},
  doi = {10.1108/02621710911000677},
  urldate = {2024-10-28},
  abstract = {Purpose - This paper aims to study the possible relationship between elements of personality as measured by the Myers-Briggs type indicator (MBTI) and transformational leadership (TL) as measured by the Multifactor Leadership Questionnaire (MLQ). Design/methodology/approach - The study was done at the North American manufacturing facility of an international technology company. Utilizing the Multifactor Leadership Questionnaire to measure transformational leadership, over 2,000 followers provided assessments of transformational leadership for 148 managers who had done self-assessments and had completed Form K of the MBTI. Findings - No relationship was found between follower assessments of transformational leadership and leader personality as measured by the MBTI. Leaders did, however, perceive themselves to be significantly more transformational than did those who reported to them. Leader preference for extraversion over introversion and intuition over perception were both significantly associated with self-reports of transformational leadership. Research limitations/implications - Studies utilizing large samples across a variety of organizational settings are needed to confirm the results of this study. Practical implications - This study calls into question the existence of a relationship between the MBTI and transformational leadership. The study does not provide any support for the possible utility of the MBTI for the prediction or explanation of transformational leadership behaviors. Assuming that followers' perceptions of TL are the more valid, the findings suggest that previous results linking MBTI and TL may be measurement artifacts. Originality/value - Utilizing a large sample, the MLQ and continuous measures of MBTI preferences the results of this study contradict previous reports of a relationship between personality as measured by the MBTI and transformational leadership.},
  copyright = {Copyright Emerald Group Publishing Limited 2009},
  langid = {english},
  keywords = {20th century,Archetypes (Psychology),Behavior,Leadership,Management training,Morality,Personality,Personality traits,Preferences,Psychological tests,Self evaluation,Studies,Validity,World War II},
  file = {/home/james/Zotero/storage/9MRIX2L8/Brown and Reilly - 2009 - The Myers-Briggs type indicator and transformational leadership.pdf}
}

@book{brunsTwitterSociety2013,
  title = {Twitter and {{Society}}},
  author = {Bruns, Axel and Burgess, Jean and Mahrt, Merja and Puschmann, Cornelius and Weller, Katrin},
  year = {2013},
  series = {Digital {{Formations}}},
  edition = {1st, New ed.},
  number = {89},
  publisher = {Peter Lang Incorporated, International Academic Publishers},
  address = {New York},
  abstract = {This book has won the CHOICE Outstanding Academic Title award 2014. Since its launch in 2006, Twitter has evolved from a niche service to a mass phenomenon; it has become instrumental for everyday communication as well as for political debates, crisis communication, marketing, and cultural participation. But the basic idea behind it has stayed the same: users may post short messages (tweets) of up to 140 characters and follow the updates posted by other users. Drawing on the experience of leading international Twitter researchers from a variety of disciplines and contexts, this is the first book to document the various notions and concepts of Twitter communication, providing a detailed and comprehensive overview of current research into the uses of Twitter. It also presents methods for analyzing Twitter data and outlines their practical application in different research contexts., {\textpm}[T]his book is a great resource for educators and researchers alike in the growing field of social media communication. (Patricia Swann, Journalism and Mass Communication Quaterly 91/4 2014), {\textpm}This collection of important work - featuring both well-known and emerging scholars from diverse disciplines - helps contextualize Twitter as a sociotechnical phenomenon. It will serve as a crucial foundation for new research while also offering useful perspectives for educators helping students to understand social media. By going beyond na{\"i}ve stereotypes and revealing the complex practices and diverse users that help define Twitter, this book provides rich insights into the importance of social media in contemporary life. (Danah Boyd, Senior Researcher at Microsoft Research and Research Assistant Professor in Media, Culture, and Communication at New York University) {\textpm}Talk of Big Data is everywhere, as contributors to this book rightly note. This timely collection, bringing together noted scholars and academics who work in the area, offers important insight into Big Data through a focus on the most important real-time stream message bus today, namely Twitter. Covering key aspects of Twitter social use and practices, Twitter and Society is a key text for providing empirical and methodological reflection on a fast-moving and important area of research. (David M. Berry, Reader in Media \& Communication and Co-Director of the Centre for Material Digital Culture at Sussex University)},
  isbn = {978-1-4541-9992-2}
}

@book{burnsTransformingLeadershipNew2003,
  title = {Transforming Leadership: A New Pursuit of Happiness},
  shorttitle = {Transforming Leadership},
  author = {Burns, James MacGregor},
  year = {2003},
  publisher = {Grove},
  address = {New York},
  isbn = {978-0-8021-4118-7},
  langid = {english}
}

@misc{CanCTScan,
  title = {Can a {{CT Scan Detect Stomach Cancer}}? {{Procedure}}, {{Getting Help}}},
  urldate = {2024-08-22}
}

@article{carstensenPowerIdeasConceptualizing2016,
  title = {Power through, over and in {{Ideas}}: {{Conceptualizing Ideational Power}} in {{Discursive Institutionalism}}},
  shorttitle = {Power through, over and in {{Ideas}}},
  author = {Carstensen, Martin B. and Schmidt, Vivien A.},
  year = {2016},
  month = mar,
  journal = {Journal of European Public Policy},
  volume = {23},
  number = {3},
  pages = {318--337},
  publisher = {Routledge},
  issn = {13501763},
  doi = {10.1080/13501763.2015.1115534},
  urldate = {2021-07-07},
  abstract = {Owing to the tendency of discursive institutionalists to conflate the notion that `ideas matter' for policy-making with the `power of ideas', little has been done to explicitly theorize ideational power. To fill this lacuna, the contribution defines ideational power as the capacity of actors (whether individual or collective) to influence other actors' normative and cognitive beliefs through the use of ideational elements, and -- based on insights from the discursive institutionalist literature -- suggests three different types of ideational power:power through ideas, understood as the capacity of actors to persuade other actors to accept and adopt their views through the use of ideational elements;power over ideas, meaning the imposition of ideas and the power to resist the inclusion of alternative ideas into the policy-making arena; andpower in ideas, which takes place through the establishing of hegemony or institutions imposing constraints on what ideas are considered.},
  keywords = {Discursive institutionalism,GOVERNMENT policy,HEGEMONY,ideas,MARXIAN economics,NORMATIVE economics,POLITICAL science research,power,POWER (Social sciences)}
}

@misc{changBiasPropagationFederated2023,
  title = {Bias {{Propagation}} in {{Federated Learning}}},
  author = {Chang, Hongyan and Shokri, Reza},
  year = {2023},
  month = sep,
  number = {arXiv:2309.02160},
  eprint = {2309.02160},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.02160},
  urldate = {2024-09-04},
  abstract = {We show that participating in federated learning can be detrimental to group fairness. In fact, the bias of a few parties against under-represented groups (identified by sensitive attributes such as gender or race) can propagate through the network to all the parties in the network. We analyze and explain bias propagation in federated learning on naturally partitioned real-world datasets. Our analysis reveals that biased parties unintentionally yet stealthily encode their bias in a small number of model parameters, and throughout the training, they steadily increase the dependence of the global model on sensitive attributes. What is important to highlight is that the experienced bias in federated learning is higher than what parties would otherwise encounter in centralized training with a model trained on the union of all their data. This indicates that the bias is due to the algorithm. Our work calls for auditing group fairness in federated learning and designing learning algorithms that are robust to bias propagation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/james/Zotero/storage/8NZSVZUD/Chang and Shokri - 2023 - Bias Propagation in Federated Learning.pdf}
}

@misc{changBiasPropagationFederated2023a,
  title = {Bias {{Propagation}} in {{Federated Learning}}},
  author = {Chang, Hongyan and Shokri, Reza},
  year = {2023},
  month = sep,
  number = {arXiv:2309.02160},
  eprint = {2309.02160},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2024-09-04},
  abstract = {We show that participating in federated learning can be detrimental to group fairness. In fact, the bias of a few parties against under-represented groups (identified by sensitive attributes such as gender or race) can propagate through the network to all the parties in the network. We analyze and explain bias propagation in federated learning on naturally partitioned real-world datasets. Our analysis reveals that biased parties unintentionally yet stealthily encode their bias in a small number of model parameters, and throughout the training, they steadily increase the dependence of the global model on sensitive attributes. What is important to highlight is that the experienced bias in federated learning is higher than what parties would otherwise encounter in centralized training with a model trained on the union of all their data. This indicates that the bias is due to the algorithm. Our work calls for auditing group fairness in federated learning and designing learning algorithms that are robust to bias propagation.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/james/Zotero/storage/44QMCQKW/Chang and Shokri - 2023 - Bias Propagation in Federated Learning.pdf}
}

@misc{changBiasPropagationFederated2023b,
  title = {Bias {{Propagation}} in {{Federated Learning}}},
  author = {Chang, Hongyan and Shokri, Reza},
  year = {2023},
  month = sep,
  number = {arXiv:2309.02160},
  eprint = {2309.02160},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.02160},
  urldate = {2024-09-06},
  abstract = {We show that participating in federated learning can be detrimental to group fairness. In fact, the bias of a few parties against under-represented groups (identified by sensitive attributes such as gender or race) can propagate through the network to all the parties in the network. We analyze and explain bias propagation in federated learning on naturally partitioned real-world datasets. Our analysis reveals that biased parties unintentionally yet stealthily encode their bias in a small number of model parameters, and throughout the training, they steadily increase the dependence of the global model on sensitive attributes. What is important to highlight is that the experienced bias in federated learning is higher than what parties would otherwise encounter in centralized training with a model trained on the union of all their data. This indicates that the bias is due to the algorithm. Our work calls for auditing group fairness in federated learning and designing learning algorithms that are robust to bias propagation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/james/Zotero/storage/3N33QUAR/Chang and Shokri - 2023 - Bias Propagation in Federated Learning.pdf}
}

@book{ChapterModelAggregation,
  title = {Chapter 7: {{Model Aggregation}}},
  shorttitle = {Chapter 7},
  urldate = {2024-09-04},
  abstract = {7 			Model Aggregation 			 In the Model aggregation basics section of Chapter 3, Workings of the Federated Learning System, we introduced the concept of aggregation within the federated...},
  isbn = {978-1-80324-710-6},
  langid = {english},
  file = {/home/james/Zotero/storage/7HLWSR4A/B18369_07.html}
}

@book{ChapterWhatFederated,
  title = {Chapter 2: {{What Is Federated Learning}}?},
  shorttitle = {Chapter 2},
  urldate = {2024-09-06},
  abstract = {2 			What Is Federated Learning? 			 In Chapter 1, Challenges in Big Data and Traditional AI, we examined how shifting tides in big data and machine learning (ML) have set the stage for a...},
  isbn = {978-1-80324-710-6},
  langid = {english},
  file = {/home/james/Zotero/storage/ACA5S8YT/B18369_02.html}
}

@article{chenRadiomicsPrecisionMedicine2022,
  title = {Radiomics in {{Precision Medicine}} for {{Gastric Cancer}}: {{Opportunities}} and {{Challenges}}},
  shorttitle = {Radiomics in {{Precision Medicine}} for {{Gastric Cancer}}},
  author = {Chen, Qiuying and Zhang, Lu and Liu, Shuyi and You, Jingjing and Chen, Luyan and Jin, Zhe and Zhang, Shuixing and Zhang, Bin},
  year = {2022},
  month = sep,
  journal = {European Radiology},
  volume = {32},
  number = {9},
  pages = {5852--5868},
  issn = {1432-1084},
  doi = {10.1007/s00330-022-08704-8},
  urldate = {2024-08-23},
  abstract = {Radiomic features derived from routine medical images show great potential for personalized medicine in gastric cancer (GC). We aimed to evaluate the current status and quality of radiomic research as well as its potential for identifying biomarkers to predict therapy response and prognosis in patients with GC.},
  keywords = {Artificial Intelligence,Gastric cancer,Medical Imaging,Radiomics,Study quality,Survival,Therapy response}
}

@misc{chongEmpiricallySupportedTaxonomy,
  type = {Chapter},
  title = {An {{Empirically Supported Taxonomy}} of {{Misinformation}}},
  author = {Chong, Mark and Choy, Murphy},
  journal = {https://services-igi-global-com.ezproxy.lib.uts.edu.au/resolvedoi/resolve.aspx?doi=10.4018/978-1-7998-2543-2.ch005},
  publisher = {IGI Global},
  urldate = {2021-09-13},
  copyright = {Access limited to members},
  isbn = {9781799825432}
}

@book{chunClinicalGastrointestinalEndoscopy2018,
  title = {Clinical {{Gastrointestinal Endoscopy}}: {{A Comprehensive Atlas}}},
  shorttitle = {Clinical {{Gastrointestinal Endoscopy}}},
  editor = {Chun, Hoon Jai and Yang, Suk-Kyun and Choi, Myung-Gyu},
  year = {2018},
  publisher = {Springer Singapore},
  address = {Singapore},
  doi = {10.1007/978-981-10-4995-8},
  urldate = {2024-08-21},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-981-10-4994-1 978-981-10-4995-8}
}

@misc{chungEmpiricalEvaluationGated2014,
  title = {Empirical {{Evaluation}} of {{Gated Recurrent Neural Networks}} on {{Sequence Modeling}}},
  author = {Chung, Junyoung and Gulcehre, Caglar and Cho, KyungHyun and Bengio, Yoshua},
  year = {2014},
  month = dec,
  number = {arXiv:1412.3555},
  publisher = {arXiv},
  urldate = {2024-05-16},
  abstract = {In this paper we compare different types of recurrent units in recurrent neural networks (RNNs). Especially, we focus on more sophisticated units that implement a gating mechanism, such as a long short-term memory (LSTM) unit and a recently proposed gated recurrent unit (GRU). We evaluate these recurrent units on the tasks of polyphonic music modeling and speech signal modeling. Our experiments revealed that these advanced recurrent units are indeed better than more traditional recurrent units such as tanh units. Also, we found GRU to be comparable to LSTM.},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing}
}

@article{clarkeCovid19WhoFact2021,
  title = {Covid-19: {{Who Fact Checks Health}} and {{Science}} on {{Facebook}}?},
  shorttitle = {Covid-19},
  author = {Clarke, Laurie},
  year = {2021},
  month = may,
  journal = {BMJ},
  pages = {n1170},
  issn = {1756-1833},
  doi = {10.1136/bmj.n1170},
  urldate = {2021-08-09}
}

@misc{CompetencyFramework,
  title = {Competency {{Framework}}},
  urldate = {2024-10-29},
  howpublished = {https://www.d2dcrc.com.au/data-science-competency-framework},
  file = {/home/james/Zotero/storage/5A4CKXJ2/data-science-competency-framework.html}
}

@article{contiEarlyGastricCancer2023,
  title = {Early {{Gastric Cancer}}: {{Update}} on {{Prevention}}, {{Diagnosis}} and {{Treatment}}},
  shorttitle = {Early {{Gastric Cancer}}},
  author = {Conti, Clara Benedetta and Agnesi, Stefano and Scaravaglio, Miki and Masseria, Pietro and Dinelli, Marco Emilio and Oldani, Massimo and Uggeri, Fabio},
  year = {2023},
  month = jan,
  journal = {International Journal of Environmental Research and Public Health},
  volume = {20},
  number = {3},
  pages = {2149},
  issn = {1660-4601},
  doi = {10.3390/ijerph20032149},
  urldate = {2024-08-21},
  abstract = {Gastric cancer (GC) is a relevant public health issue as its incidence and mortality rates are growing worldwide. There are recognized carcinogen agents, such as obesity, tobacco, meat, alcohol consumption and some dietary protective factors. Strategies of early diagnosis through population-based surveillance programs have been demonstrated to be effective in lowering the morbidity and mortality related to GC in some countries. Indeed, the detection of early lesions is very important in order to offer minimally invasive treatments. Endoscopic resection is the gold standard for lesions with a low risk of lymph node metastasis, whereas surgical mini-invasive approaches can be considered in early lesions when endoscopy is not curative. This review outlines the role of lifestyle and prevention strategies for GC, in order to reduce the patients' risk factors, implement the surveillance of precancerous conditions and, therefore, improve the diagnosis of early lesions. Furthermore, we summarize the available treatments for early gastric cancer.},
  copyright = {https://creativecommons.org/licenses/by/4.0/}
}

@article{COVID19Misinformation2020,
  title = {{{COVID-19}} and {{Misinformation}}},
  year = {2020},
  month = nov,
  journal = {EMBO reports},
  volume = {21},
  number = {11},
  pages = {e51420},
  publisher = {John Wiley \& Sons, Ltd},
  issn = {1469-221X},
  doi = {10.15252/embr.202051420},
  urldate = {2021-08-09},
  abstract = {Social media companies have resorted to censorship to suppress misinformation about the COVID-19 pandemic. This is not the most prudent solution though given the uncertainties about the disease.}
}

@misc{COVID19MisleadingInformation,
  title = {{{COVID-19 Misleading Information Policy}}},
  urldate = {2021-08-09},
  abstract = {Content that is demonstrably false or misleading and may lead to significant risk of harm (such as increased exposure to the virus, or adverse effects on public health systems) may not be shared on Twitter and is subject to removal.}
}

@book{dabrowskiManagingITProjects2023,
  title = {Managing {{IT Projects}}: {{How}} to {{Pragmatically Deliver Projects}} for {{External Customers}}},
  shorttitle = {Managing {{IT Projects}}},
  author = {D{\k a}browski, Marcin},
  year = {2023},
  publisher = {Apress},
  address = {Berkeley, CA},
  doi = {10.1007/978-1-4842-9243-3},
  urldate = {2024-08-11},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {978-1-4842-9242-6 978-1-4842-9243-3},
  keywords = {Business transformation,customer satisfaction,delay management,effective communication,key success factors,making things happen,managing expectations,on-time delivery,project delays,transparency}
}

@article{dadkhahRealTimeHostileActivities2021,
  title = {A {{Real-Time Hostile Activities Analyses}} and {{Detection System}}},
  author = {Dadkhah, Sajjad and Shoeleh, Farzaneh and Yadollahi, Mohammad Mehdi and Zhang, Xichen and Ghorbani, Ali A.},
  year = {2021},
  month = jun,
  journal = {Applied Soft Computing},
  volume = {104},
  pages = {107175},
  issn = {1568-4946},
  doi = {10.1016/j.asoc.2021.107175},
  urldate = {2021-07-21},
  abstract = {Over recent years, the development of online social media has dramatically changed the way people connect and share information. It is undeniable that social platform has promoted the quickest type of spread for fake stories. Almost all the current online fact-checking sources and researches are concentrating on the validating political content and context. The proposed system in this paper provides a complete visual data analytics methods to assist users in achieving a comprehensive understanding of malicious activities at multiple levels such as adversary's behavior, victim's behavior, content, and context level. In this paper, we investigate a variety of datasets from different aspects such as role, vulnerabilities, influential level, and distribution pattern. The proposed method in this paper focuses on automatic fake/hostile activity detection by utilizing a variety of machine learning (ML) techniques, deep learning models, natural language processes (NLP), and social network analysis (SNA) techniques. Different auxiliary models, such as bot detection, user credibility, and text readability, are deployed to generate additional influential features. The classification performance of ten different machine learning algorithms using a variety of well-known datasets is evaluated by utilizing 10-fold cross-validation.},
  keywords = {Bot detection,Fake news detection,Hostile detection,Natural language processing,Social network analysis}
}

@book{dalkirNavigatingFakeNews,
  title = {Navigating {{Fake News}}, {{Alternative Facts}}, and {{Misinformation}} in a {{Post-Truth World}}},
  author = {Dalkir, Kimiz and Katz, Rebecca},
  journal = {https://services-igi-global-com.ezproxy.lib.uts.edu.au/resolvedoi/resolve.aspx?doi=10.4018/978-1-7998-2543-2},
  publisher = {IGI Global},
  urldate = {2021-09-12},
  copyright = {Access limited to members},
  isbn = {978-1-79982-543-2}
}

@article{dangTwitterPartnersAP2021,
  title = {Twitter {{Partners}} with {{AP}}, {{Reuters}} to {{Battle Misinformation}} on {{Its Site}}},
  author = {Dang, Sheila},
  year = {2021},
  month = aug,
  journal = {Reuters},
  urldate = {2021-08-09},
  abstract = {Twitter Inc (TWTR.N) will partner with the Associated Press and Reuters to more quickly provide credible information on the social networking site as part of an effort to fight the spread of misinformation, it said on Monday.},
  chapter = {Technology}
}

@misc{DataEthicsCanvas,
  title = {The {{Data Ethics Canvas}} 2021 -- {{The ODI}}},
  urldate = {2021-08-10}
}

@article{davidUsingSentimentAnalysis2024,
  title = {Using Sentiment Analysis to Assess {{PMBOK}} Knowledge Areas' Compatibility with Agile Methodology},
  author = {David, I. and Gelbard, R.},
  year = {2024},
  month = jan,
  journal = {Procedia Computer Science},
  series = {{{CENTERIS}} -- {{International Conference}} on {{ENTERprise Information Systems}} / {{ProjMAN}} - {{International Conference}} on {{Project MANagement}} / {{HCist}} - {{International Conference}} on {{Health}} and {{Social Care Information Systems}} and {{Technologies}} 2023},
  volume = {239},
  pages = {381--395},
  issn = {1877-0509},
  doi = {10.1016/j.procs.2024.06.185},
  urldate = {2024-10-26},
  abstract = {The agile approach to software development has significantly impacted the industry, given its ability to cope with requirements. Despite this, many aspects of the agile paradigm's compatibility with various software project characteristics have not been thoroughly researched. To address this lacuna, the study presents a systematic literature review (SLR) that aims to assess the compatibility of the agile methodology with each of the knowledge areas included in the Project Management Body of Knowledge (PMBOK). By employing Machine Learning (ML) text-mining and sentiment analysis techniques, the paper explores the sentiment regarding each PMBOK knowledge area (PM-KA). It thus provides valuable insights to assist practitioners and researchers in assessing the compatibility of the agile methodology with each PM-KA and identifying potential gaps or significant challenges within the agile paradigm.},
  keywords = {Agile Methodology,Project Management,Sentiment Analysis,Systematic Literature Review},
  file = {/home/james/Zotero/storage/I9E2IE9Z/David and Gelbard - 2024 - Using sentiment analysis to assess PMBOK knowledge areas compatibility with agile methodology.pdf}
}

@book{deabreuTeachingMediaLiteracy2019,
  title = {Teaching {{Media Literacy}}},
  author = {De Abreu, Belinha S. and Ciulla Lipkin, Michelle and Agosto, Denise E.},
  year = {2019},
  publisher = {American Library Association},
  address = {Chicago, UNITED STATES},
  urldate = {2021-08-16},
  isbn = {978-0-8389-4612-1},
  keywords = {Media literacy-Study and teaching.}
}

@misc{DecisionMakingUncertainty,
  title = {Decision {{Making}} under {{Uncertainty}} and {{Reinforcement Learning}} : {{Theory}} and {{Algorithms}} - {{University}} of {{Technology Sydney}}},
  shorttitle = {Decision {{Making}} under {{Uncertainty}} and {{Reinforcement Learning}}},
  urldate = {2024-04-08},
  abstract = {Decision making under uncertainty and reinforcement learning : theory and algorithms -book}
}

@book{demanzoniGastricCancer25Year2022,
  title = {Gastric {{Cancer}}: {{The}} 25-{{Year R-Evolution}}},
  shorttitle = {Gastric {{Cancer}}},
  editor = {De Manzoni, Giovanni and Roviello, Franco},
  year = {2022},
  series = {Updates in {{Surgery}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-73158-8},
  urldate = {2024-08-23},
  copyright = {https://www.springer.com/tdm},
  isbn = {978-3-030-73157-1 978-3-030-73158-8}
}

@misc{DemocracyPreparationConduct,
  title = {Democracy and the {{Preparation}} and {{Conduct}} of {{War}} - {{ProQuest}}},
  urldate = {2024-06-19},
  abstract = {Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the ProQuest Platform.}
}

@article{dengArtificialIntelligenceApplications2022,
  title = {Artificial Intelligence Applications in Pathological Diagnosis of Gastric Cancer},
  author = {Deng, Yang and Qin, Hang-Yu and Zhou, Yan-Yan and Liu, Hong-Hong and Jiang, Yong and Liu, Jian-Ping and Bao, Ji},
  year = {2022},
  month = dec,
  journal = {Heliyon},
  volume = {8},
  number = {12},
  pages = {e12431},
  issn = {2405-8440},
  doi = {10.1016/j.heliyon.2022.e12431},
  urldate = {2024-09-06},
  abstract = {Globally, gastric cancer is the third leading cause of death from tumors. Prevention and individualized treatment are considered to be the best options for reducing the mortality rate of gastric cancer. Artificial intelligence (AI) technology has been widely used in the field of gastric cancer, including diagnosis, prognosis, and image analysis. Eligible papers were identified from PubMed and IEEE up to April 13, 2022. Through the comparison of these articles, the application status of AI technology in the diagnosis of gastric cancer was summarized, including application types, application scenarios, advantages and limitations. This review presents the current state and role of AI in the diagnosis of gastric cancer based on four aspects: 1) accurate sampling from early diagnosis (endoscopy), 2) digital pathological diagnosis, 3) molecules and genes, and 4) clinical big data analysis and prognosis prediction. AI plays a very important role in facilitating the diagnosis of gastric cancer; however, it also has shortcomings such as interpretability. The purpose of this review is to provide assistance to researchers working in this domain., Gastric cancer; Pathological diagnosis; Artificial intelligence; Gastroenterology.},
  pmcid = {PMC9816967},
  pmid = {36619448},
  file = {/home/james/Zotero/storage/QW7I6LWL/Deng et al. - 2022 - Artificial intelligence applications in pathological diagnosis of gastric cancer.pdf}
}

@article{dengAssociationPreoperativeChemosensitivity2021,
  title = {Association of {{Preoperative Chemosensitivity With Postoperative Survival}} in {{Patients With Resected Gastric Adenocarcinoma}}},
  author = {Deng, Lei and Groman, Adrienne and Jiang, Changchuan and Perimbeti, Stuthi and Gabriel, Emmanuel and Kukar, Moshim and Mukherjee, Sarbajit},
  year = {2021},
  month = nov,
  journal = {JAMA Network Open},
  volume = {4},
  number = {11},
  pages = {e2135340},
  issn = {2574-3805},
  doi = {10.1001/jamanetworkopen.2021.35340},
  urldate = {2024-09-06},
  abstract = {Considering its low completion rate, the survival benefit associated with postoperative chemotherapy (PC) is unclear in patients with resectable gastric adenocarcinoma who received preoperative chemotherapy.To determine whether preoperative chemosensitivity is associated with postoperative survival among patients with resectable gastric adenocarcinoma who receive  PC.This national, hospital-based cohort study used data from the National Cancer Database, which covers more than 70\% newly diagnosed gastric adenocarcinomas in the US, between 2006 and 2017. Participants included patients with clinical stage II or III disease treated with preoperative chemotherapy and curative-intent resection, excluding radiotherapy.  Preoperative chemosensitivity was defined as very sensitive (ypT0N0), sensitive (pathological TNM stage\,less than\,clinical, excluding ypT0N0), and refractory (pathological\,greater than or equal to\,clinical). Data were analyzed in April 2021.Receipt of PC or not.Overall survival from surgical discharge.This study included 2382 patients (1599 men [67\%]; median [IQR] age, 63 [54-70] years). Most patients (1524 patients [64\%]) received no PC. Most patients (1483 patients [62\%]) had refractory disease, followed by sensitive disease (727 patients [31\%]) and very sensitive disease (172 patients [7\%]). Patients with older age (odds ratio [OR], 0.99; 95\% CI, 0.97-1.00), comorbidity (OR, 0.71; 95\% CI, 0.57-0.90), longer time from chemotherapy initiation to surgery (OR, 0.99; 95\% CI, 0.97-1.00), less sensitivity to preoperative chemotherapy (very sensitive vs refractory OR, 0.58; 95\% CI, 0.37-0.89; sensitive vs refractory OR, 0.96; 95\% CI, 0.76-1.20), and longer surgical hospitalization (OR, 0.95; 95\% CI, 0.93-0.97) had a significantly lower likelihood of receiving PC. PC was not associated with improved survival in the whole group (hazard ratio [HR], 0.88; 95\% CI, 0.75-1.02). Patients with refractory disease had the worst survival compared with patients with sensitive disease (HR, 0.39; 95\% CI, 0.32-0.46) and those with very sensitive disease (HR, 0.12; 95\% CI, 0.07-0.20). Preoperative chemosensitivity was significantly associated with the survival benefit from PC (P\,for interaction\,=\,.03). PC was significantly associated with longer survival in patients with sensitive disease (5-year survival rate, 73.8\% in the PC group vs 65.0\% in the no PC group; HR, 0.64; 95\% CI, 0.46-0.91), but not in those with very sensitive disease (5-year survival rate, 80.0\% in the PC group vs 90.8\% in the no PC group; HR, 2.45; 95\% CI, 0.81-7.43) and those with refractory disease (5-year survival rate, 41.8\% in the PC group vs 40.7\% in the no PC group; HR, 0.93; 95\% CI, 0.79-1.10).In this cohort study, preoperative chemosensitivity was associated with survival among patients with resectable gastric adenocarcinoma who received PC. These findings may help inform future studies to personalize postoperative therapy.},
  file = {/home/james/Zotero/storage/BPBFS8T6/Deng et al. - 2021 - Association of Preoperative Chemosensitivity With Postoperative Survival in Patients With Resected G.pdf;/home/james/Zotero/storage/AD3AWW46/2786353.html}
}

@article{dengEdgeIntelligenceConfluence2020,
  title = {Edge {{Intelligence}}: {{The Confluence}} of {{Edge Computing}} and {{Artificial Intelligence}}},
  shorttitle = {Edge {{Intelligence}}},
  author = {Deng, Shuiguang and Zhao, Hailiang and Fang, Weijia and Yin, Jianwei and Dustdar, Schahram and Zomaya, Albert Y.},
  year = {2020},
  month = aug,
  journal = {IEEE Internet of Things Journal},
  volume = {7},
  number = {8},
  pages = {7457--7469},
  issn = {2327-4662, 2372-2541},
  doi = {10.1109/JIOT.2020.2984887},
  urldate = {2024-04-24},
  abstract = {Along with the rapid developments in communication technologies and the surge in the use of mobile devices, a brand-new computation paradigm, Edge Computing, is surging in popularity. Meanwhile, Artificial Intelligence (AI) applications are thriving with the breakthroughs in deep learning and the many improvements in hardware architectures. Billions of data bytes, generated at the network edge, put massive demands on data processing and structural optimization. Thus, there exists a strong demand to integrate Edge Computing and AI, which gives birth to Edge Intelligence. In this paper, we divide Edge Intelligence into AI for edge (Intelligence-enabled Edge Computing) and AI on edge (Artificial Intelligence on Edge). The former focuses on providing more optimal solutions to key problems in Edge Computing with the help of popular and effective AI technologies while the latter studies how to carry out the entire process of building AI models, i.e., model training and inference, on the edge. This paper provides insights into this new inter-disciplinary field from a broader perspective. It discusses the core concepts and the research road-map, which should provide the necessary background for potential future research initiatives in Edge Intelligence.},
  keywords = {and Cluster Computing,and Cluster Computing\vphantom,Computer Science - Distributed,Computer Science - Distributed\vphantom,Computer Science - Networking and Internet Architecture,Parallel}
}

@article{denizTransferLearningBased2018,
  title = {Transfer Learning Based Histopathologic Image Classification for Breast Cancer Detection},
  author = {Deniz, Erkan and {\c S}eng{\"u}r, Abdulkadir and Kadiro{\u g}lu, Zehra and Guo, Yanhui and Bajaj, Varun and Budak, {\"U}mit},
  year = {2018},
  month = sep,
  journal = {Health Information Science and Systems},
  volume = {6},
  number = {1},
  pages = {18},
  doi = {10.1007/s13755-018-0057-x},
  urldate = {2024-11-01},
  abstract = {Breast cancer is one of the leading cancer type among women in worldwide. Many breast cancer patients die every year due to the late diagnosis and treatment. Thus, in recent years, early breast cancer detection systems based on patient's imagery are ...},
  langid = {english},
  pmid = {30279988},
  file = {/home/james/Zotero/storage/HIGP89AH/Deniz et al. - 2018 - Transfer learning based histopathologic image classification for breast cancer detection.pdf}
}

@misc{DeveloperTermsTwitter,
  title = {Developer {{Terms}} -- {{Twitter Developers}}},
  urldate = {2021-08-10},
  abstract = {Developer terms -- Twitter Developers. Developer use of Twitter materials and content is subject to and governed by our Developer Policy and agreements.}
}

@book{dimitrakakisDecisionMakingUncertainty2022,
  title = {Decision {{Making}} under {{Uncertainty}} and {{Reinforcement Learning}} : {{Theory}} and {{Algorithms}}},
  author = {Dimitrakakis, Christos and Ortner, Ronald},
  year = {2022},
  series = {Intelligent {{Systems Reference Library}} ; {{Volume}} 223},
  publisher = {Springer},
  address = {Cham, Switzerland},
  isbn = {3-031-07614-1},
  keywords = {Decision making - Mathematical models,Reinforcement learning.,Uncertainty.}
}

@incollection{dipietroChapter21Deep2020,
  title = {Chapter 21 - {{Deep Learning}}: {{RNNs}} and {{LSTM}}},
  shorttitle = {Chapter 21 - {{Deep Learning}}},
  booktitle = {Handbook of {{Medical Image Computing}} and {{Computer Assisted Intervention}}},
  author = {DiPietro, Robert and Hager, Gregory D.},
  editor = {Zhou, S. Kevin and Rueckert, Daniel and Fichtinger, Gabor},
  year = {2020},
  month = jan,
  series = {The {{Elsevier}} and {{MICCAI Society Book Series}}},
  pages = {503--519},
  publisher = {Academic Press},
  doi = {10.1016/B978-0-12-816176-0.00026-0},
  urldate = {2024-05-22},
  abstract = {Recurrent neural networks (RNNs) are a class of neural networks that are naturally suited to processing time-series data and other sequential data. Here we introduce recurrent neural networks as an extension to feedforward networks, in order to allow the processing of variable-length (or even infinite-length) sequences, and some of the most popular recurrent architectures in use, including long short-term memory (LSTM) and gated recurrent units (GRUs). In addition, various aspects surrounding RNNs are discussed in detail, including various probabilistic models that are often realized using RNNs and various applications of RNNs that have appeared within the MICCAI community.},
  isbn = {978-0-12-816176-0},
  keywords = {Long short-term memory,Recurrent neural networks}
}

@book{duganLeadershipTheoryCultivating2024,
  title = {Leadership Theory: Cultivating Critical Perspectives},
  shorttitle = {Leadership Theory},
  author = {Dugan, John P.},
  year = {2024},
  edition = {Second edition},
  publisher = {John Wiley \& Sons, Inc},
  address = {Hoboken, New Jersey},
  abstract = {"There is a clear gap in the market for a survey text on leadership theory that is interdisciplinary, includes theories designed for use with college students, and is grounded in social justice. Existing texts tend to (1) be bound to a single discipline, such as business or psychology, (2) lack the critical perspective necessary to fully understand the justice orientation central to many contemporary leadership theories, and/or (3) omit the very theories designed for working with college students. This last issue is particularly troubling given the rapid expansion of curricular and cocurricular leadership programs on college campuses. Collectively, these limitations result in curricular and cocurricular educators' reliance on the few existing and inadequate texts or the need to cobble together multiple texts, articles, and chapters to present the necessary breadth and depth of information"--},
  isbn = {978-1-394-15210-0 978-1-394-15211-7 978-1-394-15212-4},
  langid = {english}
}

@misc{EarlyGastricCancer,
  title = {Early {{Gastric Cancer}}: {{Update}} on {{Prevention}}, {{Diagnosis}} and {{Treatment}} - {{ProQuest}}},
  shorttitle = {Early {{Gastric Cancer}}},
  urldate = {2024-08-21},
  abstract = {Explore millions of resources from scholarly journals, books, newspapers, videos and more, on the ProQuest Platform.}
}

@misc{EfficientGastrointestinalDisease,
  title = {Efficient {{Gastrointestinal Disease Classification Using Pretrained Deep Convolutional Neural Network}} - {{ProQuest}}},
  urldate = {2024-11-02},
  howpublished = {https://www.proquest.com/docview/2799630724?accountid=17095\&parentSessionId=1mlLnft2oPFQ4Hr9bP4KD3\%2FtsGTS6IMRrRMBw03jC\%2Fk\%3D\&pq-origsite=primo\&sourcetype=Scholarly\%20Journals},
  file = {/home/james/Zotero/storage/JQV5QVEL/Efficient Gastrointestinal Disease Classification Using Pretrained Deep Convolutional Neural Network.pdf;/home/james/Zotero/storage/BJXVR96J/2799630724.html}
}

@article{elnaqaExploringFeaturebasedApproaches2009,
  title = {Exploring Feature-Based Approaches in {{PET}} Images for Predicting Cancer Treatment Outcomes},
  author = {El Naqa, I. and Grigsby, P. and Apte, A. and Kidd, E. and Donnelly, E. and Khullar, D. and Chaudhari, S. and Yang, D. and Schmitt, M. and Laforest, Richard and Thorstad, W. and Deasy, J. O.},
  year = {2009},
  month = jun,
  journal = {Pattern recognition},
  volume = {42},
  number = {6},
  pages = {1162--1171},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2008.08.011},
  urldate = {2024-09-04},
  abstract = {Accumulating evidence suggests that characteristics of pre-treatment FDG-PET could be used as prognostic factors to predict outcomes in different cancer sites. Current risk analyses are limited to visual assessment or direct uptake value measurements. We are investigating intensity-volume histogram metrics and shape and texture features extracted from PET images to predict patient's response to treatment. These approaches were demonstrated using datasets from cervix and head and neck cancers, where AUC of 0.76 and 1.0 were achieved, respectively. The preliminary results suggest that the proposed approaches could potentially provide better tools and discriminant power for utilizing functional imaging in clinical prognosis.},
  pmcid = {PMC2701316},
  pmid = {20161266},
  file = {/home/james/Zotero/storage/6BASIDQ2/El Naqa et al. - 2009 - Exploring feature-based approaches in PET images for predicting cancer treatment outcomes.pdf}
}

@misc{EnhancingBreastCancer,
  title = {Enhancing {{Breast Cancer Classification}} in {{Histopathological Images}} through {{Federated Learning Framework}} {\textbar} {{IEEE Journals}} \& {{Magazine}} {\textbar} {{IEEE Xplore}}},
  urldate = {2024-10-22},
  howpublished = {https://ieeexplore-ieee-org.ezproxy.lib.uts.edu.au/document/10145428},
  file = {/home/james/Zotero/storage/UMVP7WGB/Enhancing Breast Cancer Classification in Histopathological Images through Federated Learning Framew.pdf}
}

@misc{FakeNewsChallenge,
  title = {Fake {{News Challenge}}},
  urldate = {2021-08-07}
}

@book{fantiAtlasClinicalPETCT2021,
  title = {Atlas of {{Clinical PET-CT}} in {{Treatment Response Evaluation}} in {{Oncology}}},
  editor = {Fanti, Stefano and Gnanasegaran, Gopinath and Carri{\'o}, Ignasi},
  year = {2021},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-68858-5},
  urldate = {2024-08-23},
  copyright = {https://www.springer.com/tdm},
  isbn = {978-3-030-68857-8 978-3-030-68858-5}
}

@misc{FederatedLearning,
  title = {Federated {{Learning}}},
  urldate = {2024-09-06},
  abstract = {An online research report on federated learning by Cloudera Fast Forward.},
  howpublished = {https://federated.fastforwardlabs.com},
  langid = {english},
  file = {/home/james/Zotero/storage/ZPBKYUTE/federated.fastforwardlabs.com.html}
}

@article{fekiFederatedLearningCOVID192021,
  title = {Federated Learning for {{COVID-19}} Screening from {{Chest X-ray}} Images},
  author = {Feki, Ines and Ammar, Sourour and Kessentini, Yousri and Muhammad, Khan},
  year = {2021},
  month = jul,
  journal = {Applied Soft Computing},
  volume = {106},
  pages = {107330},
  issn = {1568-4946},
  doi = {10.1016/j.asoc.2021.107330},
  urldate = {2024-10-22},
  abstract = {Today, the whole world is facing a great medical disaster that affects the health and lives of the people: the COVID-19 disease, colloquially known as the Corona virus. Deep learning is an effective means to assist radiologists to analyze the vast amount of chest X-ray images, which can potentially have a substantial role in streamlining and accelerating the diagnosis of COVID-19. Such techniques involve large datasets for training and all such data must be centralized in order to be processed. Due to medical data privacy regulations, it is often not possible to collect and share patient data in a centralized data server. In this work, we present a collaborative federated learning framework allowing multiple medical institutions screening COVID-19 from Chest X-ray images using deep learning without sharing patient data. We investigate several key properties and specificities of federated learning setting including the not independent and identically distributed (non-IID) and unbalanced data distributions that naturally arise. We experimentally demonstrate that the proposed federated learning framework provides competitive results to that of models trained by sharing data, considering two different model architectures. These findings would encourage medical institutions to adopt collaborative process and reap benefits of the rich private data in order to rapidly build a powerful model for COVID-19 screening.},
  keywords = {CNN,COVID-19 screening,Decentralized training,Deep learning,Federated learning,X-ray images},
  file = {/home/james/Zotero/storage/FATTM9GY/Feki et al. - 2021 - Federated learning for COVID-19 screening from Chest X-ray images.pdf;/home/james/Zotero/storage/PT56G5Y7/S1568494621002532.html}
}

@article{fengRobustlyFederatedLearning2024,
  title = {Robustly {{Federated Learning Model}} for {{Identifying High-Risk Patients}} with {{Postoperative Gastric Cancer Recurrence}}},
  author = {Feng, Bao and Shi, Jiangfeng and Huang, Liebin and Yang, Zhiqi and Feng, Shi-Ting and Li, Jianpeng and Chen, Qinxian and Xue, Huimin and Chen, Xiangguang and Wan, Cuixia and Hu, Qinghui and Cui, Enming and Chen, Yehang and Long, Wansheng},
  year = {2024},
  month = jan,
  journal = {Nature Communications},
  volume = {15},
  number = {1},
  pages = {742},
  issn = {2041-1723},
  doi = {10.1038/s41467-024-44946-4},
  urldate = {2024-08-22},
  abstract = {Abstract The prediction of patient disease risk via computed tomography (CT) images and artificial intelligence techniques shows great potential. However, training a robust artificial intelligence model typically requires large-scale data support. In practice, the collection of medical data faces obstacles related to privacy protection. Therefore, the present study aims to establish a robust federated learning model to overcome the data island problem and identify high-risk patients with postoperative gastric cancer recurrence in a multicentre, cross-institution setting, thereby enabling robust treatment with significant value. In the present study, we collect data from four independent medical institutions for experimentation. The robust federated learning model algorithm yields area under the receiver operating characteristic curve (AUC) values of 0.710, 0.798, 0.809, and 0.869 across four data centres. Additionally, the effectiveness of the algorithm is evaluated, and both adaptive and common features are identified through analysis.}
}

@article{fengRobustlyFederatedLearning2024a,
  title = {Robustly Federated Learning Model for Identifying High-Risk Patients with Postoperative Gastric Cancer Recurrence},
  author = {Feng, Bao and Shi, Jiangfeng and Huang, Liebin and Yang, Zhiqi and Feng, Shi-Ting and Li, Jianpeng and Chen, Qinxian and Xue, Huimin and Chen, Xiangguang and Wan, Cuixia and Hu, Qinghui and Cui, Enming and Chen, Yehang and Long, Wansheng},
  year = {2024},
  month = jan,
  journal = {Nature Communications},
  volume = {15},
  pages = {742},
  issn = {2041-1723},
  doi = {10.1038/s41467-024-44946-4},
  urldate = {2024-09-06},
  abstract = {The prediction of patient disease risk via computed tomography (CT) images and artificial intelligence techniques shows great potential. However, training a robust artificial intelligence model typically requires large-scale data support. In practice, the collection of medical data faces obstacles related to privacy protection. Therefore, the present study aims to establish a robust federated learning model to overcome the data island problem and identify high-risk patients with postoperative gastric cancer recurrence in a multicentre, cross-institution setting, thereby enabling robust treatment with significant value. In the present study, we collect data from four independent medical institutions for experimentation. The robust federated learning model algorithm yields area under the receiver operating characteristic curve (AUC) values of 0.710, 0.798, 0.809, and 0.869 across four data centres. Additionally, the effectiveness of the algorithm is evaluated, and both adaptive and common features are identified through analysis., Medical data faces isolation and cross-center performance issues. Here, the authors propose a robust federated learning model to identify high-risk postoperative gastric cancer recurrence, achieving promising results across data from four independent medical institutions.},
  pmcid = {PMC10811238},
  pmid = {38272913},
  file = {/home/james/Zotero/storage/URRQYIHX/Feng et al. - 2024 - Robustly federated learning model for identifying high-risk patients with postoperative gastric canc.pdf}
}

@article{fengRobustlyFederatedLearning2024b,
  title = {Robustly Federated Learning Model for Identifying High-Risk Patients with Postoperative Gastric Cancer Recurrence},
  author = {Feng, Bao and Shi, Jiangfeng and Huang, Liebin and Yang, Zhiqi and Feng, Shi-Ting and Li, Jianpeng and Chen, Qinxian and Xue, Huimin and Chen, Xiangguang and Wan, Cuixia and Hu, Qinghui and Cui, Enming and Chen, Yehang and Long, Wansheng},
  year = {2024},
  month = jan,
  journal = {Nature Communications},
  volume = {15},
  pages = {742},
  issn = {2041-1723},
  doi = {10.1038/s41467-024-44946-4},
  urldate = {2024-09-06},
  abstract = {The prediction of patient disease risk via computed tomography (CT) images and artificial intelligence techniques shows great potential. However, training a robust artificial intelligence model typically requires large-scale data support. In practice, the collection of medical data faces obstacles related to privacy protection. Therefore, the present study aims to establish a robust federated learning model to overcome the data island problem and identify high-risk patients with postoperative gastric cancer recurrence in a multicentre, cross-institution setting, thereby enabling robust treatment with significant value. In the present study, we collect data from four independent medical institutions for experimentation. The robust federated learning model algorithm yields area under the receiver operating characteristic curve (AUC) values of 0.710, 0.798, 0.809, and 0.869 across four data centres. Additionally, the effectiveness of the algorithm is evaluated, and both adaptive and common features are identified through analysis., Medical data faces isolation and cross-center performance issues. Here, the authors propose a robust federated learning model to identify high-risk postoperative gastric cancer recurrence, achieving promising results across data from four independent medical institutions.},
  pmcid = {PMC10811238},
  pmid = {38272913},
  file = {/home/james/Zotero/storage/FY49MMTK/Feng et al. - 2024 - Robustly federated learning model for identifying high-risk patients with postoperative gastric canc.pdf}
}

@misc{Food101MiningDiscriminative,
  title = {Food-101 -- {{Mining Discriminative Components}} with {{Random Forests}}},
  urldate = {2024-04-16}
}

@misc{Food101Torchvision17,
  title = {Food101 --- {{Torchvision}} 0.17 {{Documentation}}},
  urldate = {2024-04-16}
}

@misc{FurtherTests,
  title = {Further {{Tests}}},
  journal = {Cancer Council NSW},
  urldate = {2024-08-22},
  abstract = {If the biopsy shows you have stomach cancer, you will have some of the following tests to work out whether the cancer has spread to other areas of your}
}

@misc{GeneralDataProtection,
  title = {General {{Data Protection Regulation}} ({{GDPR}}) -- {{Legal Text}}},
  journal = {General Data Protection Regulation (GDPR)},
  urldate = {2024-10-22},
  abstract = {The official PDF of the Regulation (EU) 2016/679 -- known as GDPR -- its recitals \& key issues as a neatly arranged website.},
  howpublished = {https://gdpr-info.eu/},
  langid = {american},
  file = {/home/james/Zotero/storage/97LTVXND/gdpr-info.eu.html}
}

@misc{GlobalCancerBurden,
  title = {Global {{Cancer Burden Growing}}, amidst {{Mounting Need}} for {{Services}}},
  urldate = {2024-08-23},
  abstract = {Ahead of World Cancer Day, the World Health Organization (WHO)'s cancer agency, the International Agency for Research on Cancer (IARC), released the latest estimates of the global burden of cancer. WHO also published survey results from 115 countries, showing a majority of countries do not adequately finance priority cancer and palliative care services, as part of universal health coverage (UHC).}
}

@misc{GoogleColaboratory,
  title = {Google {{Colaboratory}}},
  urldate = {2024-04-08}
}

@misc{GoogLeNet,
  title = {{{GoogLeNet}}},
  journal = {PyTorch},
  urldate = {2024-04-08},
  abstract = {import torch model = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True) model.eval()}
}

@article{gottliebInformationDisinformationSocial2020,
  title = {Information and {{Disinformation}}: {{Social Media}} in the {{COVID-19 Crisis}}},
  shorttitle = {Information and {{Disinformation}}},
  author = {Gottlieb, Michael and Dyer, Sean},
  year = {2020},
  journal = {Academic Emergency Medicine},
  volume = {27},
  number = {7},
  pages = {640--641},
  issn = {1553-2712},
  doi = {10.1111/acem.14036},
  urldate = {2021-08-09}
}

@article{guptaDeepLearningCNN2022,
  title = {Deep {{Learning}} ({{CNN}}) and {{Transfer Learning}}: {{A Review}}},
  shorttitle = {Deep {{Learning}} ({{CNN}}) and {{Transfer Learning}}},
  author = {Gupta, Jaya and Pathak, Sunil and Kumar, Gireesh},
  year = {2022},
  month = may,
  journal = {Journal of Physics: Conference Series},
  volume = {2273},
  number = {1},
  pages = {012029},
  publisher = {IOP Publishing},
  address = {Bristol, United Kingdom},
  issn = {17426588},
  doi = {10.1088/1742-6596/2273/1/012029},
  urldate = {2024-11-01},
  abstract = {Deep Learning is a machine learning area that has recently been used in a variety of industries. Unsupervised, semi-supervised, and supervised-learning are only a few of the strategies that have been developed to accommodate different types of learning. A number of experiments showed that deep learning systems fared better than traditional ones when it came to image processing, computer vision, and pattern recognition. Several real-world applications and hierarchical systems have utilised transfer learning and deep learning algorithms for pattern recognition and classification tasks. Real-world machine learning settings, on the other hand, often do not support this assumption since training data can be difficult or expensive to get, and there is a constant need to generate high-performance beginners who can work with data from a variety of sources. The objective of this paper is using deep learning to uncover higher-level representational features, to clearly explain transfer learning, to provide current solutions and evaluate applications in diverse areas of transfer learning as well as deep learning.},
  copyright = {Published under licence by IOP Publishing Ltd. This work is published under http://creativecommons.org/licenses/by/3.0/ (the ``License'').  Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
  langid = {english},
  keywords = {Algorithms,Classification,Computer vision,Convolutional neural network,Deep learning,Image processing,Machine learning,Object recognition,Pattern recognition,Physics,Supervised learning,Transfer learning},
  file = {/home/james/Zotero/storage/TK28B9MR/Gupta et al. - 2022 - Deep Learning (CNN) and Transfer Learning A Review.pdf}
}

@incollection{ha-vikstromChapter11Knowledge2016,
  title = {Chapter 11 - {{Knowledge}} Management and Analytical Modeling for Transformational Leadership Profiles in a Multinational Company},
  booktitle = {Successes and {{Failures}} of {{Knowledge Management}}},
  author = {{Ha-Vikstr{\"o}m}, T. and Takala, J.},
  editor = {Liebowitz, Jay},
  year = {2016},
  month = jan,
  pages = {151--173},
  publisher = {Morgan Kaufmann},
  address = {Boston},
  doi = {10.1016/B978-0-12-805187-0.00011-5},
  urldate = {2024-10-28},
  abstract = {Each multinational company endeavors to be a world leader in its field; they invest in knowledge sharing and knowledge management (KM) as well as leadership training to make sure all leaders have the right skills to take the company to the highest level of performance. This study is aimed to examine the direction of transformational leadership capability for the middle level leaders in a multinational company, and to pursue/validate the transformational leadership analytic conceptual model, which allows a simple direct measurement of transformational leadership profiles and provides a total leadership index through participants' responses. Descriptive and normative research approaches have been utilized in this study. By using the analytic hierarchy process tool and the transformational leadership (TL) sand cone model, a series of 26 survey responses from experienced leaders from four different departments in a multinational company were analyzed. The results support a view that the sand cone model is a simple holistic analytic concept to visualize a clear TL profile, as a vital role of KM. Moreover, three practical findings are: First, significance features and factors to help the organization in having a better understanding of their current TL capabilities. Second, a new comprehensive layout for the TL sand cone model to increase the self-awareness for the decision makers. Third, five new equations for TL indexes, that is, the specific index, outcome index, leadership index, resource index, and total TL index that provide a useful and precise assessment for the leaders.},
  isbn = {978-0-12-805187-0},
  keywords = {knowledge management,leadership profile,transformational leadership,transformational leadership sand cone model},
  file = {/home/james/Zotero/storage/RY9YR3S3/B9780128051870000115.html}
}

@article{ha-vikstromMeasuringTransformationalLeadership2018,
  title = {Measuring Transformational Leadership Profiles -- an Empirical Study across 21 Nations in a Multinational Company},
  author = {{Ha-Vikstr{\"o}m}, Thanh and Takala, Josu},
  year = {2018},
  month = jan,
  journal = {Theoretical Issues in Ergonomics Science},
  volume = {19},
  number = {1},
  pages = {1--20},
  issn = {1463-922X, 1464-536X},
  doi = {10.1080/1463922X.2016.1239780},
  urldate = {2024-10-28},
  abstract = {The main purpose of this empirical research is to validate and verify the transformational leadership sand cone model, a decision-making model covering essential behaviours for transformational leaders, from resource allocations to the direction of outcomes. By using transformational leadership indexes and the Analytic Hierarchy Processbased questionnaire as well as a descriptive research approach, we measure the effectiveness of transformational leadership for 86 leaders located in 21 different geographical zones around the world. The results provide an effective measuring method and also a quantitative result that may provide the organisation a new insight into developing training programmes for global leaders. The model can be used as a direct guideline for leaders to follow and improve their transformational leadership skills. It can also be used for recruitment, selection or promotion purposes. Moreover, the model can be utilised as an aid in developing sustainable careers for global leaders.},
  langid = {english},
  file = {/home/james/Zotero/storage/IF25R4VK/Ha-Vikstrm and Takala - 2018 - Measuring transformational leadership profiles  an empirical study across 21 nations in a multinati.pdf}
}

@misc{haddadAnswerAreThere2016,
  title = {Answer to "{{Are}} There Any Image Classification Algorithms Which Are Not Neural Networks?"},
  shorttitle = {Answer to "{{Are}} There Any Image Classification Algorithms Which Are Not Neural Networks?},
  author = {Haddad, Bashar},
  year = {2016},
  month = aug,
  journal = {Data Science Stack Exchange},
  urldate = {2024-09-04},
  file = {/home/james/Zotero/storage/KXBT2UW6/are-there-any-image-classification-algorithms-which-are-not-neural-networks.html}
}

@article{hallinanGastricCarcinomaImaging2013,
  title = {Gastric {{Carcinoma}}: {{Imaging Diagnosis}}, {{Staging}} and {{Assessment}} of {{Treatment Response}}},
  shorttitle = {Gastric {{Carcinoma}}},
  author = {Hallinan, James Thomas Patrick Decourcy and Venkatesh, Sudhakar Kundapur},
  year = {2013},
  month = may,
  journal = {Cancer Imaging},
  volume = {13},
  number = {2},
  pages = {212--227},
  issn = {1740-5025},
  doi = {10.1102/1470-7330.2013.0023},
  urldate = {2024-08-21},
  abstract = {Gastric carcinoma (GC) is one of the most common causes of cancer-related death worldwide. Surgical resection is the only cure available and is dependent on the GC stage at presentation, which incorporates depth of tumor invasion, extent of lymph node and distant metastases. Accurate preoperative staging is therefore essential for optimal surgical management with consideration of preoperative and/or postoperative chemotherapy. Multidetector computed tomography (MDCT) with its ability to assess tumor depth, nodal disease and metastases is the preferred technique for staging GC. Endoscopic ultrasonography is more accurate for assessing the depth of wall invasion in early cancer, but is limited in the assessment of advanced local or stenotic cancer and detection of distant metastases. Magnetic resonance imaging (MRI), although useful for staging, is not proven to be effective. Positron emission tomography (PET) is most useful for detecting and characterizing distant metastases. Both MDCT and PET are useful for assessment of treatment response following preoperative chemotherapy and for detection of recurrence after surgical resection. This review article discusses the usefulness of imaging modalities for detecting, staging and assessing treatment response for GC and the potential role of newer applications including CT volumetry, virtual gastroscopy and perfusion CT in the management of GC.},
  pmcid = {PMC3667568},
  pmid = {23722535}
}

@article{hammerEthicalConsiderationsWhen2017,
  title = {Ethical {{Considerations When Using Social Media}} for {{Research}}},
  author = {Hammer, Marilyn J. and {link will open in a new window Link to external site}, this},
  year = {2017},
  journal = {Oncology nursing forum},
  volume = {44},
  number = {4},
  pages = {410--412},
  doi = {http://dx.doi.org.ezproxy.lib.uts.edu.au/10.1188/17.ONF.410-412},
  urldate = {2021-08-10},
  abstract = {Because of its adaptation across age groups and populations, social media is being used as a venue for the conduction of research studies. The implications for use of social media to streamline data collection and analyses to understand epidemiologic effects of disease are intriguing. Public access to personalized Internet-based searches and conversations for patients with or at risk for cancer can potentially allow providers to target individuals for earlier interventions and improved outcomes. Although publicly posted, the use of personal information to solicit research participants, implement interventions, or abstract information for research studies raises questions regarding maintaining the ethical conduct of research.}
}

@misc{hasanSecurityPrivacyIssues2023,
  title = {Security and {{Privacy Issues}} of {{Federated Learning}}},
  author = {Hasan, Jahid},
  year = {2023},
  month = jul,
  number = {arXiv:2307.12181},
  eprint = {2307.12181},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.12181},
  urldate = {2024-09-06},
  abstract = {Federated Learning (FL) has emerged as a promising approach to address data privacy and confidentiality concerns by allowing multiple participants to construct a shared model without centralizing sensitive data. However, this decentralized paradigm introduces new security challenges, necessitating a comprehensive identification and classification of potential risks to ensure FL's security guarantees. This paper presents a comprehensive taxonomy of security and privacy challenges in Federated Learning (FL) across various machine learning models, including large language models. We specifically categorize attacks performed by the aggregator and participants, focusing on poisoning attacks, backdoor attacks, membership inference attacks, generative adversarial network (GAN) based attacks, and differential privacy attacks. Additionally, we propose new directions for future research, seeking innovative solutions to fortify FL systems against emerging security risks and uphold sensitive data confidentiality in distributed learning environments.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security},
  file = {/home/james/Zotero/storage/QRDRI89D/Hasan - 2023 - Security and Privacy Issues of Federated Learning.pdf}
}

@article{hassanResidualBasedMultiStageDeep2024,
  title = {Residual-{{Based Multi-Stage Deep Learning Framework}} for {{Computer-Aided Alzheimer}}'s {{Disease Detection}}},
  author = {Hassan, Najmul and Miah, Abu Saleh Musa and Shin, Jungpil},
  year = {2024},
  journal = {Journal of Imaging},
  volume = {10},
  number = {6},
  pages = {141},
  publisher = {MDPI AG},
  address = {Basel, Switzerland},
  doi = {10.3390/jimaging10060141},
  urldate = {2024-10-22},
  abstract = {Alzheimer's Disease (AD) poses a significant health risk globally, particularly among the elderly population. Recent studies underscore its prevalence, with over 50\% of elderly Japanese facing a lifetime risk of dementia, primarily attributed to AD. As the most prevalent form of dementia, AD gradually erodes brain cells, leading to severe neurological decline. In this scenario, it is important to develop an automatic AD-detection system, and many researchers have been working to develop an AD-detection system by taking advantage of the advancement of deep learning (DL) techniques, which have shown promising results in various domains, including medical image analysis. However, existing approaches for AD detection often suffer from limited performance due to the complexities associated with training hierarchical convolutional neural networks (CNNs). In this paper, we introduce a novel multi-stage deep neural network architecture based on residual functions to address the limitations of existing AD-detection approaches. Inspired by the success of residual networks (ResNets) in image-classification tasks, our proposed system comprises five stages, each explicitly formulated to enhance feature effectiveness while maintaining model depth. Following feature extraction, a deep learning-based feature-selection module is applied to mitigate overfitting, incorporating batch normalization, dropout and fully connected layers. Subsequently, machine learning (ML)-based classification algorithms, including Support Vector Machines (SVM), Random Forest (RF) and SoftMax, are employed for classification tasks. Comprehensive evaluations conducted on three benchmark datasets, namely ADNI1: Complete 1Yr 1.5T, MIRAID and OASIS Kaggle, demonstrate the efficacy of our proposed model. Impressively, our model achieves accuracy rates of 99.47\%, 99.10\% and 99.70\% for ADNI1: Complete 1Yr 1.5T, MIRAID and OASIS datasets, respectively, outperforming existing systems in binary class problems. Our proposed model represents a significant advancement in the AD-analysis domain.},
  copyright = {{\copyright} 2024 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
  langid = {english},
  keywords = {Accuracy,Algorithms,Alzheimer's disease,Artificial neural networks,Classification,CNN,Cognition & reasoning,Cognitive ability,Datasets,Deep learning,Dementia,Efficiency,Feature extraction,Image analysis,Image classification,machine learning,Machine learning,Medical imaging,Neural networks,Older people,Random Forest,Researchers,residual network,Support vector machines},
  file = {/home/james/Zotero/storage/NY6WSFAW/Hassan et al. - 2024 - Residual-Based Multi-Stage Deep Learning Framework for Computer-Aided Alzheimers Disease Detection.pdf}
}

@article{hatherellNationalSecurityInformation2020,
  title = {National Security, Information and Ideas: {{Time}} to Think about Ideational Power},
  shorttitle = {National Security, Information and Ideas},
  author = {Hatherell, Michael and Mansted, Katherine and Guan, Jade},
  year = {2020},
  journal = {Australian Journal of Defence and Strategic Studies},
  volume = {2},
  number = {1 202},
  pages = {125--137},
  publisher = {Department of Defence, Copyright Commonwealth of Australia},
  issn = {2652-3736 (Online) {\textbackslash}textbar 2652-3728 (Print)},
  urldate = {2021-07-07},
  abstract = {The ability to shape ideas is a form of power that can change the beliefs and thus the behaviour of others. In this paper, the authors contend that Australia needs to appreciate the power of ideas if it is to learn how it can leverage its own ideational power in a strategic and ethical manner.}
}

@article{hauptCharacterizingTwitterUser2021,
  title = {Characterizing {{Twitter User Topics}} and {{Communication Network Dynamics}} of the ``{{Liberate}}'' {{Movement}} during {{COVID-19 Using Unsupervised Machine Learning}} and {{Social Network Analysis}}},
  author = {Haupt, Michael Robert and {Jinich-Diamant}, Alex and Li, Jiawei and Nali, Matthew and Mackey, Tim K.},
  year = {2021},
  month = jan,
  journal = {Online Social Networks and Media},
  volume = {21},
  pages = {100114},
  issn = {2468-6964},
  doi = {10.1016/j.osnem.2020.100114},
  urldate = {2021-08-23},
  abstract = {This paper analyzes online user conversation topics and discourse on Twitter related to the ``Liberate'' Protest movement in reaction to social distancing guidelines at the early stages of the COVID-19 pandemic. Interdisciplinary approaches in big data, machine learning, content analysis, and social network analysis (SNA) were used to characterize the communicative behavior, conversation themes, and network structures of Liberate protest supporters and non-supporters. Tweets were content coded and grouped within topic clusters produced from an unsupervised machine learning algorithm using natural language processing. An analysis of topic clusters found that tweets that support the protests are highly concentrated and have higher volumes of replicated tweets. Protest Supporters were also more likely to retweet other users while Non-Supporters were more likely to include a URL from an outside media source and produce a unique tweet. SNA was also used to assess the characteristics of retweet networks and found that the Protester Supporter network had a more centralized structure and was strongly influenced by a political organization, in contrast to the Non-Supporter network that had a larger number of smaller and more evenly-sized nodes and more driven by media personalities and commentators. Collectively, these characteristics indicate that protest supporters had more centralized, consistent and disseminated discourse protesting COVID-19 social distancing requirements compared to non-supporters who were more diverse in their criticism of the Liberate movement and generally more fragmented in their support of public health measures. Results from this study provide important insights into pandemic communication dynamics of opposing twitter communities, including in the context of those who oppose and support public health measures in a highly politicized social and online environment. Results are important in the context of assessing the messages, communication propagation and overall activities of social media communities in response to basic public health measures needed to contain this post-digital era global pandemic.},
  keywords = {COVID-19,Machine learning,Political discourse,Social network analysis,Twitter}
}

@inproceedings{heDeepResidualLearning2016,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  booktitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year = {2016},
  month = jun,
  pages = {770--778},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2016.90},
  urldate = {2024-09-04},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8{\texttimes} deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  keywords = {Complexity theory,Degradation,Image recognition,Image segmentation,Neural networks,Training,Visualization},
  file = {/home/james/Zotero/storage/3FUTX2ZJ/He et al. - 2016 - Deep Residual Learning for Image Recognition.pdf;/home/james/Zotero/storage/MXNCYN9E/7780459.html}
}

@inproceedings{heDeepResidualLearning2016a,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  booktitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year = {2016},
  month = jun,
  pages = {770--778},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2016.90},
  urldate = {2024-09-04},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8{\texttimes} deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  keywords = {Complexity theory,Degradation,Image recognition,Image segmentation,Neural networks,Training,Visualization},
  file = {/home/james/Zotero/storage/SWQ84E3Y/He et al. - 2016 - Deep Residual Learning for Image Recognition.pdf}
}

@article{hirasawaApplicationArtificialIntelligence2018,
  title = {Application of Artificial Intelligence Using a Convolutional Neural Network for Detecting Gastric Cancer in Endoscopic Images},
  author = {Hirasawa, Toshiaki and Aoyama, Kazuharu and Tanimoto, Tetsuya and Ishihara, Soichiro and Shichijo, Satoki and Ozawa, Tsuyoshi and Ohnishi, Tatsuya and Fujishiro, Mitsuhiro and Matsuo, Keigo and Fujisaki, Junko and Tada, Tomohiro},
  year = {2018},
  month = jul,
  journal = {Gastric Cancer: Official Journal of the International Gastric Cancer Association and the Japanese Gastric Cancer Association},
  volume = {21},
  number = {4},
  pages = {653--660},
  issn = {1436-3305},
  doi = {10.1007/s10120-018-0793-2},
  abstract = {BACKGROUND: Image recognition using artificial intelligence with deep learning through convolutional neural networks (CNNs) has dramatically improved and been increasingly applied to medical fields for diagnostic imaging. We developed a CNN that can automatically detect gastric cancer in endoscopic images. METHODS: A CNN-based diagnostic system was constructed based on Single Shot MultiBox Detector architecture and trained using 13,584 endoscopic images of gastric cancer. To evaluate the diagnostic accuracy, an independent test set of 2296 stomach images collected from 69 consecutive patients with 77 gastric cancer lesions was applied to the constructed CNN. RESULTS: The CNN required 47~s to analyze 2296 test images. The CNN correctly diagnosed 71 of 77 gastric cancer lesions with an overall sensitivity of 92.2\%, and 161 non-cancerous lesions were detected as gastric cancer, resulting in a positive predictive value of 30.6\%. Seventy of the 71 lesions (98.6\%) with a diameter of 6~mm or more as well as all invasive cancers were correctly detected. All missed lesions were superficially depressed and differentiated-type intramucosal cancers that were difficult to distinguish from gastritis even for experienced endoscopists. Nearly half of the false-positive lesions were gastritis with changes in color tone or an irregular mucosal surface. CONCLUSION: The constructed CNN system for detecting gastric cancer could process numerous stored endoscopic images in a very short time with a clinically relevant diagnostic ability. It may be well applicable to daily clinical practice to reduce the burden of endoscopists.},
  langid = {english},
  pmid = {29335825},
  keywords = {Adult,Aged,Aged 80 and over,Artificial intelligence,Artificial Intelligence,Endoscopy,Endoscopy Gastrointestinal,Female,Humans,Image Processing Computer-Assisted,Male,Middle Aged,Neural networks (computer),Neural Networks Computer,Stomach neoplasms,Stomach Neoplasms},
  file = {/home/james/Zotero/storage/JN5RFPR9/Hirasawa et al. - 2018 - Application of artificial intelligence using a convolutional neural network for detecting gastric ca.pdf}
}

@article{hirasawaApplicationArtificialIntelligence2018a,
  title = {Application of Artificial Intelligence Using a Convolutional Neural Network for Detecting Gastric Cancer in Endoscopic Images},
  author = {Hirasawa, Toshiaki and Aoyama, Kazuharu and Tanimoto, Tetsuya and Ishihara, Soichiro and Shichijo, Satoki and Ozawa, Tsuyoshi and Ohnishi, Tatsuya and Fujishiro, Mitsuhiro and Matsuo, Keigo and Fujisaki, Junko and Tada, Tomohiro},
  year = {2018},
  month = jul,
  journal = {Gastric Cancer},
  volume = {21},
  number = {4},
  pages = {653--660},
  issn = {1436-3291, 1436-3305},
  doi = {10.1007/s10120-018-0793-2},
  urldate = {2024-09-08},
  langid = {english},
  file = {/home/james/Zotero/storage/2I6ZCB5R/Hirasawa et al. - 2018 - Application of artificial intelligence using a convolutional neural network for detecting gastric ca.pdf}
}

@article{hirasawaCoagulationSyndromeDelayed2015,
  title = {Coagulation Syndrome: {{Delayed}} Perforation after Colorectal Endoscopic Treatments},
  shorttitle = {Coagulation Syndrome},
  author = {Hirasawa, Kingo and Sato, Chiko and Makazu, Makomo and Kaneko, Hiroaki and Kobayashi, Ryosuke and Kokawa, Atsushi and Maeda, Shin},
  year = {2015},
  month = sep,
  journal = {World Journal of Gastrointestinal Endoscopy},
  volume = {7},
  number = {12},
  pages = {1055--1061},
  issn = {1948-5190},
  doi = {10.4253/wjge.v7.i12.1055},
  urldate = {2024-09-06},
  abstract = {Various procedure-related adverse events related to colonoscopic treatment have been reported. Previous studies on the complications of colonoscopic treatment have focused primarily on perforation or bleeding. Coagulation syndrome (CS), which is synonymous with transmural burn syndrome following endoscopic treatment, is another typical adverse event. CS is the result of electrocoagulation injury to the bowel wall that induces a transmural burn and localized peritonitis resulting in serosal inflammation. CS occurs after polypectomy, endoscopic mucosal resection (EMR), and even endoscopic submucosal dissection (ESD). The occurrence of CS after polypectomy or EMR varies according previous reports; most report an occurrence rate around 1\%. However, artificial ulcers after ESD are largely theoretical, and CS following ESD was reported in about 9\% of cases, which is higher than that for CS after polypectomy or EMR. Most cases of post-polypectomy syndrome (PPS) have an excellent prognosis, and they are managed conservatively with medical therapy. PPS rarely develops into delayed perforation. Delayed perforation is a severe adverse event that often requires emergency surgery. Since few studies have reported on CS and delayed perforation associated with CS, we focused on CS after colonoscopic treatments in this review. Clinicians should consider delayed perforation in CS patients.},
  pmcid = {PMC4564832},
  pmid = {26380051},
  file = {/home/james/Zotero/storage/2VEBEK9X/Hirasawa et al. - 2015 - Coagulation syndrome Delayed perforation after colorectal endoscopic treatments.pdf}
}

@misc{hobbesAnswerAreThere2016,
  title = {Answer to "{{Are}} There Any Image Classification Algorithms Which Are Not Neural Networks?"},
  shorttitle = {Answer to "{{Are}} There Any Image Classification Algorithms Which Are Not Neural Networks?},
  author = {Hobbes},
  year = {2016},
  month = aug,
  journal = {Data Science Stack Exchange},
  urldate = {2024-09-04},
  file = {/home/james/Zotero/storage/KZ3XM7IR/are-there-any-image-classification-algorithms-which-are-not-neural-networks.html}
}

@book{hoferUncertaintyAnalysisModel2018,
  title = {The {{Uncertainty Analysis}} of {{Model Results}}: {{A Practical Guide}}},
  shorttitle = {The {{Uncertainty Analysis}} of {{Model Results}}},
  author = {Hofer, Eduard},
  year = {2018},
  publisher = {Springer International Publishing AG},
  address = {Cham},
  abstract = {This book is a practical guide to the uncertainty analysis of computer model applications. Used in many areas, such as engineering, ecology, economics, computer models are subject to various uncertainties at the level of model formulations, parameter values and input data.},
  isbn = {978-3-319-76296-8},
  keywords = {Computer simulation,Mathematical models,Statistics}
}

@misc{howardSearchingMobileNetV32019,
  title = {Searching for {{MobileNetV3}}},
  author = {Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and Le, Quoc V. and Adam, Hartwig},
  year = {2019},
  month = nov,
  number = {arXiv:1905.02244},
  publisher = {arXiv},
  urldate = {2024-04-15},
  abstract = {We present the next generation of MobileNets based on a combination of complementary search techniques as well as a novel architecture design. MobileNetV3 is tuned to mobile phone CPUs through a combination of hardware-aware network architecture search (NAS) complemented by the NetAdapt algorithm and then subsequently improved through novel architecture advances. This paper starts the exploration of how automated search algorithms and network design can work together to harness complementary approaches improving the overall state of the art. Through this process we create two new MobileNet models for release: MobileNetV3-Large and MobileNetV3-Small which are targeted for high and low resource use cases. These models are then adapted and applied to the tasks of object detection and semantic segmentation. For the task of semantic segmentation (or any dense pixel prediction), we propose a new efficient segmentation decoder Lite Reduced Atrous Spatial Pyramid Pooling (LR-ASPP). We achieve new state of the art results for mobile classification, detection and segmentation. MobileNetV3-Large is 3.2{\textbackslash}textbackslash\% more accurate on ImageNet classification while reducing latency by 15{\textbackslash}textbackslash\% compared to MobileNetV2. MobileNetV3-Small is 4.6{\textbackslash}textbackslash\% more accurate while reducing latency by 5{\textbackslash}textbackslash\% compared to MobileNetV2. MobileNetV3-Large detection is 25{\textbackslash}textbackslash\% faster at roughly the same accuracy as MobileNetV2 on COCO detection. MobileNetV3-Large LR-ASPP is 30{\textbackslash}textbackslash\% faster than MobileNetV2 R-ASPP at similar accuracy for Cityscapes segmentation.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{huangAccurateDiagnosisPrognosis2021,
  title = {Accurate {{Diagnosis}} and {{Prognosis Prediction}} of {{Gastric Cancer Using Deep Learning}} on {{Digital Pathological Images}}: {{A Retrospective Multicentre Study}}},
  shorttitle = {Accurate {{Diagnosis}} and {{Prognosis Prediction}} of {{Gastric Cancer Using Deep Learning}} on {{Digital Pathological Images}}},
  author = {Huang, Binglu and Tian, Shan and Zhan, Na and Ma, Jingjing and Huang, Zhiwei and Zhang, Chukang and Zhang, Hao and Ming, Fanhua and Liao, Fei and Ji, Mengyao and Zhang, Jixiang and Liu, Yinghui and He, Pengzhan and Deng, Beiying and Hu, Jiaming and Dong, Weiguo},
  year = {2021},
  month = nov,
  journal = {EBioMedicine},
  volume = {73},
  pages = {103631},
  issn = {23523964},
  doi = {10.1016/j.ebiom.2021.103631},
  urldate = {2024-08-14},
  abstract = {Background: To reduce the high incidence and mortality of gastric cancer (GC), we aimed to develop deep learning-based models to assist in predicting the diagnosis and overall survival (OS) of GC patients using pathological images.},
  keywords = {Deep learning,Diagnosis,Gastric cancer,Multiple instance learning,Overall survival}
}

@misc{huangDenselyConnectedConvolutional2018,
  title = {Densely {{Connected Convolutional Networks}}},
  author = {Huang, Gao and Liu, Zhuang and {van der Maaten}, Laurens and Weinberger, Kilian Q.},
  year = {2018},
  month = jan,
  number = {arXiv:1608.06993},
  publisher = {arXiv},
  urldate = {2024-05-16},
  abstract = {Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections - one between each layer and its subsequent layer - our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/DenseNet .},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
}

@misc{huComparativeStudyGastric2022,
  title = {A {{Comparative Study}} of {{Gastric Histopathology Sub-size Image Classification}}: From {{Linear Regression}} to {{Visual Transformer}}},
  shorttitle = {A {{Comparative Study}} of {{Gastric Histopathology Sub-size Image Classification}}},
  author = {Hu, Weiming and Chen, Haoyuan and Liu, Wanli and Li, Xiaoyan and Sun, Hongzan and Huang, Xinyu and Grzegorzek, Marcin and Li, Chen},
  year = {2022},
  month = may,
  number = {arXiv:2205.12843},
  eprint = {2205.12843},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2205.12843},
  urldate = {2024-10-22},
  abstract = {Gastric cancer is the fifth most common cancer in the world. At the same time, it is also the fourth most deadly cancer. Early detection of cancer exists as a guide for the treatment of gastric cancer. Nowadays, computer technology has advanced rapidly to assist physicians in the diagnosis of pathological pictures of gastric cancer. Ensemble learning is a way to improve the accuracy of algorithms, and finding multiple learning models with complementarity types is the basis of ensemble learning. The complementarity of sub-size pathology image classifiers when machine performance is insufficient is explored in this experimental platform. We choose seven classical machine learning classifiers and four deep learning classifiers for classification experiments on the GasHisSDB database. Among them, classical machine learning algorithms extract five different image virtual features to match multiple classifier algorithms. For deep learning, we choose three convolutional neural network classifiers. In addition, we also choose a novel Transformer-based classifier. The experimental platform, in which a large number of classical machine learning and deep learning methods are performed, demonstrates that there are differences in the performance of different classifiers on GasHisSDB. Classical machine learning models exist for classifiers that classify Abnormal categories very well, while classifiers that excel in classifying Normal categories also exist. Deep learning models also exist with multiple models that can be complementarity. Suitable classifiers are selected for ensemble learning, when machine performance is insufficient. This experimental platform demonstrates that multiple classifiers are indeed complementarity and can improve the efficiency of ensemble learning. This can better assist doctors in diagnosis, improve the detection of gastric cancer, and increase the cure rate.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/home/james/Zotero/storage/BV3G2AD6/Hu et al. - 2022 - A Comparative Study of Gastric Histopathology Sub-size Image Classification from Linear Regression.pdf;/home/james/Zotero/storage/UM4A72MK/2205.html}
}

@article{huGasHisSDBNewGastric,
  title = {{{GasHisSDB}}: {{A New Gastric Histopathology Image Dataset}} for {{Computer Aided Diagnosis}} of {{Gastric Cancer}}},
  author = {Hu, Weiming and Li, Chen and Li, Xiaoyan},
  abstract = {Background and Objective: Gastric cancer has turned out to be the fifth most common cancer globally, and early detection of gastric cancer is essential to save lives. Histopathological examination of gastric cancer is the gold standard for the diagnosis of gastric cancer. However, computer-aided diagnostic techniques are challenging to evaluate due to the scarcity of publicly available gastric histopathology image datasets. Methods: In this paper, a noble publicly available Gastric Histopathology Sub-size Image Database (GasHisSDB) is published to identify classifiers' performance. Specifically, two types of data are included: normal and abnormal, with a total of 245,196 tissue case images. In order to prove that the methods of different periods in the field of image classification have discrepancies on GasHisSDB, we select a variety of classifiers for evaluation. Seven classical machine learning classifiers, three Convolutional Neural Network classifiers, and a novel transformer-based classifier are selected for testing on image classification tasks. Results: This study performed extensive experiments using traditional machine learning and deep learning methods to prove that the methods of different periods have discrepancies on GasHisSDB. Traditional machine learning achieved the best accuracy rate of 86.08\% and a minimum of just 41.12\%. The best accuracy of deep learning reached 96.47\% and the lowest was 86.21\%. Accuracy rates vary significantly across classifiers. Conclusions: To the best of our knowledge, it is the first publicly available gastric cancer histopathology dataset containing a large number of images for weakly supervised learning. We believe that GasHisSDB can attract researchers to explore new algorithms for the automated diagnosis of gastric cancer, which can help physicians and patients in the clinical setting.},
  langid = {english},
  file = {/home/james/Zotero/storage/VKHI3TPA/Hu et al. - GasHisSDB A New Gastric Histopathology Image Dataset for Computer Aided Diagnosis of Gastric Cancer.pdf}
}

@misc{huGasHisSDBNewGastric2021,
  title = {{{GasHisSDB}}: {{A New Gastric Histopathology Image Dataset}} for {{Computer Aided Diagnosis}} of {{Gastric Cancer}}},
  shorttitle = {{{GasHisSDB}}},
  author = {Hu, Weiming and Li, Chen and Li, Xiaoyan and Rahaman, Md Mamunur and Ma, Jiquan and Zhang, Yong and Chen, Haoyuan and Liu, Wanli and Sun, Changhao and Yao, Yudong and Sun, Hongzan and Grzegorzek, Marcin},
  year = {2021},
  month = nov,
  number = {arXiv:2106.02473},
  eprint = {2106.02473},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-09-06},
  abstract = {Background and Objective: Gastric cancer has turned out to be the fifth most common cancer globally, and early detection of gastric cancer is essential to save lives. Histopathological examination of gastric cancer is the gold standard for the diagnosis of gastric cancer. However, computer-aided diagnostic techniques are challenging to evaluate due to the scarcity of publicly available gastric histopathology image datasets. Methods: In this paper, a noble publicly available Gastric Histopathology Sub-size Image Database (GasHisSDB) is published to identify classifiers' performance. Specifically, two types of data are included: normal and abnormal, with a total of 245,196 tissue case images. In order to prove that the methods of different periods in the field of image classification have discrepancies on GasHisSDB, we select a variety of classifiers for evaluation. Seven classical machine learning classifiers, three Convolutional Neural Network classifiers, and a novel transformer-based classifier are selected for testing on image classification tasks. Results: This study performed extensive experiments using traditional machine learning and deep learning methods to prove that the methods of different periods have discrepancies on GasHisSDB. Traditional machine learning achieved the best accuracy rate of 86.08\% and a minimum of just 41.12\%. The best accuracy of deep learning reached 96.47\% and the lowest was 86.21\%. Accuracy rates vary significantly across classifiers. Conclusions: To the best of our knowledge, it is the first publicly available gastric cancer histopathology dataset containing a large number of images for weakly supervised learning. We believe that GasHisSDB can attract researchers to explore new algorithms for the automated diagnosis of gastric cancer, which can help physicians and patients in the clinical setting.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/james/Zotero/storage/REMG5UXX/Hu et al. - 2021 - GasHisSDB A New Gastric Histopathology Image Dataset for Computer Aided Diagnosis of Gastric Cancer.pdf}
}

@article{huGasHisSDBNewGastric2022,
  title = {{{GasHisSDB}}: {{A}} New Gastric Histopathology Image Dataset for Computer Aided Diagnosis of Gastric Cancer},
  shorttitle = {{{GasHisSDB}}},
  author = {Hu, Weiming and Li, Chen and Li, Xiaoyan and Rahaman, Md Mamunur and Ma, Jiquan and Zhang, Yong and Chen, Haoyuan and Liu, Wanli and Sun, Changhao and Yao, Yudong and Sun, Hongzan and Grzegorzek, Marcin},
  year = {2022},
  month = mar,
  journal = {Computers in Biology and Medicine},
  volume = {142},
  pages = {105207},
  issn = {0010-4825},
  doi = {10.1016/j.compbiomed.2021.105207},
  urldate = {2024-09-07},
  abstract = {Background and objective Gastric cancer is the fifth most common cancer globally, and early detection of gastric cancer is essential to save lives. Histopathological examination of gastric cancer is the gold standard for the diagnosis of gastric cancer. However, computer-aided diagnostic techniques are challenging to evaluate due to the scarcity of publicly available gastric histopathology image datasets. Methods In this paper, a noble publicly available Gastric Histopathology Sub-size Image Database (GasHisSDB) is published to identify classifiers' performance. Specifically, two types of data are included: normal and abnormal, with a total of 245,196 tissue case images. In order to prove that the methods of different periods in the field of image classification have discrepancies on GasHisSDB, we select a variety of classifiers for evaluation. Seven classical machine learning classifiers, three Convolutional Neural Network classifiers, and a novel transformer-based classifier are selected for testing on image classification tasks. Results This study performed extensive experiments using traditional machine learning and deep learning methods to prove that the methods of different periods have discrepancies on GasHisSDB. Traditional machine learning achieved the best accuracy rate of 86.08\% and a minimum of just 41.12\%. The best accuracy of deep learning reached 96.47\% and the lowest was 86.21\%. Accuracy rates vary significantly across classifiers. Conclusions To the best of our knowledge, it is the first publicly available gastric cancer histopathology dataset containing a large number of images for weakly supervised learning. We believe that GasHisSDB can attract researchers to explore new algorithms for the automated diagnosis of gastric cancer, which can help physicians and patients in the clinical setting.},
  keywords = {Database,Gastric histopathology,Image classification,Sub-size image},
  file = {/home/james/Zotero/storage/K6F3YI7R/Hu et al. - 2022 - GasHisSDB A new gastric histopathology image dataset for computer aided diagnosis of gastric cancer.pdf;/home/james/Zotero/storage/SQNN2SDP/S0010482521010015.html}
}

@article{huGastricCancerClassification2012,
  title = {Gastric {{Cancer}}: {{Classification}}, {{Histology}} and {{Application}} of {{Molecular Pathology}}},
  shorttitle = {Gastric {{Cancer}}},
  author = {Hu, Bing and El Hajj, Nassim and Sittler, Scott and Lammert, Nancy and Barnes, Robert and {Meloni-Ehrig}, Aurelia},
  year = {2012},
  month = sep,
  journal = {Journal of Gastrointestinal Oncology},
  volume = {3},
  number = {3},
  pages = {251--261},
  issn = {2078-6891},
  doi = {10.3978/j.issn.2078-6891.2012.021},
  urldate = {2024-08-14},
  abstract = {Gastric cancer remains one of the deadly diseases with poor prognosis. New classification of gastric cancers based on histologic features, genotypes and molecular phenotypes helps better understand the characteristics of each subtype, and improve early diagnosis, prevention and treatment. The objective of this article is to review the new classification of gastric cancers and the up-to-date guidance in the application of molecular testing.},
  pmcid = {PMC3418539},
  pmid = {22943016}
}

@incollection{hutchisonWhatDoesClassifying2010,
  title = {What {{Does Classifying More Than}} 10,000 {{Image Categories Tell Us}}?},
  booktitle = {Computer {{Vision}} -- {{ECCV}} 2010},
  author = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Deng, Jia and Berg, Alexander C. and Li, Kai and {Fei-Fei}, Li},
  editor = {Daniilidis, Kostas and Maragos, Petros and Paragios, Nikos},
  year = {2010},
  volume = {6315},
  pages = {71--84},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-15555-0_6},
  urldate = {2024-04-15},
  abstract = {Image classification is a critical task for both humans and computers. One of the challenges lies in the large scale of the semantic space. In particular, humans can recognize tens of thousands of object classes and scenes. No computer vision algorithm today has been tested at this scale. This paper presents a study of large scale categorization including a series of challenging experiments on classification with more than 10, 000 image classes. We find that a) computational issues become crucial in algorithm design; b) conventional wisdom from a couple of hundred image categories on relative performance of different classifiers does not necessarily hold when the number of categories increases; c) there is a surprisingly strong relationship between the structure of WordNet (developed for studying language) and the difficulty of visual categorization; d) classification can be improved by exploiting the semantic hierarchy. Toward the future goal of developing automatic vision algorithms to recognize tens of thousands or even millions of image categories, we make a series of observations and arguments about dataset scale, category density, and image hierarchy.},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-642-15554-3 978-3-642-15555-0}
}

@article{iacobucciSixtySecondsCovid2021,
  title = {Sixty {{Seconds}} on . . . {{Covid Influencers}}.},
  author = {Iacobucci, Gareth},
  year = {2021},
  journal = {BMJ (Clinical research ed.)},
  volume = {372},
  pages = {n151},
  doi = {http://dx.doi.org.ezproxy.lib.uts.edu.au/10.1136/bmj.n151},
  urldate = {2021-08-09}
}

@article{ikenoyamaDetectingEarlyGastric2021,
  title = {Detecting Early Gastric Cancer: {{Comparison}} between the Diagnostic Ability of Convolutional Neural Networks and Endoscopists},
  shorttitle = {Detecting Early Gastric Cancer},
  author = {Ikenoyama, Yohei and Hirasawa, Toshiaki and Ishioka, Mitsuaki and Namikawa, Ken and Yoshimizu, Shoichi and Horiuchi, Yusuke and Ishiyama, Akiyoshi and Yoshio, Toshiyuki and Tsuchida, Tomohiro and Takeuchi, Yoshinori and Shichijo, Satoki and Katayama, Naoyuki and Fujisaki, Junko and Tada, Tomohiro},
  year = {2021},
  month = jan,
  journal = {Digestive Endoscopy},
  volume = {33},
  number = {1},
  pages = {141--150},
  issn = {0915-5635},
  doi = {10.1111/den.13688},
  urldate = {2024-09-06},
  abstract = {Objectives Detecting early gastric cancer is difficult, and it may even be overlooked by experienced endoscopists. Recently, artificial intelligence based on deep learning through convolutional neural networks (CNNs) has enabled significant advancements in the field of gastroenterology. However, it remains unclear whether a CNN can outperform endoscopists. In this study, we evaluated whether the performance of a CNN in detecting early gastric cancer is better than that of endoscopists. Methods The CNN was constructed using 13,584 endoscopic images from 2639 lesions of gastric cancer. Subsequently, its diagnostic ability was compared to that of 67 endoscopists using an independent test dataset (2940 images from 140 cases). Results The average diagnostic time for analyzing 2940 test endoscopic images by the CNN and endoscopists were 45.5~{\textpm}~1.8~s and 173.0~{\textpm}~66.0~min, respectively. The sensitivity, specificity, and positive and negative predictive values for the CNN were 58.4\%, 87.3\%, 26.0\%, and 96.5\%, respectively. These values for the 67 endoscopists were 31.9\%, 97.2\%, 46.2\%, and 94.9\%, respectively. The CNN had a significantly higher sensitivity than the endoscopists (by 26.5\%; 95\% confidence interval, 14.9--32.5\%). Conclusion The CNN detected more early gastric cancer cases in a shorter time than the endoscopists. The CNN needs further training to achieve higher diagnostic accuracy. However, a diagnostic support tool for gastric cancer using a CNN will be realized in the near future.},
  pmcid = {PMC7818187},
  pmid = {32282110},
  file = {/home/james/Zotero/storage/U95YW83V/Ikenoyama et al. - 2021 - Detecting early gastric cancer Comparison between the diagnostic ability of convolutional neural ne.pdf}
}

@article{jangPresentFutureImageEnhanced2015,
  title = {The {{Past}}, {{Present}}, and {{Future}} of {{Image-Enhanced Endoscopy}}},
  author = {Jang, Jae-Young},
  year = {2015},
  month = nov,
  journal = {Clinical Endoscopy},
  volume = {48},
  number = {6},
  pages = {466--475},
  issn = {2234-2400},
  doi = {10.5946/ce.2015.48.6.466},
  urldate = {2024-08-21},
  abstract = {Despite the remarkable progress recently made to enhance the resolution of white-light endoscopy, detection, and diagnosis of premalignant lesions, such as adenomas and subtle early-stage cancers, remains a great challenge. As for example, although chromoendoscopy, such as endoscopy using indigo carmine, is useful for the early diagnosis of subtle lesions, the technique presents various disadvantages ranging from the time required for spray application of the dye and suctioning of excess dye to the increased difficulty in identifying lesions in the presence of severe inflammation and obstruction of visual field due to the pooling of solution in depressed-type lesions. To overcome these diagnostic problems associated with chromoendoscopy, research has focused on the development of endoscopes based on new optical technologies. Several types of image-enhanced endoscopy methods have recently been presented. In particular, image-enhanced endoscopy has emerged as a new paradigm for the diagnosis of gastrointestinal disorders. Image-enhanced endoscopes provide high-contrast images of lesions by means of optical or electronic technologies, including the contrast enhancement of the mucosal surface and of blood vessels. Chromoendoscopy, narrow-band imaging, i-SCAN, and flexible spectral imaging color enhancement are representative examples of image-enhanced endoscopy discussed in this paper.},
  pmcid = {PMC4676674},
  pmid = {26668791}
}

@article{jayaprakasamVariantsPitfallsPET2021,
  title = {Variants and {{Pitfalls}} in {{PET}}/{{CT Imaging}} of {{Gastrointestinal Cancers}}},
  author = {Jayaprakasam, Vetri Sudar and Paroder, Viktoriya and Sch{\"o}der, Heiko},
  year = {2021},
  month = sep,
  journal = {Seminars in nuclear medicine},
  volume = {51},
  number = {5},
  pages = {485--501},
  issn = {0001-2998},
  doi = {10.1053/j.semnuclmed.2021.04.001},
  urldate = {2024-08-23},
  abstract = {In the past two decades, PET/CT has become an essential modality in oncology increasingly used in the management of gastrointestinal (GI)cancers. Most PET/CT tracers used in clinical practice show some degree of GI uptake. This uptake is quite variable and knowledge of common patterns of biodistribution of various radiotracers is helpful in clinical practice. 18F-Fluoro-Deoxy-Glucose (FDG) is the most commonly used radiotracer and has quite a variable uptake within the bowel. 68Ga-Prostate specific membrane antigen (PSMA) shows intense uptake within the proximal small bowel loops. 11C-methyl-L-methionine (MET) shows high accumulation within the bowels, which makes it difficult to assess bowel or pelvic diseases. One must also be aware of technical artifacts causing difficulties in interpretations, such as high attenuation oral contrast material within the bowel lumen or misregistration artifact due to patient movements., It is imperative to know the common variants and benign diseases that can mimic malignant pathologies. Intense FDG uptake within the esophagus and stomach may be a normal variant or may be associated with benign conditions such as esophagitis, reflux disease, or gastritis. Metformin can cause diffuse intense uptake throughout the bowel loops. Intense physiologic uptake can also be seen within the anal canal. Segmental bowel uptake can be seen in inflammatory bowel disease, radiation, or medication induced enteritis/colitis or infection. Diagnosis of appendicitis or diverticular disease requires CT correlation, as normal appendix or diverticulum can show intense uptake., Certain malignant pathologies are known to have only low FDG uptake, such as early-stage esophageal adenocarcinoma, mucinous tumors, indolent lymphomas, and multicystic mesotheliomas. Response assessment, particularly in the neoadjuvant setting, can be limited by post-treatment inflammatory changes. Post-operative complications such as abscess or fistula formation can also show intense uptake and may obscure underlying malignant pathology. In the absence of clinical suspicion or rising tumor marker, the role of FDG PET/CT in routine surveillance of patients with GI malignancy is not clear.},
  pmcid = {PMC8338802},
  pmid = {33965198}
}

@book{jinFederatedLearningFundamentals2023,
  title = {Federated {{Learning}}: {{Fundamentals}} and {{Advances}}},
  shorttitle = {Federated {{Learning}}},
  author = {Jin, Yaochu and Zhu, Hangyu and Xu, Jinjin and Chen, Yang},
  year = {2023},
  series = {Machine {{Learning}}: {{Foundations}}, {{Methodologies}}, and {{Applications}}},
  publisher = {Springer Nature},
  address = {Singapore},
  doi = {10.1007/978-981-19-7083-2},
  urldate = {2024-10-22},
  copyright = {https://www.springer.com/tdm},
  isbn = {978-981-19708-2-5 978-981-19708-3-2},
  langid = {english},
  keywords = {Cryptology,Data Privacy,Federated Learning,Machine Learning,Neural Networks},
  file = {/home/james/Zotero/storage/XU768Y33/Jin et al. - 2023 - Federated Learning Fundamentals and Advances.pdf}
}

@book{johnsonLeadershipCommunicationPerspective2018,
  title = {Leadership: A Communication Perspective},
  shorttitle = {Leadership},
  author = {Johnson, Craig E. and Hackman, Michael Z.},
  year = {2018},
  edition = {Seventh edition},
  publisher = {Waveland Press},
  address = {Long Grove, Illinois},
  abstract = {Leadership: A Communication Perspective has been at the forefront of university and college leadership courses for nearly three decades, providing a compelling, authoritative introduction to leadership as a communication-based activity. The new edition continues the tradition of excellence with an up-to-date treatment of theory and research combined with practical, real-world advice for improving communication competence and leadership effectiveness. The authors profile contemporary leaders and organizations like Alibaba's Jack Ma, Zappos' Tony Hsieh, Facebook's Sheryl Sandberg, Uber, The Container Store, Airbnb, Chipotle, the Waffle House, Nordstrom, and Google. Their presentation balances current scholarship and trends with historical perspectives to provide a fuller understanding of the study and practice of leadership. Leadership and followership are examined in multiple contexts, including organizational leadership, public leadership, and leadership in groups and teams. Topics new to this edition include transcendent followership, the leadership skills approach, team coaching, escalation of commitment, invisible leadership, cultural intelligence, trigger events, and resilience},
  isbn = {978-1-4786-3502-4},
  langid = {english},
  annotation = {OCLC: 1020456081}
}

@inproceedings{joshiImageCaptioningUsing2024,
  title = {Image {{Captioning Using CNN-LSTM}}},
  booktitle = {Advances in {{Communication}} and {{Applications}}},
  author = {Joshi, Akshay and Kalal, Kartik and Bhandare, Dhiraj and Patil, Vaishnavi and Kulkarni, Uday and Meena, S. M.},
  editor = {Shetty, N. R. and Prasad, N. H. and Nagaraj, H. C.},
  year = {2024},
  pages = {421--433},
  publisher = {Springer Nature},
  address = {Singapore},
  doi = {10.1007/978-981-99-7633-1_32},
  abstract = {We regularly encounter a large number of images from various fields such as news articles, diagrams, literature, and the Internet. Even though several images do not have a description, humans have the capability to understand them without their captions but this is not the case with machines. As long as machines do not behave, think, and talk like humans, natural language descriptions will be challenging to solve. Although image captioning is a challenging undertaking, numerous researchers have made substantial advancements. Image captioning is the task of automatically generating a textual description of an image. This technology has significant potential for a range of applications, including assistive technologies for visually impaired individuals, content-based image retrieval, and personalized recommendation systems. In this work, CNN-LSTM model is used to generate captions for images by processing its features. This paper mainly describes an image captioning method using a deep learning approach, a combination of LSTM and Xception model, which shows representative work of the model. Xception is used to extract the high-level features of the images. The extracted features alongside the image captions are fed as input to the LSTM which generates the most appropriate caption for the given image. In this work, the model is evaluated using BLEU score, a standard metric that is used for evaluating machine-translated text. This will summarize the images without any human intervention.},
  isbn = {978-981-9976-33-1},
  keywords = {BLEU score,CNN,Deep learning,Image captioning,LSTM,Xception}
}

@inproceedings{jouppiTPUV4Optically2023,
  title = {{{TPU}} v4: {{An Optically Reconfigurable Supercomputer}} for {{Machine Learning}} with {{Hardware Support}} for {{Embeddings}}},
  shorttitle = {{{TPU V4}}},
  booktitle = {Proceedings of the 50th {{Annual International Symposium}} on {{Computer Architecture}}},
  author = {Jouppi, Norm and Kurian, George and Li, Sheng and Ma, Peter and Nagarajan, Rahul and Nai, Lifeng and Patil, Nishant and Subramanian, Suvinay and Swing, Andy and Towles, Brian and Young, Clifford and Zhou, Xiang and Zhou, Zongwei and Patterson, David A},
  year = {2023},
  month = jun,
  pages = {1--14},
  publisher = {ACM},
  address = {Orlando FL USA},
  doi = {10.1145/3579371.3589350},
  urldate = {2024-04-27},
  abstract = {In response to innovations in machine learning (ML) models, production workloads changed radically and rapidly. TPU v4 is the fifth Google domain specific architecture (DSA) and its third supercomputer for such ML models. Optical circuit switches (OCSes) dynamically reconfigure its interconnect topology to improve scale, availability, utilization, modularity, deployment, security, power, and performance; users can pick a twisted 3D torus topology if desired. Much cheaper, lower power, and faster than Infiniband, OCSes and underlying optical components are {$<$}5\% of system cost and {$<$}3\% of system power. Each TPU v4 includes SparseCores, dataflow processors that accelerate models that rely on embeddings by 5x--7x yet use only 5\% of die area and power. Deployed since 2020, TPU v4 outperforms TPU v3 by 2.1x and improves performance/Watt by 2.7x. The TPU v4 supercomputer is 4x larger at 4096 chips and thus nearly 10x faster overall, which along with OCS flexibility and availability allows a large language model to train at an average of {\textbackslash}textasciitilde60\% of peak FLOPS/second. For similar sized systems, it is {\textbackslash}textasciitilde4.3x--4.5x faster than the Graphcore IPU Bow and is 1.2x--1.7x faster and uses 1.3x--1.9x less power than the Nvidia A100. TPU v4s inside the energy-optimized warehouse scale computers of Google Cloud use {\textbackslash}textasciitilde2-6x less energy and produce {\textbackslash}textasciitilde20x less CO2e than contemporary DSAs in typical on-premise data centers.},
  isbn = {9798400700958}
}

@article{kalraDecentralizedFederatedLearning2023,
  title = {Decentralized Federated Learning through Proxy Model Sharing},
  author = {Kalra, Shivam and Wen, Junfeng and Cresswell, Jesse C. and Volkovs, Maksims and Tizhoosh, H. R.},
  year = {2023},
  journal = {Nature Communications},
  volume = {14},
  number = {1},
  pages = {2899},
  publisher = {Nature Publishing Group},
  address = {London, United States},
  doi = {10.1038/s41467-023-38569-4},
  urldate = {2024-10-23},
  abstract = {Institutions in highly regulated domains such as finance and healthcare often have restrictive rules around data sharing. Federated learning is a distributed learning framework that enables multi-institutional collaborations on decentralized data with improved protection for each collaborator's data privacy. In this paper, we propose a communication-efficient scheme for decentralized federated learning called ProxyFL, or proxy-based federated learning. Each participant in ProxyFL maintains two models, a private model, and a publicly shared proxy model designed to protect the participant's privacy. Proxy models allow efficient information exchange among participants without the need of a centralized server. The proposed method eliminates a significant limitation of canonical federated learning by allowing model heterogeneity; each participant can have a private model with any architecture. Furthermore, our protocol for communication by proxy leads to stronger privacy guarantees using differential privacy analysis. Experiments on popular image datasets, and a cancer diagnostic problem using high-quality gigapixel histology whole slide images, show that ProxyFL can outperform existing alternatives with much less communication overhead and stronger privacy. Federated learning enables multi-institutional collaborations on decentralized data with improved privacy protection. Here, authors propose a new scheme for decentralized federated learning with much less communication overhead and stronger privacy.},
  copyright = {{\copyright} The Author(s) 2023. This work is published under http://creativecommons.org/licenses/by/4.0/ (the~``License''). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
  langid = {english},
  keywords = {Communication,Data exchange,Differential privacy,Federated learning,Heterogeneity,Histology,Image processing,Image quality,Learning,Medical imaging,Privacy,Social}
}

@misc{kayalibayCNNbasedSegmentationMedical2017,
  title = {{{CNN-based Segmentation}} of {{Medical Imaging Data}}},
  author = {Kayalibay, Baris and Jensen, Grady and {van der Smagt}, Patrick},
  year = {2017},
  month = jul,
  number = {arXiv:1701.03056},
  publisher = {arXiv},
  urldate = {2024-08-20},
  abstract = {Convolutional neural networks have been applied to a wide variety of computer vision tasks. Recent advances in semantic segmentation have enabled their application to medical image segmentation. While most CNNs use two-dimensional kernels, recent CNN-based publications on medical image segmentation featured three-dimensional kernels, allowing full access to the three-dimensional structure of medical images. Though closely related to semantic segmentation, medical image segmentation includes specific challenges that need to be addressed, such as the scarcity of labelled data, the high class imbalance found in the ground truth and the high memory demand of three-dimensional images.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@misc{KbSafariCompatibility,
  title = {Kb:{{Safari Compatibility}} [{{Zotero Documentation}}]},
  urldate = {2021-07-07}
}

@article{khayatianHistopathologyImageAnalysis2024,
  title = {Histopathology Image Analysis for Gastric Cancer Detection: A Hybrid Deep Learning and Catboost Approach},
  shorttitle = {Histopathology Image Analysis for Gastric Cancer Detection},
  author = {Khayatian, Danial and Maleki, Alireza and Nasiri, Hamid and Dorrigiv, Morteza},
  year = {2024},
  month = aug,
  journal = {Multimedia Tools and Applications},
  issn = {1573-7721},
  doi = {10.1007/s11042-024-19816-2},
  urldate = {2024-09-08},
  langid = {english}
}

@book{khayyamArtificialIntelligenceCancer2023,
  title = {Artificial {{Intelligence}} in {{Cancer Diagnosis}} and {{Therapy}}},
  editor = {Khayyam, Hamid and Madani, Ali and Kafieh, Rahele and Hekmatnia, Ali},
  year = {2023},
  month = mar,
  publisher = {MDPI},
  doi = {10.3390/books978-3-0365-6673-3},
  urldate = {2024-08-22},
  isbn = {978-3-0365-6673-3 978-3-0365-6672-6}
}

@article{kimTransferLearningMedical2022,
  title = {Transfer Learning for Medical Image Classification: A Literature Review},
  shorttitle = {Transfer Learning for Medical Image Classification},
  author = {Kim, Hee E. and {Cosa-Linan}, Alejandro and Santhanam, Nandhini and Jannesari, Mahboubeh and Maros, Mate E. and Ganslandt, Thomas},
  year = {2022},
  month = apr,
  journal = {BMC Medical Imaging},
  volume = {22},
  number = {1},
  pages = {69},
  issn = {1471-2342},
  doi = {10.1186/s12880-022-00793-7},
  urldate = {2024-09-04},
  abstract = {Transfer learning (TL) with convolutional neural networks aims to improve performances on a new task by leveraging the knowledge of similar tasks learned in advance. It has made a major contribution to medical image analysis as it overcomes the data scarcity problem as well as it saves time and hardware resources. However, transfer learning has been arbitrarily configured in the majority of studies. This review paper attempts to provide guidance for selecting a model and TL approaches for the medical image classification task.},
  keywords = {Convolutional neural network,Deep learning,Fine-tuning,Medical image analysis,Transfer learning},
  file = {/home/james/Zotero/storage/W58VXLWK/Kim et al. - 2022 - Transfer learning for medical image classification a literature review.pdf;/home/james/Zotero/storage/EPXN8FNL/s12880-022-00793-7.html}
}

@misc{kingmaAdamMethodStochastic2017,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  year = {2017},
  month = jan,
  number = {arXiv:1412.6980},
  publisher = {arXiv},
  urldate = {2024-04-27},
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  keywords = {Computer Science - Machine Learning}
}

@article{klanecekUncertaintyEstimationDeep2023,
  title = {Uncertainty Estimation for Deep Learning-Based Pectoral Muscle Segmentation via {{Monte Carlo}} Dropout},
  author = {Klanecek, Zan and Wagner, Tobias and Wang, Yao-Kuan and Cockmartin, Lesley and Marshall, Nicholas and Schott, Brayden and Deatsch, Ali and Studen, Andrej and Hertl, Kristijana and Jarm, Katja and Krajc, Mateja and Vrhovec, Milo{\v s} and Bosmans, Hilde and Jeraj, Robert},
  year = {2023},
  month = may,
  journal = {Physics in Medicine \& Biology},
  volume = {68},
  number = {11},
  pages = {115007},
  publisher = {IOP Publishing},
  issn = {0031-9155},
  doi = {10.1088/1361-6560/acd221},
  urldate = {2024-10-22},
  abstract = {Objective. Deep Learning models are often susceptible to failures after deployment. Knowing when your model is producing inadequate predictions is crucial. In this work, we investigate the utility of Monte Carlo (MC) dropout and the efficacy of the proposed uncertainty metric (UM) for flagging of unacceptable pectoral muscle segmentations in mammograms. Approach. Segmentation of pectoral muscle was performed with modified ResNet18 convolutional neural network. MC dropout layers were kept unlocked at inference time. For each mammogram, 50 pectoral muscle segmentations were generated. The mean was used to produce the final segmentation and the standard deviation was applied for the estimation of uncertainty. From each pectoral muscle uncertainty map, the overall UM was calculated. To validate the UM, a correlation between the dice similarity coefficient (DSC) and UM was used. The UM was first validated in a training set (200 mammograms) and finally tested in an independent dataset (300 mammograms). ROC-AUC analysis was performed to test the discriminatory power of the proposed UM for flagging unacceptable segmentations. Main results. The introduction of dropout layers in the model improved segmentation performance (DSC = 0.95 {\textpm} 0.07 versus DSC = 0.93 {\textpm} 0.10). Strong anti-correlation (r = -0.76, p {$<$} 0.001) between the proposed UM and DSC was observed. A high AUC of 0.98 (97\% specificity at 100\% sensitivity) was obtained for the discrimination of unacceptable segmentations. Qualitative inspection by the radiologist revealed that images with high UM are difficult to segment. Significance. The use of MC dropout at inference time in combination with the proposed UM enables flagging of unacceptable pectoral muscle segmentations from mammograms with excellent discriminatory power.},
  langid = {english},
  file = {/home/james/Zotero/storage/ED3Z5QP7/Klanecek et al. - 2023 - Uncertainty estimation for deep learning-based pectoral muscle segmentation via Monte Carlo dropout.pdf}
}

@article{klangDeepLearningGastric2023,
  title = {Deep {{Learning}} and {{Gastric Cancer}}: {{Systematic Review}} of {{AI-Assisted Endoscopy}}},
  shorttitle = {Deep {{Learning}} and {{Gastric Cancer}}},
  author = {Klang, Eyal and Sourosh, Ali and Nadkarni, Girish N. and Sharif, Kassem and Lahat, Adi},
  year = {2023},
  month = dec,
  journal = {Diagnostics},
  volume = {13},
  number = {24},
  pages = {3613},
  issn = {2075-4418},
  doi = {10.3390/diagnostics13243613},
  urldate = {2024-09-06},
  abstract = {Background: Gastric cancer (GC), a significant health burden worldwide, is typically diagnosed in the advanced stages due to its non-specific symptoms and complex morphological features. Deep learning (DL) has shown potential for improving and standardizing early GC detection. This systematic review aims to evaluate the current status of DL in pre-malignant, early-stage, and gastric neoplasia analysis. Methods: A comprehensive literature search was conducted in PubMed/MEDLINE for original studies implementing DL algorithms for gastric neoplasia detection using endoscopic images. We adhered to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. The focus was on studies providing quantitative diagnostic performance measures and those comparing AI performance with human endoscopists. Results: Our review encompasses 42 studies that utilize a variety of DL techniques. The findings demonstrate the utility of DL in GC classification, detection, tumor invasion depth assessment, cancer margin delineation, lesion segmentation, and detection of early-stage and pre-malignant lesions. Notably, DL models frequently matched or outperformed human endoscopists in diagnostic accuracy. However, heterogeneity in DL algorithms, imaging techniques, and study designs precluded a definitive conclusion about the best algorithmic approach. Conclusions: The promise of artificial intelligence in improving and standardizing gastric neoplasia detection, diagnosis, and segmentation is significant. This review is limited by predominantly single-center studies and undisclosed datasets used in AI training, impacting generalizability and demographic representation. Further, retrospective algorithm training may not reflect actual clinical performance, and a lack of model details hinders replication efforts. More research is needed to substantiate these findings, including larger-scale multi-center studies, prospective clinical trials, and comprehensive technical reporting of DL algorithms and datasets, particularly regarding the heterogeneity in DL algorithms and study designs.},
  pmcid = {PMC10742887},
  pmid = {38132197},
  file = {/home/james/Zotero/storage/WY5BA2ER/Klang et al. - 2023 - Deep Learning and Gastric Cancer Systematic Review of AI-Assisted Endoscopy.pdf}
}

@article{kumariMisinformationDetectionUsing2021,
  title = {Misinformation {{Detection Using Multitask Learning}} with {{Mutual Learning}} for {{Novelty Detection}} and {{Emotion Recognition}}},
  author = {Kumari, Rina and Ashok, Nischal and Ghosal, Tirthankar and Ekbal, Asif},
  year = {2021},
  month = sep,
  journal = {Information Processing \& Management},
  volume = {58},
  number = {5},
  pages = {102631},
  issn = {0306-4573},
  doi = {10.1016/j.ipm.2021.102631},
  urldate = {2021-08-23},
  abstract = {Fake news or misinformation is the information or stories intentionally created to deceive or mislead the readers. Nowadays, social media platforms have become the ripe grounds for misinformation, spreading them in a few minutes, which led to chaos, panic, and potential health hazards among people. The rapid dissemination and a prolific rise in the spread of fake news and misinformation create the most time-critical challenges for the Natural Language Processing (NLP) community. Relevant literature reveals that the presence of an element of surprise in the story is a strong driving force for the rapid dissemination of misinformation, which attracts immediate attention and invokes strong emotional stimulus in the reader. False stories or fake information are written to arouse interest and activate the emotions of people to spread it. Thus, false stories have a higher level of novelty and emotional content than true stories. Hence, Novelty of the news item and recognizing the Emotional state of the reader after reading the item seems two key tasks to tightly couple with misinformation Detection. Previous literature did not explore misinformation detection with mutual learning for novelty detection and emotion recognition to the best of our knowledge. Our current work argues that joint learning of novelty and emotion from the target text makes a strong case for misinformation detection. In this paper, we propose a deep multitask learning framework that jointly performs novelty detection, emotion recognition, and misinformation detection. Our deep multitask model achieves state-of-the-art (SOTA) performance for fake news detection on four benchmark datasets, viz. ByteDance, FNC, Covid-Stance and FNID with 7.73\%, 3.69\%, 7.95\% and 13.38\% accuracy gain, respectively. The evaluation shows that our multitask learning framework improves the performance over the single-task framework for four datasets with 7.8\%, 28.62\%, 11.46\%, and 15.66\% overall accuracy gain. We claim that textual novelty and emotion are the two key aspects to consider while developing an automatic fake news detection mechanism. The source code is available at https://github.com/Nish-19/Misinformation-Multitask-Attention-NE.},
  keywords = {Deep learning,Emotion recognition,Fake news detection,Multitasking,Novelty prediction}
}

@misc{kurenkovBriefHistoryNeural2020,
  title = {A {{Brief History}} of {{Neural Nets}} and {{Deep Learning}}},
  author = {Kurenkov, Andrey},
  year = {2020},
  month = sep,
  journal = {Skynet Today},
  urldate = {2024-04-15},
  abstract = {The story of how neural nets evolved from the earliest days of AI to now.}
}

@article{leApplicationLongShortTerm2019,
  title = {Application of {{Long Short-Term Memory}} ({{LSTM}}) {{Neural Network}} for {{Flood Forecasting}}},
  author = {Le, Xuan Hien and Ho, Hung and Lee, Giha and Jung, Sungho},
  year = {2019},
  month = jul,
  journal = {Water},
  volume = {11},
  pages = {1387},
  doi = {10.3390/w11071387},
  abstract = {Flood forecasting is an essential requirement in integrated water resource management. This paper suggests a Long Short-Term Memory (LSTM) neural network model for flood forecasting, where the daily discharge and rainfall were used as input data. Moreover, characteristics of the data sets which may influence the model performance were also of interest. As a result, the Da River basin in Vietnam was chosen and two different combinations of input data sets from before 1985 (when the Hoa Binh dam was built) were used for one-day, two-day, and three-day flowrate forecasting ahead at Hoa Binh Station. The predictive ability of the model is quite impressive: The Nash--Sutcliffe efficiency (NSE) reached 99\%, 95\%, and 87\% corresponding to three forecasting cases, respectively. The findings of this study suggest a viable option for flood forecasting on the Da River in Vietnam, where the river basin stretches between many countries and downstream flows (Vietnam) may fluctuate suddenly due to flood discharge from upstream hydroelectric reservoirs.}
}

@article{leMagnifyingEndoscopyDetecting2021,
  title = {Magnifying {{Endoscopy}} in {{Detecting Early Gastric Cancer}}: {{A Network Meta-Analysis}} of {{Prospective Studies}}},
  shorttitle = {Magnifying {{Endoscopy}} in {{Detecting Early Gastric Cancer}}},
  author = {Le, Hao and Wang, Lianjun and Zhang, Lan and Chen, Pengfei and Xu, Bin and Peng, Dengfa and Yang, Ming and Tan, Yong and Cai, Changsong and Li, Huqing and Zhao, Qiu},
  year = {2021},
  month = jan,
  journal = {Medicine},
  volume = {100},
  number = {3},
  pages = {e23934},
  doi = {10.1097/MD.0000000000023934},
  urldate = {2024-08-22},
  abstract = {Background: Conventional white-light imaging endoscopy (C-WLI) had a significant number of misdiagnosis in early gastric cancer (EGC), and magnifying endoscopy (ME) combined with different optical imaging was more accurate in the diagnosis of EGC. This study aimed to evaluate the accuracy of ME and compare the accuracy of ME with different optical imaging in detecting EGC. Methods: A comprehensive literature search was conducted to identify all relevant studies. Pair-wise meta-analysis was conducted to evaluate the accuracy of ME, and Bayesian network meta-analysis was performed to combine direct and indirect evidence and estimate the relative effects. Results: Eight prospective studies were identified with a total of 5948 patients and 3 optical imaging in ME (ME with WLI (M-WLI), ME with narrow-band imaging (M-NBI), and ME with blue laser imaging (M-BLI)). Pair-wise meta-analysis showed a higher accuracy of ME than C-WLI (OR: 2.97, 95\% CI: 1.68{\textbackslash}sim5.25). In network meta-analysis, both M-NBI and M-BLI were more accurate than M-WLI (OR: 2.56, 95\% CI: 2.13{\textbackslash}sim3.13; OR: 3.13, 95\% CI: 1.85{\textbackslash}sim5.71). There was no significant difference between M-NBI and M-BLI. Conclusion: ME was effective in improving the detecting rate of EGC, especially with NBI or BLI.}
}

@book{lewisProjectPlanningScheduling2023,
  title = {Project Planning, Scheduling, and Control: The Ultimate Hands-on Guide to Bringing Projects in on Time and on Budget},
  shorttitle = {Project Planning, Scheduling, and Control},
  author = {Lewis, James P.},
  year = {2023},
  edition = {Sixth Edition.},
  publisher = {McGraw-Hill},
  abstract = {"A new edition of the classic project management book is here, revised and updated with even more guidelines and real-world examples"--.},
  isbn = {978-1-264-28627-0},
  langid = {english}
}

@article{liDetectionGastricCancer2018,
  title = {Detection of {{Gastric Cancer}} and {{Its Histological Type Based}} on {{Iodine Concentration}} in {{Spectral CT}}},
  author = {Li, Rui and Li, Jing and Wang, Xiaopeng and Liang, Pan and Gao, Jianbo},
  year = {2018},
  month = nov,
  journal = {Cancer Imaging},
  volume = {18},
  number = {1},
  pages = {42},
  issn = {1470-7330},
  doi = {10.1186/s40644-018-0176-2},
  urldate = {2024-08-22},
  abstract = {Computed tomography (CT) imaging is the most common imaging modality for the diagnosis and staging of gastric cancer. The aim of this study is was to prospectively explore the ability of quantitative spectral CT parameters in the detection of gastric cancer and its histologic types.},
  keywords = {Adenocarcinoma,Gastric,Histological degree,Iodine concentration,Spectral CT imaging}
}

@article{liFederatedLearningChallenges2020,
  title = {Federated {{Learning}}: {{Challenges}}, {{Methods}}, and {{Future Directions}}},
  shorttitle = {Federated {{Learning}}},
  author = {Li, Tian and Sahu, Anit Kumar and Talwalkar, Ameet and Smith, Virginia},
  year = {2020},
  month = may,
  journal = {IEEE Signal Processing Magazine},
  volume = {37},
  number = {3},
  pages = {50--60},
  issn = {1053-5888, 1558-0792},
  doi = {10.1109/MSP.2020.2975749},
  urldate = {2024-08-23},
  abstract = {Federated learning involves training statistical models over remote devices or siloed data centers, such as mobile phones or hospitals, while keeping data localized. Training in heterogeneous and potentially massive networks introduces novel challenges that require a fundamental departure from standard approaches for large-scale machine learning, distributed optimization, and privacy-preserving data analysis. In this article, we discuss the unique characteristics and challenges of federated learning, provide a broad overview of current approaches, and outline several directions of future work that are relevant to a wide range of research communities.},
  keywords = {and Cluster Computing,Computer Science - Distributed,Computer Science - Machine Learning,Parallel,Statistics - Machine Learning}
}

@article{liFederatedLearningFramework2022,
  title = {A {{Federated Learning Framework}} for {{Breast Cancer Histopathological Image Classification}}},
  author = {Li, Lingxiao and Xie, Niantao and Yuan, Sha},
  year = {2022},
  journal = {Electronics},
  volume = {11},
  number = {22},
  pages = {3767},
  publisher = {MDPI AG},
  address = {Basel, Switzerland},
  doi = {10.3390/electronics11223767},
  urldate = {2024-10-22},
  abstract = {Quantities and diversities of datasets are vital to model training in a variety of medical image diagnosis applications. However, there are the following problems in real scenes: the required data may not be available in a single institution due to the number of patients or the type of pathology, and it is often not feasible to share patient data due to medical data privacy regulations. This means keeping private data safe is required and has become an obstacle in fusing data from multi-party to train a medical model. To solve the problems, we propose a federated learning framework, which allows knowledge fusion achieved by sharing the model parameters of each client through federated training rather than sharing data. Based on breast cancer histopathological dataset (BreakHis), our federated learning experiments achieve the expected results which are similar to the performances of the centralized learning and verify the feasibility and efficiency of the proposed framework.},
  copyright = {{\copyright} 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
  langid = {english},
  keywords = {Algorithms,Artificial intelligence,breast cancer,Breast cancer,Classification,Collaboration,Computer vision,Confidentiality,Data sharing,Datasets,Deep learning,Feasibility,federated learning,Federated learning,histopathology,image classification,Image classification,Knowledge,knowledge fusion,Machine learning,Medical diagnosis,medical image diagnosis,Medical imaging,Medical research,Neural networks,Privacy,Servers},
  file = {/home/james/Zotero/storage/ZFMRE58N/Li et al. - 2022 - A Federated Learning Framework for Breast Cancer Histopathological Image Classification.pdf}
}

@misc{linNetworkNetwork2014,
  title = {Network {{In Network}}},
  author = {Lin, Min and Chen, Qiang and Yan, Shuicheng},
  year = {2014},
  month = mar,
  number = {arXiv:1312.4400},
  publisher = {arXiv},
  urldate = {2024-04-21},
  abstract = {We propose a novel deep network structure called "Network In Network" (NIN) to enhance model discriminability for local patches within the receptive field. The conventional convolutional layer uses linear filters followed by a nonlinear activation function to scan the input. Instead, we build micro neural networks with more complex structures to abstract the data within the receptive field. We instantiate the micro neural network with a multilayer perceptron, which is a potent function approximator. The feature maps are obtained by sliding the micro networks over the input in a similar manner as CNN; they are then fed into the next layer. Deep NIN can be implemented by stacking mutiple of the above described structure. With enhanced local modeling via the micro network, we are able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers. We demonstrated the state-of-the-art classification performances with NIN on CIFAR-10 and CIFAR-100, and reasonable performances on SVHN and MNIST datasets.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing}
}

@article{liuSecureFederatedTransfer2020,
  title = {Secure {{Federated Transfer Learning}}},
  author = {Liu, Yang and Kang, Yan and Xing, Chaoping and Chen, Tianjian and Yang, Qiang},
  year = {2020},
  month = jul,
  journal = {IEEE Intelligent Systems},
  volume = {35},
  number = {4},
  eprint = {1812.03337},
  primaryclass = {cs, stat},
  pages = {70--82},
  issn = {1541-1672, 1941-1294},
  doi = {10.1109/MIS.2020.2988525},
  urldate = {2024-09-06},
  abstract = {Machine learning relies on the availability of vast amounts of data for training. However, in reality, data are mostly scattered across different organizations and cannot be easily integrated due to many legal and practical constraints. To address this important challenge in the field of machine learning, we introduce a new technique and framework, known as federated transfer learning (FTL), to improve statistical modeling under a data federation. FTL allows knowledge to be shared without compromising user privacy and enables complementary knowledge to be transferred across domains in a data federation, thereby enabling a target-domain party to build flexible and effective models by leveraging rich labels from a source domain. This framework requires minimal modifications to the existing model structure and provides the same level of accuracy as the non-privacy-preserving transfer learning. It is flexible and can be effectively adapted to various secure multi-party machine learning tasks.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/james/Zotero/storage/84EY3PL3/Liu et al. - 2020 - Secure Federated Transfer Learning.pdf}
}

@book{ludwigFederatedLearningComprehensive2022,
  title = {Federated {{Learning}}: {{A Comprehensive Overview}} of {{Methods}} and {{Applications}}},
  shorttitle = {Federated {{Learning}}},
  editor = {Ludwig, Heiko and Baracaldo, Nathalie},
  year = {2022},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-96896-0},
  urldate = {2024-10-22},
  copyright = {https://www.springer.com/tdm},
  isbn = {978-3-030-96895-3 978-3-030-96896-0},
  langid = {english},
  file = {/home/james/Zotero/storage/SIVZ8ZHT/978-3-030-96896-0.pdf}
}

@misc{luFederatedLearningComputational2020a,
  title = {Federated {{Learning}} for {{Computational Pathology}} on {{Gigapixel Whole Slide Images}}},
  author = {Lu, Ming Y. and Kong, Dehan and Lipkova, Jana and Chen, Richard J. and Singh, Rajendra and Williamson, Drew F. K. and Chen, Tiffany Y. and Mahmood, Faisal},
  year = {2020},
  month = sep,
  number = {arXiv:2009.10190},
  eprint = {2009.10190},
  primaryclass = {cs, eess, q-bio},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2009.10190},
  urldate = {2024-09-08},
  abstract = {Deep Learning-based computational pathology algorithms have demonstrated profound ability to excel in a wide array of tasks that range from characterization of well known morphological phenotypes to predicting non-human-identifiable features from histology such as molecular alterations. However, the development of robust, adaptable, and accurate deep learning-based models often rely on the collection and time-costly curation large high-quality annotated training data that should ideally come from diverse sources and patient populations to cater for the heterogeneity that exists in such datasets. Multi-centric and collaborative integration of medical data across multiple institutions can naturally help overcome this challenge and boost the model performance but is limited by privacy concerns amongst other difficulties that may arise in the complex data sharing process as models scale towards using hundreds of thousands of gigapixel whole slide images. In this paper, we introduce privacy-preserving federated learning for gigapixel whole slide images in computational pathology using weakly-supervised attention multiple instance learning and differential privacy. We evaluated our approach on two different diagnostic problems using thousands of histology whole slide images with only slide-level labels. Additionally, we present a weakly-supervised learning framework for survival prediction and patient stratification from whole slide images and demonstrate its effectiveness in a federated setting. Our results show that using federated learning, we can effectively develop accurate weakly supervised deep learning models from distributed data silos without direct data sharing and its associated complexities, while also preserving differential privacy using randomized noise generation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing,Quantitative Biology - Tissues and Organs},
  file = {/home/james/Zotero/storage/IBIVHPWF/Lu et al. - 2020 - Federated Learning for Computational Pathology on Gigapixel Whole Slide Images.pdf}
}

@article{mabroukEnsembleFederatedLearning2023,
  title = {Ensemble {{Federated Learning}}: {{An}} Approach for Collaborative Pneumonia Diagnosis},
  shorttitle = {Ensemble {{Federated Learning}}},
  author = {Mabrouk, Alhassan and D{\'i}az Redondo, Rebeca P. and Abd Elaziz, Mohamed and Kayed, Mohammed},
  year = {2023},
  month = sep,
  journal = {Applied Soft Computing},
  volume = {144},
  pages = {110500},
  issn = {1568-4946},
  doi = {10.1016/j.asoc.2023.110500},
  urldate = {2024-10-22},
  abstract = {Federated learning is a very convenient approach for scenarios where (i) the exchange of data implies privacy concerns and/or (ii) a quick reaction is needed. In smart healthcare systems, both aspects are usually required. In this paper, we work on the first scenario, where preserving privacy is key and, consequently, building a unique and massive medical image data set by fusing different data sets from different medical institutions or research centers (computation nodes) is not an option. We propose an ensemble federated learning (EFL) approach that is based on the following characteristics: First, each computation node works with a different data set (but of the same type). They work locally and apply an ensemble approach combining eight well-known CNN models (densenet169, mobilenetv2, xception, inceptionv3, vgg16, resnet50, densenet121, and resnet152v2) on Chest X-ray images. Second, the best two local models are used to create a local ensemble model that is shared with a central node. Third, the ensemble models are aggregated to obtain a global model, which is shared with the computation nodes to continue with a new iteration. This procedure continues until there are no changes in the best local models. We have performed different experiments to compare our approach with centralized ones (with or without an ensemble approach). The results conclude that our proposal outperforms these ones in Chest X-ray images (achieving an accuracy of 96.63\%) and offers very competitive results compared to other proposals in the literature. A source code is provided at the Code Ocean repository: https://codeocean.com/capsule/0530602/tree.},
  keywords = {Deep Learning,Ensemble Learning,Federated Learning,Medical image processing,Pneumonia detection},
  file = {/home/james/Zotero/storage/P3YKG62N/Mabrouk et al. - 2023 - Ensemble Federated Learning An approach for collaborative pneumonia diagnosis.pdf;/home/james/Zotero/storage/VZ4RA74K/S1568494623005185.html}
}

@book{MachineLearningPyTorch,
  title = {Machine {{Learning}} with {{PyTorch}} and {{Scikit-Learn}}},
  urldate = {2024-04-03},
  abstract = {This book of the bestselling and widely acclaimed Python Machine Learning series is a comprehensive guide to machine and deep learning using PyTorch s simple to code framework. Purchase of the...},
  isbn = {978-1-80181-931-2}
}

@article{madanchianLeadershipEffectivenessMeasurement2017,
  title = {Leadership {{Effectiveness Measurement}} and {{Its Effect}} on {{Organization Outcomes}}},
  author = {Madanchian, Mitra and Hussein, Norashikin and Noordin, Fauziah and Taherdoost, Hamed},
  year = {2017},
  month = jan,
  journal = {Procedia Engineering},
  series = {10th {{International Conference Interdisciplinarity}} in {{Engineering}}, {{INTER-ENG}} 2016, 6-7 {{October}} 2016, {{Tirgu Mures}}, {{Romania}}},
  volume = {181},
  pages = {1043--1048},
  issn = {1877-7058},
  doi = {10.1016/j.proeng.2017.02.505},
  urldate = {2024-10-28},
  abstract = {According to the leadership's researchers, effective leadership is a key analyst of organizational success or failure while examining the factors that lead to organizational success [1]. The undeniable question is, do leadership or leaders and effective leadership matter and positively effect on organizational outcomes? Based on [2] argument, the effective leadership is important and does effect on organizational outcomes. In this article the author discussed what leader effectiveness is and how it is measured based on outcomes. In sum up, effective leaders have power over specific traits and show specific behaviors or styles of leadership.},
  keywords = {Leadership,Leadership Effectiveness,Organizational Outcome,Organizational Theory},
  file = {/home/james/Zotero/storage/ZM3WU7WZ/Madanchian et al. - 2017 - Leadership Effectiveness Measurement and Its Effect on Organization Outcomes.pdf;/home/james/Zotero/storage/M8K3SN9C/S1877705817310950.html}
}

@misc{maintainersTorchVisionPyTorchComputer2016,
  title = {{{TorchVision}}: {{PyTorch}}'s {{Computer Vision Library}}},
  shorttitle = {{{TorchVision}}},
  author = {{maintainers}, TorchVision and {contributors}},
  year = {2016},
  month = nov,
  urldate = {2024-04-15},
  abstract = {Datasets, Transforms and Models specific to Computer Vision},
  copyright = {BSD-3-Clause}
}

@article{marzoukCombiningBagVisual2024,
  title = {Combining Bag of Visual Words-Based Features with {{CNN}} in Image Classification},
  author = {Marzouk, Marwa A. and Elkholy, Mohamed},
  year = {2024},
  month = jan,
  journal = {Journal of Intelligent Systems},
  volume = {33},
  number = {1},
  publisher = {De Gruyter},
  issn = {2191-026X},
  doi = {10.1515/jisys-2023-0054},
  urldate = {2024-09-04},
  abstract = {Although traditional image classification techniques are often used in authentic ways, they have several drawbacks, such as unsatisfactory results, poor classification accuracy, and a lack of flexibility. In this study, we introduce a combination of convolutional neural network (CNN) and support vector machine (SVM), along with a modified bag of visual words (BoVW)-based image classification model. BoVW uses scale-invariant feature transform (SIFT) and Oriented Fast and Rotated BRIEF (ORB) descriptors; as a consequence, the SIFT--ORB--BoVW model developed contains highly discriminating features, which enhance the performance of the classifier. To identify appropriate images and overcome challenges, we have also explored the possibility of utilizing a fuzzy Bag of Visual Words (BoVW) approach. This study also discusses using CNNs/SVM to improve the proposed feature extractor's ability to learn more relevant visual vocabulary from the image. The proposed technique was compared with classic BoVW. The experimental results proved the significant enhancement of the proposed technique in terms of performance and accuracy over state-of-the-art models of BoVW.},
  copyright = {De Gruyter expressly reserves the right to use all content for commercial text and data mining within the meaning of Section 44b of the German Copyright Act.},
  langid = {english},
  keywords = {BoVW,CNNs,deep learning,image classification,SVM},
  file = {/home/james/Zotero/storage/LIAYTA39/Marzouk and Elkholy - 2024 - Combining bag of visual words-based features with CNN in image classification.pdf}
}

@misc{mcmahanCommunicationEfficientLearningDeep2016,
  title = {Communication-{{Efficient Learning}} of {{Deep Networks}} from {{Decentralized Data}}},
  author = {McMahan, H. Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Ag{\"u}era},
  year = {2016},
  month = feb,
  journal = {arXiv.org},
  urldate = {2024-09-05},
  abstract = {Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos. However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches. We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach Federated Learning. We present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a defining characteristic of this setting. Communication costs are the principal constraint, and we show a reduction in required communication rounds by 10-100x as compared to synchronized stochastic gradient descent.},
  howpublished = {https://arxiv.org/abs/1602.05629v4},
  langid = {english},
  file = {/home/james/Zotero/storage/Q8T69PBI/McMahan et al. - 2016 - Communication-Efficient Learning of Deep Networks from Decentralized Data.pdf}
}

@misc{mcmahanCommunicationEfficientLearningDeep2023,
  title = {Communication-{{Efficient Learning}} of {{Deep Networks}} from {{Decentralized Data}}},
  author = {McMahan, H. Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and y Arcas, Blaise Ag{\"u}era},
  year = {2023},
  month = jan,
  number = {arXiv:1602.05629},
  eprint = {1602.05629},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1602.05629},
  urldate = {2024-10-23},
  abstract = {Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos. However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches. We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach Federated Learning. We present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a defining characteristic of this setting. Communication costs are the principal constraint, and we show a reduction in required communication rounds by 10-100x as compared to synchronized stochastic gradient descent.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning}
}

@article{mertogluAutomatedFakeNews2020,
  title = {Automated {{Fake News Detection}} in the {{Age}} of {{Digital Libraries}}},
  author = {Merto{\v g}lu, U{\v g}ur and Gen{\c c}, Burkay},
  year = {2020},
  month = dec,
  journal = {Information Technology and Libraries (Online)},
  volume = {39},
  number = {4},
  pages = {1--19},
  publisher = {American Library Association},
  address = {Chicago, United States},
  doi = {http://dx.doi.org.ezproxy.lib.uts.edu.au/10.6017/ital.v39i4.12483},
  urldate = {2021-07-21},
  abstract = {The transformation of printed media into the digital environment and the extensive use of social media have changed the concept of media literacy and people's habits of news consumption. While online news is faster, easier, comparatively cheaper, and offers convenience in terms of people's access to information, it speeds up the dissemination of fake news. Due to the free production and consumption of large amounts of data, fact-checking systems powered by human efforts are not enough to question the credibility of the information provided, or to prevent its rapid dissemination like a virus. Libraries, long known as sources of trusted information, are facing challenges caused by misinformation as mentioned in studies about fake news and libraries.1 Considering that libraries are undergoing digitization processes all over the world and are providing digital media to their users, it is very likely that unverified digital content will be served by world's libraries. The solution is to develop automated mechanisms that can check the credibility of digital content served in libraries without manual validation. For this purpose, we developed an automated fake news detection system based on Turkish digital news content. Our approach can be modified for any other language if there is labelled training material. This model can be integrated into libraries' digital systems to label served news content as potentially fake whenever necessary, preventing uncontrolled falsehood dissemination via libraries.},
  chapter = {ARTICLE},
  copyright = {{\textbackslash}copyright 2020. This work is published under https://creativecommons.org/licenses/by-nc/4.0/ (the ``License''). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
  keywords = {Access to information,Automation,Checking systems,Consumption,Digital libraries,Digital media,Digital systems,Digitization,Election results,False information,Information dissemination,Information professionals,Librarians,Libraries,Library and information science,Library And Information Sciences,Media literacy,News}
}

@article{miDesigningEfficientConvolutional2022,
  title = {Designing {{Efficient Convolutional Neural Network Structure}}: {{A Survey}}},
  shorttitle = {Designing {{Efficient Convolutional Neural Network Structure}}},
  author = {Mi, Jian-Xun and Feng, Jie and Huang, Ke-Yang},
  year = {2022},
  month = jun,
  journal = {Neurocomputing},
  volume = {489},
  pages = {139--156},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2021.08.158},
  urldate = {2024-04-27},
  abstract = {As a powerful machine learning method, deep learning has attracted the attention of numerous researchers. While exploring a high-performance neural network model, the floating-point operations of a neural network model are also increasing. In recent years, many researchers have noticed that efficiency is also one of important indicators to measure the property of neural network models. Obviously, the efficient neural network model is more helpful to deploy on mobile and embedded devices. Therefore, the efficient neural network model becomes a hot research spot. In this paper, we review the methods related to the structural design of efficient convolution neural networks in recent years. According to the characteristics of these methods, we divide them into three kinds of methods: model pruning, efficient architecture, and neural architecture search. Detailed analyses of each method are presented to demonstrate their advantages and disadvantages. Then, we comprehensively compare them in detail and propose many suggestions about the design of the efficient convolution neural network model structure. Inspired by these suggestions, we built a new efficient neural network model, SharedNet. And the SharedNet obtains the best accuracy of manually-designed efficient CNN models on the ImageNet dataset.},
  keywords = {Deep learning,Efficient convolution,Model structure design,Neural architecture search}
}

@misc{MisinformationAgeHow,
  title = {The {{Misinformation Age}} : {{How False Beliefs Spread}}},
  urldate = {2021-09-12}
}

@misc{MissingItemCiteproc,
  title = {Missing {\textbackslash}item Citeproc? - {{Google Search}}},
  urldate = {2024-09-04},
  howpublished = {https://www.google.com/search?client=ubuntu-sn\&channel=fs\&q=missing+\%5Citem+citeproc\%3F},
  file = {/home/james/Zotero/storage/HDBXSNH8/search.html}
}

@misc{ModelsPretrainedWeights,
  title = {Models and Pre-Trained Weights --- {{Torchvision}} 0.20 Documentation},
  urldate = {2024-10-23},
  howpublished = {https://pytorch.org/vision/stable/models.html},
  file = {/home/james/Zotero/storage/32QIAL7A/models.html}
}

@article{mudavadkarGastricCancerDetection2024a,
  title = {Gastric {{Cancer Detection}} with {{Ensemble Learning}} on {{Digital Pathology}}: {{Use Case}} of {{Gastric Cancer}} on {{GasHisSDB Dataset}}},
  shorttitle = {Gastric {{Cancer Detection}} with {{Ensemble Learning}} on {{Digital Pathology}}},
  author = {Mudavadkar, Govind Rajesh and Deng, Mo and {Al-Heejawi}, Salah Mohammed Awad and Arora, Isha Hemant and Breggia, Anne and Ahmad, Bilal and Christman, Robert and Ryan, Stephen T. and Amal, Saeed},
  year = {2024},
  month = jan,
  journal = {Diagnostics},
  volume = {14},
  number = {16},
  pages = {1746},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2075-4418},
  doi = {10.3390/diagnostics14161746},
  urldate = {2024-10-22},
  abstract = {Gastric cancer has become a serious worldwide health concern, emphasizing the crucial importance of early diagnosis measures to improve patient outcomes. While traditional histological image analysis is regarded as the clinical gold standard, it is labour intensive and manual. In recognition of this problem, there has been a rise in interest in the use of computer-aided diagnostic tools to help pathologists with their diagnostic efforts. In particular, deep learning (DL) has emerged as a promising solution in this sector. However, current DL models are still restricted in their ability to extract extensive visual characteristics for correct categorization. To address this limitation, this study proposes the use of ensemble models, which incorporate the capabilities of several deep-learning architectures and use aggregate knowledge of many models to improve classification performance, allowing for more accurate and efficient gastric cancer detection. To determine how well these proposed models performed, this study compared them with other works, all of which were based on the Gastric Histopathology Sub-Size Images Database, a publicly available dataset for gastric cancer. This research demonstrates that the ensemble models achieved a high detection accuracy across all sub-databases, with an average accuracy exceeding 99\%. Specifically, ResNet50, VGGNet, and ResNet34 performed better than EfficientNet and VitNet. For the 80 {\texttimes} 80-pixel sub-database, ResNet34 exhibited an accuracy of approximately 93\%, VGGNet achieved 94\%, and the ensemble model excelled with 99\%. In the 120 {\texttimes} 120-pixel sub-database, the ensemble model showed 99\% accuracy, VGGNet 97\%, and ResNet50 approximately 97\%. For the 160 {\texttimes} 160-pixel sub-database, the ensemble model again achieved 99\% accuracy, VGGNet 98\%, ResNet50 98\%, and EfficientNet 92\%, highlighting the ensemble model's superior performance across all resolutions. Overall, the ensemble model consistently provided an accuracy of 99\% across the three sub-pixel categories. These findings show that ensemble models may successfully detect critical characteristics from smaller patches and achieve high performance. The findings will help pathologists diagnose gastric cancer using histopathological images, leading to earlier identification and higher patient survival rates.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {cancer detection,deep learning,gastrointestinal cancer,histopathology,machine learning},
  file = {/home/james/Zotero/storage/83KX9TZQ/Mudavadkar et al. - 2024 - Gastric Cancer Detection with Ensemble Learning on Digital Pathology Use Case of Gastric Cancer on.pdf}
}

@inproceedings{naikIntroductionFederatedLearning2024,
  title = {An {{Introduction}} to~{{Federated Learning}}: {{Working}}, {{Types}}, {{Benefits}} and~{{Limitations}}},
  shorttitle = {An {{Introduction}} to~{{Federated Learning}}},
  booktitle = {Advances in {{Computational Intelligence Systems}}},
  author = {Naik, Dishita and Naik, Nitin},
  editor = {Naik, Nitin and Jenkins, Paul and Grace, Paul and Yang, Longzhi and Prajapat, Shaligram},
  year = {2024},
  pages = {3--17},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-47508-5_1},
  abstract = {Machine learning has been constantly evolving and revolutionizing every aspect of our lives. There is ongoing research to enhance and modify machine learning models where scientists and researchers are finding ways to improve the effectiveness and adaptability of models with the changing technology moulding to user requirements for real life application. The main challenges in this endeavour of enhancing machine learning models are obtaining quality data, selecting an appropriate model, and ensuring the data privacy. Federated learning has been developed to address the aforementioned challenges, which is an effective way to train machine learning models in a collaborative manner by using the local data from a large number of devices without directly exchanging their raw data whilst simultaneously delivering on model performance. Federated learning is not just a type of machine learning, it is an amalgamation of several technologies and techniques. To fully understand its concepts a comprehensive study is required. This paper aims to simplify the fundamentals of federated learning in order to provide a better understanding of it. It explains federated learning in a step-by-step manner covering its comprehensive definition, detailed working, different types, benefits and limitations.},
  isbn = {978-3-031-47508-5},
  langid = {english},
  keywords = {Centralized federated learning,Cross-device federated learning,Cross-silo federated learning,Decentralized federated learning,Distributed machine learning (DML),Federated learning (FL),Federated machine learning (FML),Horizontal federated learning,Vertical federated learning},
  file = {/home/james/Zotero/storage/4RDD4N83/Naik and Naik - 2024 - An Introduction toFederated Learning Working, Types, Benefits andLimitations.pdf}
}

@article{nardoneImageEnhancedEndoscopySurveillance2022,
  title = {Image-{{Enhanced Endoscopy}} in the {{Surveillance}} of {{Colitis-Associated Neoplasia}}},
  author = {Nardone, Olga Maria and Iacucci, Marietta},
  year = {2022},
  month = oct,
  journal = {Gastrointestinal Endoscopy Clinics of North America},
  series = {Interventional {{Inflammatory Bowel Disease}}: {{Endoscopic Treatment}} of {{Complications}}},
  volume = {32},
  number = {4},
  pages = {845--862},
  issn = {1052-5157},
  doi = {10.1016/j.giec.2022.05.012},
  urldate = {2024-08-21},
  keywords = {Colonoscopy,Colorectal cancer surveillance,Dye-based chromoendoscopy,High-definition endoscopy,Virtual chromoendoscopy}
}

@article{nergizFederatedLearningBasedColorectal2023,
  title = {Federated {{Learning-Based Colorectal Cancer Classification}} by {{Convolutional Neural Networks}} and {{General Visual Representation Learning}}},
  author = {Nergiz, Mehmet},
  year = {2023},
  journal = {International Journal of Imaging Systems and Technology},
  volume = {33},
  number = {3},
  pages = {951--964},
  issn = {1098-1098},
  doi = {10.1002/ima.22875},
  urldate = {2024-08-19},
  abstract = {Colorectal cancer is the fourth fatal disease in the world, and the massive burden on the pathologists related to the classification of precancerous and cancerous colorectal lesions can be decreased by deep learning (DL) methods. However, the data privacy of the patients is a big challenge for being able to train deep learning models using big medical data. Federated Learning is a rising star in this era by providing the ability to train deep learning models on different sites without sacrificing data privacy. In this study, the Big Transfer model, which is a new General Visual Representation Learning method and six other classical DL methods are converted to the federated version. The effect of the federated learning is measured on all these models on four different data settings extracted from the MHIST and Chaoyang datasets. The proposed models are tested for single learning, centralized learning, and federated learning. The best AUC values of federated learning on Chaoyang are obtained by the Big Transfer and VGG models at 90.77\% and 90.76\%, respectively, whereas the best AUC value on MHIST is obtained by the Big Transfer model at 89.72\%. The overall obtained results of models on all data settings show that the contribution of Federated Learning with respect to single learning is 4.71\% and 11.68\% for the ``uniform'' and ``label-biased'' data settings of Chaoyang, respectively, and 6.89\% for the ``difficulty level-biased'' data setting of MHIST. Thus, it is experimentally shown that federated learning can be applied to the field of computational pathology for new institutional collaborations.},
  copyright = {{\textbackslash}copyright 2023 Wiley Periodicals LLC.},
  keywords = {big transfer,colorectal cancer,computational pathology,convolutional neural network,federated learning,general visual representation learning},
  file = {/home/james/Zotero/storage/7MZSC6AF/Nergiz - 2023 - Federated Learning-Based Colorectal Cancer Classification by Convolutional Neural Networks and Gener.pdf}
}

@book{NLPPrimer,
  title = {{{NLP}}: {{A Primer}}},
  shorttitle = {{{NLP}}},
  urldate = {2021-08-22},
  abstract = {Chapter 1. NLP: A Primer A language is not just words. It's a culture, a tradition, a unification of a community, a whole history that creates what a community is. It's all embodied in a...},
  isbn = {978-1-4920-5404-7}
}

@article{ozturkTransferLearningFinetuned2023,
  title = {Transfer Learning and Fine-Tuned Transfer Learning Methods' Effectiveness Analyse in the {{CNN-based}} Deep Learning Models},
  author = {{\"O}zt{\"u}rk, Celal and Ta{\c s}y{\"u}rek, Murat and T{\"u}rkdamar, Mehmet U{\u g}ur},
  year = {2023},
  journal = {Concurrency and Computation: Practice and Experience},
  volume = {35},
  number = {4},
  pages = {e7542},
  issn = {1532-0634},
  doi = {10.1002/cpe.7542},
  urldate = {2024-11-01},
  abstract = {Object detection is a type of application that includes computer vision and image processing technologies, which deal with detecting, tracking, and classifying desired objects in images. Computer vision is a field of artificial intelligence that enables computers and systems to derive information from digital images and take action or suggestions based on that information. CNN is one of the current methods of object detection due to its ease of use and GPU-supported parallel working features. Due to the aim of completing deep learning model training quickly or due to insufficient dataset, many studies using the transfer learning method are carried out in fields such as medicine, agriculture, and weapons. However, there are very few studies that use the fine-tuning method and compare transfer learning in terms of effectiveness. By paying attention to the balanced distribution of the data, approximately 100 images of each chess piece type were included in the analysis and a dataset of at least 1000 images was created. The without transfer learning fine-tune, fine-tuned transfer learning, transfer learning, fully supervised learning (FSL) and weakly supervised learning (WSL) applied models performances compared. Experimental results show that the fine-tuned transfer learning applied YOLO V4 model produces more accurate results than the other models in FSL and the transfer learning applied Faster R-CNN model produces more accurate results than the other models in WSL.},
  copyright = {{\copyright} 2022 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {CNN,deep learning,fine-tuned transfer learning},
  file = {/home/james/Zotero/storage/F7ESNS5F/ztrk et al. - 2023 - Transfer learning and fine-tuned transfer learning methods' effectiveness analyse in the CNN-based d.pdf;/home/james/Zotero/storage/JGLVMXKM/cpe.html}
}

@book{pallePrivacyAgeInnovation2024,
  title = {Privacy in the {{Age}} of {{Innovation}}: {{AI Solutions}} for {{Information Security}}},
  shorttitle = {Privacy in the {{Age}} of {{Innovation}}},
  author = {Palle, Ranadeep Reddy and Kathala, Krishna Chaitanya Rao},
  year = {2024},
  publisher = {Apress},
  address = {Berkeley, CA},
  doi = {10.1007/979-8-8688-0461-8},
  urldate = {2024-09-04},
  copyright = {https://www.springernature.com/gp/researchers/text-and-data-mining},
  isbn = {9798868804601 9798868804618},
  langid = {english},
  file = {/home/james/Zotero/storage/ZR3NLJJM/Palle and Kathala - 2024 - Privacy in the Age of Innovation AI Solutions for Information Security.pdf}
}

@misc{PapersCodeFood101,
  title = {Papers with {{Code}} - {{Food-101 Benchmark}} ({{Image Classification}})},
  urldate = {2024-04-18},
  abstract = {The current state-of-the-art on Food-101 is Bamboo (ViTB/16). See a full comparison of 7 papers with code.}
}

@misc{PapersCodeNASNet,
  title = {Papers with {{Code}} - {{NASNet}}},
  urldate = {2024-04-20},
  abstract = {Summary NASNet is a type of convolutional neural network discovered through neural architecture search. The building blocks consist of normal and reduction cells. How do I load this model? To load a pretrained model: python import timm m = timm.create\_model('nasnetalarge', pretrained=True) m.eval() Replace the model name with the variant you want to use, e.g. nasnetalarge. You can find the IDs in the model summaries at the top of this page. How do I train this model? You can follow the timm recipe scripts for training a new model afresh. Citation BibTeX @misc\{zoph2018learning, title=\{Learning Transferable Architectures for Scalable Image Recognition\}, author=\{Barret Zoph and Vijay Vasudevan and Jonathon Shlens and Quoc V. Le\}, year=\{2018\}, eprint=\{1707.07012\}, archivePrefix=\{arXiv\}, primaryClass=\{cs.CV\} \}}
}

@inproceedings{papineniBleuMethodAutomatic2002,
  title = {Bleu: {{A Method}} for {{Automatic Evaluation}} of {{Machine Translation}}},
  shorttitle = {Bleu},
  booktitle = {Proceedings of the 40th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  editor = {Isabelle, Pierre and Charniak, Eugene and Lin, Dekang},
  year = {2002},
  month = jul,
  pages = {311--318},
  publisher = {Association for Computational Linguistics},
  address = {Philadelphia, Pennsylvania, USA},
  doi = {10.3115/1073083.1073135},
  urldate = {2024-05-22}
}

@inproceedings{parkAnalysisDropoutEffect2017,
  title = {Analysis on the {{Dropout Effect}} in {{Convolutional Neural Networks}}},
  booktitle = {Computer {{Vision}} --  {{ACCV}} 2016},
  author = {Park, Sungheon and Kwak, Nojun},
  editor = {Lai, Shang-Hong and Lepetit, Vincent and Nishino, Ko and Sato, Yoichi},
  year = {2017},
  pages = {189--204},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-319-54184-6_12},
  abstract = {Regularizing neural networks is an important task to reduce overfitting. Dropout~[1] has been a widely-used regularization trick for neural networks. In convolutional neural networks (CNNs), dropout is usually applied to the fully connected layers. Meanwhile, the regularization effect of dropout in the convolutional layers has not been thoroughly analyzed in the literature. In this paper, we analyze the effect of dropout in the convolutional layers, which is indeed proved as a powerful generalization method. We observed that dropout in CNNs regularizes the networks by adding noise to the output feature maps of each layer, yielding robustness to variations of images. Based on this observation, we propose a stochastic dropout whose drop ratio varies for each iteration. Furthermore, we propose a new regularization method which is inspired by behaviors of image filters. Rather than randomly drop the activation, we selectively drop the activations which have high values across the feature map or across the channels. Experimental results validate the regularization performance of selective max-drop and stochastic dropout is competitive to the dropout or spatial dropout~[2].},
  isbn = {978-3-319-54184-6},
  langid = {english},
  keywords = {Classification Error,Convolutional Neural Network,Deep Neural Network,Regularization Method,Training Image},
  file = {/home/james/Zotero/storage/HSV3T699/Park and Kwak - 2017 - Analysis on the Dropout Effect in Convolutional Neural Networks.pdf}
}

@article{patelTestBehaviouralNudges2021,
  title = {Test {{Behavioural Nudges}} to {{Boost COVID Immunization}}},
  author = {Patel, Mitesh},
  year = {2021},
  month = feb,
  journal = {Nature},
  volume = {590},
  number = {7845},
  pages = {185--185},
  publisher = {Nature Publishing Group},
  doi = {10.1038/d41586-021-00329-z},
  urldate = {2021-08-09},
  abstract = {Studies to promote uptake are as essential as research to develop vaccines.},
  copyright = {2021 Nature}
}

@article{patiFederatedLearningEnables2022b,
  title = {Federated Learning Enables Big Data for Rare Cancer Boundary Detection},
  author = {Pati, Sarthak and Baid, Ujjwal and Edwards, Brandon and Sheller, Micah and Wang, Shih-Han and Reina, G. Anthony and Foley, Patrick and Gruzdev, Alexey and Karkada, Deepthi and Davatzikos, Christos and Sako, Chiharu and Ghodasara, Satyam and Bilello, Michel and Mohan, Suyash and Vollmuth, Philipp and Brugnara, Gianluca and Preetha, Chandrakanth J. and Sahm, Felix and {Maier-Hein}, Klaus and Zenk, Maximilian and Bendszus, Martin and Wick, Wolfgang and Calabrese, Evan and Rudie, Jeffrey and {Villanueva-Meyer}, Javier and Cha, Soonmee and Ingalhalikar, Madhura and Jadhav, Manali and Pandey, Umang and Saini, Jitender and Garrett, John and Larson, Matthew and Jeraj, Robert and Currie, Stuart and Frood, Russell and Fatania, Kavi and Huang, Raymond Y. and Chang, Ken and Bala{\~n}a, Carmen and Capellades, Jaume and Puig, Josep and Trenkler, Johannes and Pichler, Josef and Necker, Georg and Haunschmidt, Andreas and Meckel, Stephan and Shukla, Gaurav and Liem, Spencer and Alexander, Gregory S. and Lombardo, Joseph and Palmer, Joshua D. and Flanders, Adam E. and Dicker, Adam P. and Sair, Haris I. and Jones, Craig K. and Venkataraman, Archana and Jiang, Meirui and So, Tiffany Y. and Chen, Cheng and Heng, Pheng Ann and Dou, Qi and Kozubek, Michal and Lux, Filip and Mich{\'a}lek, Jan and Matula, Petr and Ke{\v r}kovsk{\'y}, Milo{\v s} and Kop{\v r}ivov{\'a}, Tereza and Dost{\'a}l, Marek and Vyb{\'i}hal, V{\'a}clav and Vogelbaum, Michael A. and Mitchell, J. Ross and Farinhas, Joaquim and Maldjian, Joseph A. and Yogananda, Chandan Ganesh Bangalore and Pinho, Marco C. and Reddy, Divya and Holcomb, James and Wagner, Benjamin C. and Ellingson, Benjamin M. and Cloughesy, Timothy F. and Raymond, Catalina and Oughourlian, Talia and Hagiwara, Akifumi and Wang, Chencai and To, Minh-Son and Bhardwaj, Sargam and Chong, Chee and Agzarian, Marc and Falc{\~a}o, Alexandre Xavier and Martins, Samuel B. and Teixeira, Bernardo C. A. and Sprenger, Fl{\'a}via and Menotti, David and Lucio, Diego R. and LaMontagne, Pamela and Marcus, Daniel and Wiestler, Benedikt and Kofler, Florian and Ezhov, Ivan and Metz, Marie and Jain, Rajan and Lee, Matthew and Lui, Yvonne W. and McKinley, Richard and Slotboom, Johannes and Radojewski, Piotr and Meier, Raphael and Wiest, Roland and Murcia, Derrick and Fu, Eric and Haas, Rourke and Thompson, John and Ormond, David Ryan and Badve, Chaitra and Sloan, Andrew E. and Vadmal, Vachan and Waite, Kristin and Colen, Rivka R. and Pei, Linmin and Ak, Murat and Srinivasan, Ashok and Bapuraj, J. Rajiv and Rao, Arvind and Wang, Nicholas and Yoshiaki, Ota and Moritani, Toshio and Turk, Sevcan and Lee, Joonsang and Prabhudesai, Snehal and Mor{\'o}n, Fanny and Mandel, Jacob and Kamnitsas, Konstantinos and Glocker, Ben and Dixon, Luke V. M. and Williams, Matthew and Zampakis, Peter and Panagiotopoulos, Vasileios and Tsiganos, Panagiotis and Alexiou, Sotiris and Haliassos, Ilias and Zacharaki, Evangelia I. and Moustakas, Konstantinos and Kalogeropoulou, Christina and Kardamakis, Dimitrios M. and Choi, Yoon Seong and Lee, Seung-Koo and Chang, Jong Hee and Ahn, Sung Soo and Luo, Bing and Poisson, Laila and Wen, Ning and Tiwari, Pallavi and Verma, Ruchika and Bareja, Rohan and Yadav, Ipsa and Chen, Jonathan and Kumar, Neeraj and Smits, Marion and Van Der Voort, Sebastian R. and Alafandi, Ahmed and Incekara, Fatih and Wijnenga, Maarten M. J. and Kapsas, Georgios and Gahrmann, Renske and Schouten, Joost W. and Dubbink, Hendrikus J. and Vincent, Arnaud J. P. E. and Van Den Bent, Martin J. and French, Pim J. and Klein, Stefan and Yuan, Yading and Sharma, Sonam and Tseng, Tzu-Chi and Adabi, Saba and Niclou, Simone P. and Keunen, Olivier and Hau, Ann-Christin and Valli{\`e}res, Martin and Fortin, David and Lepage, Martin and Landman, Bennett and Ramadass, Karthik and Xu, Kaiwen and Chotai, Silky and Chambless, Lola B. and Mistry, Akshitkumar and Thompson, Reid C. and Gusev, Yuriy and Bhuvaneshwar, Krithika and Sayah, Anousheh and Bencheqroun, Camelia and Belouali, Anas and Madhavan, Subha and Booth, Thomas C. and Chelliah, Alysha and Modat, Marc and Shuaib, Haris and Dragos, Carmen and Abayazeed, Aly and Kolodziej, Kenneth and Hill, Michael and Abbassy, Ahmed and Gamal, Shady and Mekhaimar, Mahmoud and Qayati, Mohamed and Reyes, Mauricio and Park, Ji Eun and Yun, Jihye and Kim, Ho Sung and Mahajan, Abhishek and Muzi, Mark and Benson, Sean and {Beets-Tan}, Regina G. H. and Teuwen, Jonas and {Herrera-Trujillo}, Alejandro and Trujillo, Maria and Escobar, William and Abello, Ana and Bernal, Jose and G{\'o}mez, Jhon and Choi, Joseph and Baek, Stephen and Kim, Yusung and Ismael, Heba and Allen, Bryan and Buatti, John M. and Kotrotsou, Aikaterini and Li, Hongwei and Weiss, Tobias and Weller, Michael and Bink, Andrea and Pouymayou, Bertrand and Shaykh, Hassan F. and Saltz, Joel and Prasanna, Prateek and Shrestha, Sampurna and Mani, Kartik M. and Payne, David and Kurc, Tahsin and Pelaez, Enrique and {Franco-Maldonado}, Heydy and Loayza, Francis and Quevedo, Sebastian and Guevara, Pamela and Torche, Esteban and Mendoza, Cristobal and Vera, Franco and R{\'i}os, Elvis and L{\'o}pez, Eduardo and Velastin, Sergio A. and Ogbole, Godwin and Soneye, Mayowa and Oyekunle, Dotun and {Odafe-Oyibotha}, Olubunmi and Osobu, Babatunde and Shu'aibu, Mustapha and Dorcas, Adeleye and Dako, Farouk and Simpson, Amber L. and Hamghalam, Mohammad and Peoples, Jacob J. and Hu, Ricky and Tran, Anh and Cutler, Danielle and Moraes, Fabio Y. and Boss, Michael A. and Gimpel, James and Veettil, Deepak Kattil and Schmidt, Kendall and Bialecki, Brian and Marella, Sailaja and Price, Cynthia and Cimino, Lisa and Apgar, Charles and Shah, Prashant and Menze, Bjoern and {Barnholtz-Sloan}, Jill S. and Martin, Jason and Bakas, Spyridon},
  year = {2022},
  month = dec,
  journal = {Nature Communications},
  volume = {13},
  number = {1},
  pages = {7346},
  issn = {2041-1723},
  doi = {10.1038/s41467-022-33407-5},
  urldate = {2024-09-06},
  abstract = {Abstract                            Although machine learning (ML) has shown promise across disciplines, out-of-sample generalizability is concerning. This is currently addressed by sharing multi-site data, but such centralization is challenging/infeasible to scale due to various limitations. Federated ML (FL) provides an alternative paradigm for accurate and generalizable ML, by only sharing numerical model updates. Here we present the largest FL study to-date, involving data from 71 sites across 6 continents, to generate an automatic tumor boundary detector for the rare disease of glioblastoma, reporting the largest such dataset in the literature (               n               \,=\,6,\,314). We demonstrate a 33\% delineation improvement for the surgically targetable tumor, and 23\% for the complete tumor extent, over a publicly trained model. We anticipate our study to: 1) enable more healthcare studies informed by large diverse data, ensuring meaningful results for rare diseases and underrepresented populations, 2) facilitate further analyses for glioblastoma by releasing our consensus model, and 3) demonstrate the FL effectiveness at such scale and task-complexity as a paradigm shift for multi-site collaborations, alleviating the need for data-sharing.},
  langid = {english},
  file = {/home/james/Zotero/storage/HAVYGR6Q/Pati et al. - 2022 - Federated learning enables big data for rare cancer boundary detection.pdf}
}

@article{petaEnhancingBreastCancer2023,
  title = {Enhancing {{Breast Cancer Classification}} in {{Histopathological Images}} through {{Federated Learning Framework}}},
  author = {Peta, Jyothi and Koppu, Srinivas},
  year = {2023},
  journal = {IEEE Access},
  volume = {11},
  pages = {61866--61880},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2023.3283930},
  urldate = {2024-10-23},
  abstract = {In recent decades, the mortality rate of breast cancer in females is rapidly increasing because of unawareness and failed to detect in earlier stages. In existing, several studies are attempted to develop a robust mechanism for detecting breast cancers from the given input samples. However, they are not as much effective because of several limitations and the secured sharing of sensitive medical images is still a challenging problem faced by medical sector. Thus, the proposed study aims to introduce an automated disease diagnosis system using federated learning and deep learning which automates and speed up the process efficiently. The five crucial steps that involved in the proposed study are image acquisition, encryption, optimal key generation, secured data storing and disease classification. Initially, the required input medical images are gathered in the image acquisition stage. Then, to afford more confidentiality, the gathered medical samples are encrypted through an Extended ElGamal Image Encryption (E-EIE) method. Here, the efficiency of encryption process is enhanced by generating the suitable keys in optimal manner with the help of Improved Sand Cat Swarm Optimization (I-SCSO) algorithm. Next, the security of encrypted images are improvised by utilizing federated learning flower (FLF) framework for storage purpose. This framework has the ability to transmit the medical images with higher security. Finally, the stored images are decrypted and performs disease classification by using convolutional capsule twin attention tuna optimal network (C2T2Net) model. The available loss in the proposed classifier is reduced by fine-tuning the parameters using chaotic tuna swarm optimization (CTSO) algorithm. For simulation analysis, the proposed study used Python software and the experimental analysis is carried out by using BreakHis Database. The simulation results shows that the proposed study obtained higher performance in terms of accuracy (95.68\%), recall (95.6\%), precision (95.66\%), F-measure (95.63\%), specificity (95.6\%) and kappa coefficient (95.26\%).},
  keywords = {Analytical models,Breast cancer,Breast cancer classification,convolutional capsule twin attention tuna optimal network,Data models,Deep learning,Encryption,extended ElGamal image encryption,Federated learning,federated learning framework,improved sand cat swarm optimization,Medical diagnostic imaging}
}

@article{pimpalkarMBiLSTMGloVeEmbeddingGloVe2022,
  title = {{{MBiLSTMGloVe}}: {{Embedding GloVe Knowledge}} into the {{Corpus Using Multi-Layer BiLSTM Deep Learning Model}} for {{Social Media Sentiment Analysis}}},
  shorttitle = {{{MBiLSTMGloVe}}},
  author = {Pimpalkar, Amit and Raj R, Jeberson Retna},
  year = {2022},
  month = oct,
  journal = {Expert Systems with Applications},
  volume = {203},
  pages = {117581},
  issn = {0957-4174},
  doi = {10.1016/j.eswa.2022.117581},
  urldate = {2024-05-22},
  abstract = {The fast improvement and transformation of online media and unique sites with critical reviews of items, movies, goods, etc. have created a tremendous assortment of assets for clients everywhere around the globe. This information might contain a great deal of data, including product reviews, anticipating market changes, and the extremity of film assessments. Sentiment Analysis (SA) innovation produces phonetic comprehension according to the viewpoint of machines through the handling and investigation of immense amounts of information, which is a hot expedition passageway heading into the field of man-made reasoning, a.k.a. Artificial Intelligence (AI). To address the substance appendage from short texts, we want to investigate the further semantics of words by exploiting thoughtful Machine Learning (ML) and Deep Learning (DL) strategies. In this way, AI, ML, and DL procedures can control and distribute intuition introspection in these difficulties. Our recommended model, based on the DL method and the GloVe word embedding approach, learns the features using a CNN layer and then coordinates those parts into a Multi-Layered Bi-DirectionalLong-Short-Term Memory (MBiLSTM) to capture long-range embedded circumstances. The main aim of this experiment is to give an adequate answer to examine feelings and user reviews in positive and negative classifications. Our runs show that a test accuracy of 92.05\% and a validation accuracy of 93.55\% can be attained with the given model. The framework is assessed using IMDB datasets. The proposed model outflanks existing pattern models, which show that going past the substance of a tweet is valuable in opinion classification orders since it gives the classifier a deep understanding of the chore.},
  keywords = {BiLSTM,Deep learning,GloVe,Natural Language Processing,Sentiment analysis,Word embedding}
}

@misc{postCallClarityReporting2018,
  title = {A {{Call}} for {{Clarity}} in {{Reporting BLEU Scores}}},
  author = {Post, Matt},
  year = {2018},
  month = sep,
  number = {arXiv:1804.08771},
  publisher = {arXiv},
  urldate = {2024-05-22},
  abstract = {The field of machine translation faces an under-recognized problem because of inconsistency in the reporting of scores from its dominant metric. Although people refer to ``the'' BLEU score, BLEU is in fact a parameterized metric whose values can vary wildly with changes to these parameters. These parameters are often not reported or are hard to find, and consequently, BLEU scores between papers cannot be directly compared. I quantify this variation, finding differences as high as 1.8 between commonly used configurations. The main culprit is different tokenization and normalization schemes applied to the reference. Pointing to the success of the parsing community, I suggest machine translation researchers settle upon the BLEU scheme used by the annual Conference on Machine Translation (WMT), which does not allow for usersupplied reference processing, and provide a new tool, SACREBLEU,1 to facilitate this.},
  keywords = {Computer Science - Computation and Language}
}

@article{powerEthicalProblemsVirtual2019,
  title = {Ethical {{Problems}} in {{Virtual Research}}: {{Enmeshing}} the {{Blurriness}} with {{Twitter Data}}},
  shorttitle = {Ethical {{Problems}} in {{Virtual Research}}},
  author = {Power, Kerry},
  year = {2019},
  month = may,
  journal = {E-Learning and Digital Media},
  volume = {16},
  number = {3},
  pages = {196--207},
  publisher = {SAGE Publications},
  issn = {2042-7530},
  doi = {10.1177/2042753019834954},
  urldate = {2021-08-07}
}

@article{prayitnoSystematicReviewFederated2021,
  title = {A {{Systematic Review}} of {{Federated Learning}} in the {{Healthcare Area}}: {{From}} the {{Perspective}} of {{Data Properties}} and {{Applications}}},
  shorttitle = {A {{Systematic Review}} of {{Federated Learning}} in the {{Healthcare Area}}},
  author = {Prayitno and Shyu, Chi-Ren and Putra, Karisma Trinanda and Chen, Hsing-Chung and Tsai, Yuan-Yu and Hossain, K. S. M. Tozammel and Jiang, Wei and Shae, Zon-Yin},
  year = {2021},
  month = jan,
  journal = {Applied Sciences},
  volume = {11},
  number = {23},
  pages = {11191},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app112311191},
  urldate = {2024-11-01},
  abstract = {Recent advances in deep learning have shown many successful stories in smart healthcare applications with data-driven insight into improving clinical institutions' quality of care. Excellent deep learning models are heavily data-driven. The more data trained, the more robust and more generalizable the performance of the deep learning model. However, pooling the medical data into centralized storage to train a robust deep learning model faces privacy, ownership, and strict regulation challenges. Federated learning resolves the previous challenges with a shared global deep learning model using a central aggregator server. At the same time, patient data remain with the local party, maintaining data anonymity and security. In this study, first, we provide a comprehensive, up-to-date review of research employing federated learning in healthcare applications. Second, we evaluate a set of recent challenges from a data-centric perspective in federated learning, such as data partitioning characteristics, data distributions, data protection mechanisms, and benchmark datasets. Finally, we point out several potential challenges and future research directions in healthcare applications.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {artificial intelligence,data privacy-preserving,deep learning,federated learning,healthcare},
  file = {/home/james/Zotero/storage/IQ6733ZE/Prayitno et al. - 2021 - A Systematic Review of Federated Learning in the Healthcare Area From the Perspective of Data Prope.pdf}
}

@book{princeUnderstandingDeepLearning2024,
  title = {Understanding {{Deep Learning}}},
  author = {Prince, Simon},
  year = {2024},
  month = apr,
  publisher = {MIT Press},
  urldate = {2024-04-15}
}

@misc{PrivacyEnhancedFederatedLearning,
  title = {Privacy-{{Enhanced Federated Learning}}},
  journal = {Privacy Technology Research Group},
  urldate = {2024-09-04},
  abstract = {The Challenge Today's mobile intelligent devices boast increasingly powerful hardware, enabling data collection and processing at an unprecedented scale. Concurrently, [{\dots}]},
  howpublished = {https://research.csiro.au/isp/research/privacy\_mlai/privacy-enhanced-federated-learning/},
  langid = {australian},
  file = {/home/james/Zotero/storage/9AS9WAYQ/privacy-enhanced-federated-learning.html}
}

@misc{ProQuestEbookCentral,
  title = {{{ProQuest Ebook Central}} - {{Detail Page}}},
  urldate = {2021-08-10}
}

@article{qianSequenceDropoutBlockReducing2020,
  title = {Sequence-{{Dropout Block}} for {{Reducing Overfitting Problem}} in {{Image Classification}}},
  author = {Qian, Ledan and Hu, Libing and Zhao, Li and Wang, Tao and Jiang, Runhua},
  year = {2020},
  journal = {IEEE Access},
  volume = {8},
  pages = {62830--62840},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2020.2983774},
  urldate = {2024-10-23},
  abstract = {Overfitting is a common problem for computer vision applications It is a problem that when training convolution neural networks and is caused by lack of training data or network complexity. The novel sequence-dropout (SD) method is proposed in this paper to alleviate the problem of overfitting when training networks. The SD method works by dropping out units (channels of feature) from the network in a sequence, replacing the traditional operation of random omitting. Sophisticated aggregation strategies are used to obtain the global information of feature channels, and channel-wise weights are produced by gating mechanism. The SD method then selectively drops out the feature channels according to the channel-wise weights that represent the importance degree of each channel. The proposed SD block can be plugged into state-of-the-art backbone CNN models such as VGGNet and ResNet. The SD block is then evaluated on these models, demonstrating consistent performance gains over the baseline model on widely-used benchmark image classification datasets including MNIST, CIFAR-10, CIFAR-100, and ImageNet2012. Experimental results demonstrate that the superior performance of the SD block compared to other modern methods.},
  keywords = {Computer architecture,Computer vision,Convolution,Convolutional networks,image classification,Neural networks,overfitting,sequence-dropout,Task analysis,Training,Training data},
  file = {/home/james/Zotero/storage/9E4D84MT/Qian et al. - 2020 - Sequence-Dropout Block for Reducing Overfitting Problem in Image Classification.pdf;/home/james/Zotero/storage/L4Z2B9P7/9049145.html}
}

@article{qiModelAggregationTechniques2024,
  title = {Model Aggregation Techniques in Federated Learning: {{A}} Comprehensive Survey},
  shorttitle = {Model Aggregation Techniques in Federated Learning},
  author = {Qi, Pian and Chiaro, Diletta and Guzzo, Antonella and Ianni, Michele and Fortino, Giancarlo and Piccialli, Francesco},
  year = {2024},
  month = jan,
  journal = {Future Generation Computer Systems},
  volume = {150},
  pages = {272--293},
  issn = {0167-739X},
  doi = {10.1016/j.future.2023.09.008},
  urldate = {2024-09-07},
  abstract = {Federated learning (FL) is a distributed machine learning (ML) approach that enables models to be trained on client devices while ensuring the privacy of user data. Model aggregation, also known as model fusion, plays a vital role in FL. It involves combining locally generated models from client devices into a single global model while maintaining user data privacy. However, the accuracy and reliability of the resulting global model depend on the aggregation method chosen, making the selection of an appropriate method crucial. Initially, the simple averaging of model weights was the most commonly used method. However, due to its limitations in handling low-quality or malicious models, alternative techniques have been explored. As FL gains popularity in various domains, it is crucial to have a comprehensive understanding of the available model aggregation techniques and their respective strengths and limitations. However, there is currently a significant gap in the literature when it comes to systematic and comprehensive reviews of these techniques. To address this gap, this paper presents a systematic literature review encompassing 201 studies on model aggregation in FL. The focus is on summarizing the proposed techniques and the ones currently applied for model fusion. This survey serves as a valuable resource for researchers to enhance and develop new aggregation techniques, as well as for practitioners to select the most appropriate method for their FL applications.},
  keywords = {Artificial intelligence,Distributed machine learning,Federated learning,Machine learning,Model aggregation,Model fusion},
  file = {/home/james/Zotero/storage/3FQ3Q2CR/S0167739X23003333.html}
}

@article{rauniyarFederatedLearningMedical2024,
  title = {Federated {{Learning}} for {{Medical Applications}}: {{A Taxonomy}}, {{Current Trends}}, {{Challenges}}, and {{Future Research Directions}}},
  shorttitle = {Federated {{Learning}} for {{Medical Applications}}},
  author = {Rauniyar, Ashish and Hagos, Desta Haileselassie and Jha, Debesh and H{\aa}keg{\aa}rd, Jan Erik and Bagci, Ulas and Rawat, Danda B. and Vlassov, Vladimir},
  year = {2024},
  month = mar,
  journal = {IEEE Internet of Things Journal},
  volume = {11},
  number = {5},
  pages = {7374--7398},
  issn = {2327-4662},
  doi = {10.1109/JIOT.2023.3329061},
  urldate = {2024-10-22},
  abstract = {With the advent of the Internet of Things (IoT), artificial intelligence (AI), machine learning (ML), and deep learning (DL) algorithms, the landscape of data-driven medical applications has emerged as a promising avenue for designing robust and scalable diagnostic and prognostic models from medical data. This has gained a lot of attention from both academia and industry, leading to significant improvements in healthcare quality. However, the adoption of AI-driven medical applications still faces tough challenges, including meeting security, privacy, and Quality-of-Service (QoS) standards. Recent developments in federated learning (FL) have made it possible to train complex machine-learned models in a distributed manner and have become an active research domain, particularly processing the medical data at the edge of the network in a decentralized way to preserve privacy and address security concerns. To this end, in this article, we explore the present and future of FL technology in medical applications where data sharing is a significant challenge. We delve into the current research trends and their outcomes, unraveling the complexities of designing reliable and scalable FL models. This article outlines the fundamental statistical issues in FL, tackles device-related problems, addresses security challenges, and navigates the complexity of privacy concerns, all while highlighting its transformative potential in the medical field. Our study primarily focuses on medical applications of FL, particularly in the context of global cancer diagnosis. We highlight the potential of FL to enable computer-aided diagnosis tools that address this challenge with greater effectiveness than traditional data-driven methods. Recent literature has shown that FL models are robust and generalize well to new data, which is essential for medical applications. We hope that this comprehensive review will serve as a checkpoint for the field, summarizing the current state of the art and identifying open problems and future research directions.},
  keywords = {Artificial intelligence (AI),Biomedical equipment,Cancer,communication,data privacy,Data privacy,edge computing,federated learning (FL),foundational model (FMs),Internet of Things,large language model (LLM),medical applications,Medical diagnostic imaging,Medical services,security,Surveys},
  file = {/home/james/Zotero/storage/E8E2SU9F/Rauniyar et al. - 2024 - Federated Learning for Medical Applications A Taxonomy, Current Trends, Challenges, and Future Rese.pdf;/home/james/Zotero/storage/VV4LY5GV/10304218.html}
}

@book{rebalaIntroductionMachineLearning2019,
  title = {An {{Introduction}} to {{Machine Learning}}},
  author = {Rebala, Gopinath and Ravi, Ajay and Churiwala, Sanjay},
  year = {2019},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-15729-6},
  urldate = {2021-08-02},
  isbn = {978-3-030-15728-9 978-3-030-15729-6}
}

@article{REGULATIONEU2016,
  title = {{{REGULATION}}  ({{EU}})  2016/  679  {{OF}}  {{THE}}  {{EUROPEAN}}  {{PARLIAMENT}}  {{AND}}  {{OF}}  {{THE}}  {{COUNCIL}}  -  of  27  {{April}}  2016  -  on  the  Protection  of  Natural  Persons  with  Regard  to  the  Processing  of  Personal  Data  and  on  the  Free  Movement  of  Such  Data,  and  Repealing  {{Directive}} 95/  46/  {{EC}}  ({{General}}  {{Data}}  {{Protection}}  {{Regulation}})},
  langid = {english},
  file = {/home/james/Zotero/storage/IXR9EAJP/REGULATION  (EU)  2016  679  OF  THE  EUROPEAN  PARLIAMENT  AND  OF  THE  COUNCIL  -  of  27  April.pdf}
}

@book{rehmanFederatedLearningSystems2021,
  title = {Federated {{Learning Systems}}: {{Towards Next-Generation AI}}},
  shorttitle = {Federated {{Learning Systems}}},
  editor = {Rehman, Muhammad Habib Ur and Gaber, Mohamed Medhat},
  year = {2021},
  series = {Studies in {{Computational Intelligence}}},
  volume = {965},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-70604-3},
  urldate = {2024-10-22},
  copyright = {https://www.springer.com/tdm},
  isbn = {978-3-030-70603-6 978-3-030-70604-3},
  langid = {english},
  file = {/home/james/Zotero/storage/F2LWRH2R/Rehman and Gaber - 2021 - Federated Learning Systems Towards Next-Generation AI.pdf}
}

@book{rehmanFederatedLearningSystems2021a,
  title = {Federated {{Learning Systems}}: {{Towards Next-Generation AI}}},
  shorttitle = {Federated {{Learning Systems}}},
  editor = {Rehman, Muhammad Habib Ur and Gaber, Mohamed Medhat},
  year = {2021},
  series = {Studies in {{Computational Intelligence}}},
  volume = {965},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-70604-3},
  urldate = {2024-10-22},
  copyright = {https://www.springer.com/tdm},
  isbn = {978-3-030-70603-6 978-3-030-70604-3},
  langid = {english},
  file = {/home/james/Zotero/storage/JH9BF9JW/Rehman and Gaber - 2021 - Federated Learning Systems Towards Next-Generation AI.pdf}
}

@misc{rostamzadehEthicsCreativityComputer2021,
  title = {Ethics and {{Creativity}} in {{Computer Vision}}},
  author = {Rostamzadeh, Negar and Denton, Emily and Petrini, Linda},
  year = {2021},
  month = dec,
  number = {arXiv:2112.03111},
  publisher = {arXiv},
  urldate = {2024-04-27},
  abstract = {This paper offers a retrospective of what we learnt from organizing the workshop Ethical Considerations in Creative applications of Computer Vision at CVPR 2021 conference and, prior to that, a series of workshops on Computer Vision for Fashion, Art and Design at ECCV 2018, ICCV 2019, and CVPR 2020. We hope this reflection will bring artists and machine learning researchers into conversation around the ethical and social dimensions of creative applications of computer vision.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Computers and Society,Computer Science - Machine Learning}
}

@misc{russakovskyImageNetLargeScale2015,
  title = {{{ImageNet Large Scale Visual Recognition Challenge}}},
  author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and {Fei-Fei}, Li},
  year = {2015},
  month = jan,
  number = {arXiv:1409.0575},
  publisher = {arXiv},
  urldate = {2024-04-15},
  abstract = {The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the five years of the challenge, and propose future directions and improvements.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,I.4.8,I.5.2}
}

@article{saeedSmartDetectionTomato2023,
  title = {Smart {{Detection}} of {{Tomato Leaf Diseases Using Transfer Learning-Based Convolutional Neural Networks}}},
  author = {Saeed, Alaa and {Abdel-Aziz}, A. A. and Mossad, Amr and Abdelhamid, Mahmoud A. and Alkhaled, Alfadhl Y. and Mayhoub, Muhammad},
  year = {2023},
  journal = {Agriculture},
  volume = {13},
  number = {1},
  pages = {139},
  publisher = {MDPI AG},
  address = {Basel, Switzerland},
  doi = {10.3390/agriculture13010139},
  urldate = {2024-10-22},
  abstract = {Plant diseases affect the availability and safety of plants for human and animal consumption and threaten food safety, thus reducing food availability and access, as well as reducing crop yield and quality. There is a need for novel disease detection methods that can be used to reduce plant losses due to disease. Thus, this study aims to diagnose tomato leaf diseases by classifying healthy and unhealthy tomato leaf images using two pre-trained convolutional neural networks (CNNs): Inception V3 and Inception ResNet V2. The two models were trained using an open-source database (PlantVillage) and field-recorded images with a total of 5225 images. The models were investigated with dropout rates of 5\%, 10\%, 15\%, 20\%, 25\%, 30\%, 40\%, and 50\%. The most important results showed that the Inception V3 model with a 50\% dropout rate and the Inception ResNet V2 model with a 15\% dropout rate, as they gave the best performance with an accuracy of 99.22\% and a loss of 0.03. The high-performance rate shows the possibility of utilizing CNNs models for diagnosing tomato diseases under field and laboratory conditions. It is also an approach that can be expanded to support an integrated system for diagnosing various plant diseases.},
  copyright = {{\copyright} 2023 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
  langid = {english},
  keywords = {Algorithms,Artificial intelligence,Artificial neural networks,Availability,Classification,Convolutional neural network,convolutional neural networks,Crop diseases,Crop yield,Crops,Datasets,deep learning,Deep learning,Disease detection,Economic,Food availability,Food consumption,Food safety,inception ResNet V2,inception V3,Laboratories,Leaves,Machine learning,Medical imaging,Neural networks,Plant diseases,Tomato,tomato disease diagnosis,Tomatoes,Transfer learning},
  file = {/home/james/Zotero/storage/2TXFYYDJ/Saeed et al. - 2023 - Smart Detection of Tomato Leaf Diseases Using Transfer Learning-Based Convolutional Neural Networks.pdf}
}

@article{saltzCurrentApproachesExecuting2022,
  title = {Current {{Approaches}} for {{Executing Big Data Science Projects}}---a {{Systematic Literature Review}}},
  author = {Saltz, Jeffrey S. and Krasteva, Iva},
  year = {2022},
  month = feb,
  journal = {PeerJ Computer Science},
  abstract = {There is an increasing number of big data science projects aiming to create value for organizations by improving decision making, streamlining costs or enhancing business processes. However, many of these projects fail to deliver the expected value. It has been observed that a key reason many data science projects don't succeed is not technical in nature, but rather, the process aspect of the project. The lack of established and mature methodologies for executing data science projects has been frequently noted as a reason for these project failures. To help move the field forward, this study presents a systematic review of research focused on the adoption of big data science process frameworks. The goal of the review was to identify (1) the key themes, with respect to current research on how teams execute data science projects, (2) the most common approaches regarding how data science projects are organized, managed and coordinated, (3) the activities involved in a data science projects life cycle, and (4) the implications for future research in this field. In short, the review identified 68 primary studies thematically classified in six categories. Two of the themes (workflow and agility) accounted for approximately 80},
  keywords = {Agile data science,Agility,Big data,Big data science,Big data science workflows,Computers,Context,Data,Data mining,Data science,Decision making,Expected values,Literature reviews,Methods,Process frameworks,Project execution,Project management,Streamlining,Systematic review,Teams,Workflow}
}

@article{saltzPredictingDataScience2017,
  title = {Predicting {{Data Science Sociotechnical Execution Challenges}} by {{Categorizing Data Science Projects}}},
  author = {Saltz, Jeffrey and Shamshurin, Ivan and Connors, Colin},
  year = {2017},
  journal = {Journal of the Association for Information Science and Technology},
  volume = {68},
  number = {12},
  pages = {2720--2728},
  doi = {10.1002/asi.23873},
  abstract = {The challenge in executing a data science project is more than just identifying the best algorithm and tool set to use. Additional sociotechnical challenges include items such as how to define the project goals and how to ensure the project is effectively managed. This paper reports on a set of case studies where researchers were embedded within data science teams and where the researcher observations and analysis was focused on the attributes that can help describe data science projects and the challenges faced by the teams executing these projects, as opposed to the algorithms and technologies that were used to perform the analytics. Based on our case studies, we identified 14 characteristics that can help describe a data science project. We then used these characteristics to create a model that defines two key dimensions of the project. Finally, by clustering the projects within these two dimensions, we identified four types of data science projects, and based on the type of project, we identified some of the sociotechnical challenges that project teams should expect to encounter when executing data science projects.}
}

@article{sandhuMedicalImagingApplications2023,
  title = {Medical {{Imaging Applications}} of {{Federated Learning}}},
  author = {Sandhu, Sukhveer Singh and Gorji, Hamed Taheri and Tavakolian, Pantea and Tavakolian, Kouhyar and Akhbardeh, Alireza},
  year = {2023},
  month = oct,
  journal = {Diagnostics},
  volume = {13},
  number = {19},
  pages = {3140},
  issn = {2075-4418},
  doi = {10.3390/diagnostics13193140},
  urldate = {2024-08-21},
  abstract = {Since its introduction in 2016, researchers have applied the idea of Federated Learning (FL) to several domains ranging from edge computing to banking. The technique's inherent security benefits, privacy-preserving capabilities, ease of scalability, and ability to transcend data biases have motivated researchers to use this tool on healthcare datasets. While several reviews exist detailing FL and its applications, this review focuses solely on the different applications of FL to medical imaging datasets, grouping applications by diseases, modality, and/or part of the body. This Systematic Literature review was conducted by querying and consolidating results from ArXiv, IEEE Xplorer, and PubMed. Furthermore, we provide a detailed description of FL architecture, models, descriptions of the performance achieved by FL models, and how results compare with traditional Machine Learning (ML) models. Additionally, we discuss the security benefits, highlighting two primary forms of privacy-preserving techniques, including homomorphic encryption and differential privacy. Finally, we provide some background information and context regarding where the contributions lie. The background information is organized into the following categories: architecture/setup type, data-related topics, security, and learning types. While progress has been made within the field of FL and medical imaging, much room for improvement and understanding remains, with an emphasis on security and data issues remaining the primary concerns for researchers. Therefore, improvements are constantly pushing the field forward. Finally, we highlighted the challenges in deploying FL in medical imaging applications and provided recommendations for future directions.},
  pmcid = {PMC10572559},
  pmid = {37835883}
}

@article{santosAvoidingOverfittingSurvey2022,
  title = {Avoiding {{Overfitting}}: {{A Survey}} on {{Regularization Methods}} for {{Convolutional Neural Networks}}},
  shorttitle = {Avoiding {{Overfitting}}},
  author = {Santos, Claudio Filipi Gon{\c c}alves Dos and Papa, Jo{\~a}o Paulo},
  year = {2022},
  month = sep,
  journal = {ACM Comput. Surv.},
  volume = {54},
  number = {10s},
  pages = {213:1--213:25},
  issn = {0360-0300},
  doi = {10.1145/3510413},
  urldate = {2024-10-23},
  abstract = {Several image processing tasks, such as image classification and object detection, have been significantly improved using Convolutional Neural Networks (CNN). Like ResNet and EfficientNet, many architectures have achieved outstanding results in at least one dataset by the time of their creation. A critical factor in training concerns the network's regularization, which prevents the structure from overfitting. This work analyzes several regularization methods developed in the past few years, showing significant improvements for different CNN models. The works are classified into three main areas: the first one is called ``data augmentation,'' where all the techniques focus on performing changes in the input data. The second, named ``internal changes,'' aims to describe procedures to modify the feature maps generated by the neural network or the kernels. The last one, called ``label,'' concerns transforming the labels of a given input. This work presents two main differences comparing to other available surveys about regularization: (i) the first concerns the papers gathered in the manuscript, which are not older than five years, and (ii) the second distinction is about reproducibility, i.e., all works referred here have their code available in public repositories or they have been directly implemented in some framework, such as TensorFlow or Torch.},
  file = {/home/james/Zotero/storage/SYTX7Q8W/Santos and Papa - 2022 - Avoiding Overfitting A Survey on Regularization Methods for Convolutional Neural Networks.pdf}
}

@article{sarvamangalaConvolutionalNeuralNetworks2022,
  title = {Convolutional {{Neural Networks}} in {{Medical Image Understanding}}: {{A Survey}}},
  shorttitle = {Convolutional {{Neural Networks}} in {{Medical Image Understanding}}},
  author = {Sarvamangala, D. R. and Kulkarni, Raghavendra V.},
  year = {2022},
  journal = {Evolutionary Intelligence},
  volume = {15},
  number = {1},
  pages = {1--22},
  issn = {1864-5909},
  doi = {10.1007/s12065-020-00540-3},
  urldate = {2024-08-20},
  abstract = {Imaging techniques are used to capture anomalies of the human body. The captured images must be understood for diagnosis, prognosis and treatment planning of the anomalies. Medical image understanding is generally performed by skilled medical professionals. However, the scarce availability of human experts and the fatigue and rough estimate procedures involved with them limit the effectiveness of image understanding performed by skilled medical professionals. Convolutional neural networks (CNNs) are effective tools for image understanding. They have outperformed human experts in many image understanding tasks. This article aims to provide a comprehensive survey of applications of CNNs in medical image understanding. The underlying objective is to motivate medical image understanding researchers to extensively apply CNNs in their research and diagnosis. A brief introduction to CNNs has been presented. A discussion on CNN and its various award-winning frameworks have been presented. The major medical image understanding tasks, namely image classification, segmentation, localization and detection have been introduced. Applications of CNN in medical image understanding of the ailments of brain, breast, lung and other organs have been surveyed critically and comprehensively. A critical discussion on some of the challenges is also presented.},
  pmcid = {PMC7778711},
  pmid = {33425040}
}

@misc{schmidhuberAnnotatedHistoryModern2022,
  title = {Annotated {{History}} of {{Modern AI}} and {{Deep Learning}}},
  author = {Schmidhuber, Juergen},
  year = {2022},
  month = dec,
  number = {arXiv:2212.11279},
  publisher = {arXiv},
  urldate = {2024-04-15},
  abstract = {Machine learning is the science of credit assignment: finding patterns in observations that predict the consequences of actions and help to improve future performance. Credit assignment is also required for human understanding of how the world works, not only for individuals navigating daily life, but also for academic professionals like historians who interpret the present in light of past events. Here I focus on the history of modern artificial intelligence (AI) which is dominated by artificial neural networks (NNs) and deep learning, both conceptually closer to the old field of cybernetics than to what's been called AI since 1956 (e.g., expert systems and logic programming). A modern history of AI will emphasize breakthroughs outside of the focus of traditional AI text books, in particular, mathematical foundations of today's NNs such as the chain rule (1676), the first NNs (linear regression, circa 1800), and the first working deep learners (1965-). From the perspective of 2022, I provide a timeline of the -- in hindsight -- most important relevant events in the history of NNs, deep learning, AI, computer science, and mathematics in general, crediting those who laid foundations of the field. The text contains numerous hyperlinks to relevant overview sites from my AI Blog. It supplements my previous deep learning survey (2015) which provides hundreds of additional references. Finally, to round it off, I'll put things in a broader historic context spanning the time since the Big Bang until when the universe will be many times older than it is now.},
  keywords = {Computer Science - Neural and Evolutionary Computing}
}

@article{schratzHyperparameterTuningPerformance2019,
  title = {Hyperparameter Tuning and Performance Assessment of Statistical and Machine-Learning Algorithms Using Spatial Data},
  author = {Schratz, Patrick and Muenchow, Jannes and Iturritxa, Eugenia and Richter, Jakob and Brenning, Alexander},
  year = {2019},
  month = aug,
  journal = {Ecological Modelling},
  volume = {406},
  pages = {109--120},
  issn = {0304-3800},
  doi = {10.1016/j.ecolmodel.2019.06.002},
  urldate = {2024-09-30},
  abstract = {While the application of machine-learning algorithms has been highly simplified in the last years due to their well-documented integration in commonly used statistical programming languages (such as R or Python), there are several practical challenges in the field of ecological modeling related to unbiased performance estimation. One is the influence of spatial autocorrelation in both hyperparameter tuning and performance estimation. Grouped cross-validation strategies have been proposed in recent years in environmental as well as medical contexts to reduce bias in predictive performance. In this study we show the effects of spatial autocorrelation on hyperparameter tuning and performance estimation by comparing several widely used machine-learning algorithms such as boosted regression trees (BRT), k-nearest neighbor (KNN), random forest (RF) and support vector machine (SVM) with traditional parametric algorithms such as logistic regression (GLM) and semi-parametric ones like generalized additive models (GAM) in terms of predictive performance. Spatial and non-spatial cross-validation methods were used to evaluate model performances aiming to obtain bias-reduced performance estimates. A detailed analysis on the sensitivity of hyperparameter tuning when using different resampling methods (spatial/non-spatial) was performed. As a case study the spatial distribution of forest disease (Diplodia sapinea) in the Basque Country (Spain) was investigated using common environmental variables such as temperature, precipitation, soil and lithology as predictors. Random Forest (mean Brier score estimate of 0.166) outperformed all other methods with regard to predictive accuracy. Though the sensitivity to hyperparameter tuning differed between the ML algorithms, there were in most cases no substantial differences between spatial and non-spatial partitioning for hyperparameter tuning. However, spatial hyperparameter tuning maintains consistency with spatial estimation of classifier performance and should be favored over non-spatial hyperparameter optimization. High performance differences (up to 47\%) between the bias-reduced (spatial cross-validation) and overoptimistic (non-spatial cross-validation) cross-validation settings showed the high need to account for the influence of spatial autocorrelation. Overoptimistic performance estimates may lead to false actions in ecological decision making based on biased model predictions.},
  keywords = {Hyperparameter tuning,Machine-learning,Spatial autocorrelation,Spatial cross-validation,Spatial modeling}
}

@article{seatonFactCheckingInformation2020,
  title = {Fact {{Checking}} and {{Information}} in the {{Age}} of {{Covid}}},
  author = {Seaton, Jean and Sippitt, Amy and Worthy, Ben},
  year = {2020},
  month = jul,
  journal = {Political Quarterly},
  volume = {91},
  number = {3},
  pages = {578--584},
  publisher = {Wiley-Blackwell},
  issn = {00323179},
  doi = {10.1111/1467-923X.12910},
  urldate = {2021-08-09},
  abstract = {The Covid-19 pandemic has revealed and accelerated an information crisis as well as a health one. What we discover about Covid 19, how it spreads, to whom and why and how best to mitigate it---all depend on information. The essays in this special section, which this article introduces, explore the importance of information and the fundamental role of fact checkers in understanding how information flows, why mistakes are made, and how to counteract them. Fact checking as an idea and a practice emerged in the early twenty-first century, developed as a positive beacon to counteract a growing sense that information could no longer be trusted. Now, more than a decade after its creation, fact checking sits within a far more complex and chaotic media context, and its expertise and understanding has never been so important. We need to understand what fact checkers do because they are grappling with how to tether us to reality.},
  keywords = {COMMON misconceptions,Covid-19,COVID-19 pandemic,FACEBOOK (Web resource),fact checking,FACT checking,information,media,misinformation,transparency,TRANSPARENCY in government}
}

@misc{SentimentrPackageRDocumentation,
  title = {Sentimentr {{Package}} - {{RDocumentation}}},
  urldate = {2021-08-03}
}

@article{sharmaComprehensiveSurveyImage2023,
  title = {A {{Comprehensive Survey}} on {{Image Captioning}}: {{From Handcrafted}} to {{Deep Learning-Based Techniques}}, a {{Taxonomy}} and {{Open Research Issues}}},
  shorttitle = {A {{Comprehensive Survey}} on {{Image Captioning}}},
  author = {Sharma, Himanshu and Padha, Devanand},
  year = {2023},
  month = apr,
  journal = {Artificial Intelligence Review},
  volume = {56},
  number = {11},
  pages = {13619--13661},
  issn = {0269-2821},
  doi = {10.1007/s10462-023-10488-2},
  urldate = {2024-05-22},
  abstract = {Image captioning is a pretty modern area of the convergence of computer vision and natural language processing and is widely used in a range of applications such as multi-modal search, robotics, security, remote sensing, medical, and visual aid. The image captioning techniques have witnessed a paradigm shift from classical machine-learning-based approaches to the most contemporary deep learning-based techniques. We present an in-depth investigation of image captioning methodologies in this survey using our proposed taxonomy. Furthermore, the study investigates several eras of image captioning advancements, including template-based, retrieval-based, and encoder-decoder-based models. We also explore captioning in languages other than English. A thorough investigation of benchmark image captioning datasets and assessment measures is also discussed. The effectiveness of real-time image captioning is a severe barrier that prevents its use in sensitive applications such as visual aid, security, and medicine. Another observation from our research is the scarcity of personalized domain datasets that limits its adoption into more advanced issues. Despite influential contributions from several academics, further efforts are required to construct substantially robust and reliable image captioning models.},
  keywords = {Attention-based image captioning,Encoder-decoder architecture,Image captioning,Multimodal embedding}
}

@article{shellerFederatedLearningMedicine2020,
  title = {Federated Learning in Medicine: Facilitating Multi-Institutional Collaborations without Sharing Patient Data},
  shorttitle = {Federated Learning in Medicine},
  author = {Sheller, Micah J. and Edwards, Brandon and Reina, G. Anthony and Martin, Jason and Pati, Sarthak and Kotrotsou, Aikaterini and Milchenko, Mikhail and Xu, Weilin and Marcus, Daniel and Colen, Rivka R. and Bakas, Spyridon},
  year = {2020},
  month = jul,
  journal = {Scientific Reports},
  volume = {10},
  number = {1},
  pages = {12598},
  publisher = {Nature Publishing Group},
  issn = {2045-2322},
  doi = {10.1038/s41598-020-69250-1},
  urldate = {2024-09-05},
  abstract = {Several studies underscore the potential of deep learning in identifying complex patterns, leading to diagnostic and prognostic biomarkers. Identifying sufficiently large and diverse datasets, required for training, is a significant challenge in medicine and can rarely be found in individual institutions. Multi-institutional collaborations based on centrally-shared patient data face privacy and ownership challenges. Federated learning is a novel paradigm for data-private multi-institutional collaborations, where model-learning leverages all available data without sharing data between institutions, by distributing the model-training to the data-owners and aggregating their results. We show that federated learning among 10 institutions results in models reaching 99\% of the model quality achieved with centralized data, and evaluate generalizability on data from institutions outside the federation. We further investigate the effects of data distribution across collaborating institutions on model quality and learning patterns, indicating that increased access to data through data private multi-institutional collaborations can benefit model quality more than the errors introduced by the collaborative method. Finally, we compare with other collaborative-learning approaches demonstrating the superiority of federated learning, and discuss practical implementation considerations. Clinical adoption of federated learning is expected to lead to models trained on datasets of unprecedented size, hence have a catalytic impact towards precision/personalized medicine.},
  copyright = {2020 The Author(s)},
  langid = {english},
  keywords = {Biomedical engineering,Brain imaging,Cancer,CNS cancer,Computational science,Health care,Medical imaging,Scientific data},
  file = {/home/james/Zotero/storage/FU2TAQI4/Sheller et al. - 2020 - Federated learning in medicine facilitating multi-institutional collaborations without sharing pati.pdf}
}

@article{ShibbolethAuthenticationRequest,
  title = {Shibboleth {{Authentication Request}}},
  urldate = {2024-08-19}
}

@article{shortenSurveyImageData2019,
  title = {A Survey on {{Image Data Augmentation}} for {{Deep Learning}}},
  author = {Shorten, Connor and Khoshgoftaar, Taghi M.},
  year = {2019},
  month = jul,
  journal = {Journal of Big Data},
  volume = {6},
  number = {1},
  pages = {60},
  issn = {2196-1115},
  doi = {10.1186/s40537-019-0197-0},
  urldate = {2024-09-30},
  abstract = {Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.},
  keywords = {Big data,Data Augmentation,Deep Learning,GANs,Image data},
  file = {/home/james/Zotero/storage/GVHWYHM8/Shorten and Khoshgoftaar - 2019 - A survey on Image Data Augmentation for Deep Learning.pdf;/home/james/Zotero/storage/SR4PZAEB/s40537-019-0197-0.html}
}

@book{shuDisinformationMisinformationFake2020,
  title = {Disinformation, {{Misinformation}}, and {{Fake News}} in {{Social Media}}: {{Emerging Research Challenges}} and {{Opportunities}}},
  shorttitle = {Disinformation, {{Misinformation}}, and {{Fake News}} in {{Social Media}}},
  editor = {Shu, Kai and Wang, Suhang and Lee, Dongwon and Liu, Huan},
  year = {2020},
  series = {Lecture {{Notes}} in {{Social Networks}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-42699-6},
  urldate = {2021-09-05},
  isbn = {978-3-030-42698-9 978-3-030-42699-6}
}

@article{shuklaInterpretingSVMMedical2020,
  title = {Interpreting {{SVM}} for Medical Images Using {{Quadtree}}},
  author = {Shukla, Prashant and Verma, Abhishek and Abhishek and Verma, Shekhar and Kumar, Manish},
  year = {2020},
  journal = {Multimedia Tools and Applications},
  volume = {79},
  number = {39-40},
  pages = {29353},
  publisher = {Nature Publishing Group},
  doi = {10.1007/s11042-020-09431-2},
  urldate = {2024-09-04},
  abstract = {In this paper, we propose a quadtree based approach to capture the spatial information of medical images for explaining nonlinear SVM prediction. In medical image classification, interpretability becomes important to understand why the adopted model works. ...},
  langid = {english},
  pmid = {32837249},
  file = {/home/james/Zotero/storage/7IANA8BM/Shukla et al. - 2020 - Interpreting SVM for medical images using Quadtree.pdf;/home/james/Zotero/storage/75ZKH5V2/PMC7417748.html}
}

@article{sikandarIntegratingGenerativeAI2024,
  title = {Integrating {{Generative AI}} and {{Federated Learning}} for {{Privacy Preserved Sequence-Based Stomach Adenocarcinoma Detection}}},
  author = {Sikandar, Misba and Din, Ikram Ud and Almogren, Ahmad},
  year = {2024},
  journal = {IEEE Transactions on Consumer Electronics},
  pages = {1--1},
  issn = {1558-4127},
  doi = {10.1109/TCE.2024.3423786},
  urldate = {2024-10-22},
  abstract = {Stomach Adenocarcinoma (STAD) significantly impacts global cancer mortality rates. Recent strides in artificial intelligence (AI), machine learning (ML), and deep learning (DL) have primarily harnessed imaging techniques like CT, X-rays, PET, and MRI for cancer detection. Concurrently, the rapidly growing volume of genomic big data presents an untapped reservoir for identifying genetic mutations characteristic of STAD. Our research explores this avenue by examining gene amino acid sequences altered by STAD. We employ physical properties of amino acids, i.e., Electro-Ion Interaction Pseudopotential (EIIP) values and Kidera factors in feature extraction, a novel strategy in STAD diagnostics. To address the issue of class imbalance, we incorporate generative AI to produce additional data samples. Addressing the privacy and security challenges associated with data centralization in healthcare, we propose Fed\_ANN11, an artificial neural network (ANN) model developed in a federated environment following an initial deployment as ANN11. Our model demonstrates remarkable accuracy in both simple and federated environments with extracted feature sets, namely, EIIP-based and Kidera factors-based. We found that EIIP-based features eclipse Kidera factors in performance. In a simple setting, the proposed model achieved a testing accuracy of 86\% and a training accuracy of 88\% for STAD detection using the EIIP-based feature set. In a federated environment, it achieved an accuracy of 0.94\% in testing and 0.99\% in training for STAD detection using the EIIP-based feature set. Moreover, our proposed model shows significant performance compared to existing state-of-the-art methods. Fed\_ANN11 not only excels in diagnostic precision but also upholds stringent big data security and privacy protocols, heralding a paradigm shift in AI's role in healthcare.},
  keywords = {Amino Acid Sequences Genomic Data Analysis,Amino acids,Artificial intelligence,Cancer,Data privacy,Feature extraction,Federated Learning,Genetic Mutations,Medical services,Stomach Adenocarcinoma Detection,Training},
  file = {/home/james/Zotero/storage/X4JKXLK3/Sikandar et al. - 2024 - Integrating Generative AI and Federated Learning for Privacy Preserved Sequence-Based Stomach Adenoc.pdf;/home/james/Zotero/storage/DP7G425W/10587004.html}
}

@article{sohLearningCNNLSTMArchitectures,
  title = {Learning {{CNN-LSTM Architectures}} for {{Image Caption Generation}}},
  author = {Soh, Moses},
  abstract = {Automatic image caption generation brings together recent advances in natural language processing and computer vision. This work implements a generative CNN-LSTM model that beats human baselines by 2.7 BLEU-4 points and is close to matching (3.8 CIDEr points lower) the current state of the art. Experiments on the MSCOCO dataset set shows that it generates sensible and accurate captions in a majority of cases, and hyperparameter tuning using dropout and number of LSTM layers allow us to alleviate the effects of overfitting. We also demonstrate that semantically-close emitted words (e.g. 'plate' and 'bowl') move the LSTM hidden state in similar ways despite differing previous contexts, and that divergences in hidden state occur only upon emission of semantically-distant words (e.g. 'vase' and 'food'). This gives semantic meaning to the interaction between learned word embeddings and the LSTM hidden states. To our knowledge, this is a novel contribution to the literature.}
}

@article{songClinicallyApplicableHistopathological2020,
  title = {Clinically Applicable Histopathological Diagnosis System for Gastric Cancer Detection Using Deep Learning},
  author = {Song, Zhigang and Zou, Shuangmei and Zhou, Weixun and Huang, Yong and Shao, Liwei and Yuan, Jing and Gou, Xiangnan and Jin, Wei and Wang, Zhanbo and Chen, Xin and Ding, Xiaohui and Liu, Jinhong and Yu, Chunkai and Ku, Calvin and Liu, Cancheng and Sun, Zhuo and Xu, Gang and Wang, Yuefeng and Zhang, Xiaoqing and Wang, Dandan and Wang, Shuhao and Xu, Wei and Davis, Richard C. and Shi, Huaiyin},
  year = {2020},
  month = aug,
  journal = {Nature Communications},
  volume = {11},
  number = {1},
  pages = {4294},
  issn = {2041-1723},
  doi = {10.1038/s41467-020-18147-8},
  urldate = {2024-09-08},
  abstract = {Abstract             The early detection and accurate histopathological diagnosis of gastric cancer increase the chances of successful treatment. The worldwide shortage of pathologists offers a unique opportunity for the use of artificial intelligence assistance systems to alleviate the workload and increase diagnostic accuracy. Here, we report a clinically applicable system developed at the Chinese PLA General Hospital, China, using a deep convolutional neural network trained with 2,123 pixel-level annotated H\&E-stained whole slide images. The model achieves a sensitivity near 100\% and an average specificity of 80.6\% on a real-world test dataset with 3,212 whole slide images digitalized by three scanners. We show that the system could aid pathologists in improving diagnostic accuracy and preventing misdiagnoses. Moreover, we demonstrate that our system performs robustly with 1,582 whole slide images from two other medical centres. Our study suggests the feasibility and benefits of using histopathological artificial intelligence assistance systems in routine practice scenarios.},
  langid = {english},
  file = {/home/james/Zotero/storage/YMLIF76J/Song et al. - 2020 - Clinically applicable histopathological diagnosis system for gastric cancer detection using deep lea.pdf}
}

@book{soriaolivasHandbookResearchMachine2010,
  title = {Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques},
  shorttitle = {Handbook of Research on Machine Learning Applications and Trends},
  editor = {Soria Olivas, Emilio and {IGI Global}},
  year = {2010},
  publisher = {IGI Global (701 E. Chocolate Avenue, Hershey, Pennsylvania, 17033, USA)},
  address = {Hershey, Pa},
  doi = {10.4018/978-1-60566-766-9},
  isbn = {978-1-60566-766-9 978-1-60566-767-6},
  langid = {english},
  file = {/home/james/Zotero/storage/DMJNMHEJ/Soria Olivas and IGI Global - 2010 - Handbook of research on machine learning applications and trends algorithms, methods, and technique.pdf}
}

@misc{SpreadTrueFalse,
  title = {The {{Spread}} of {{True}} and {{False News Online}} {\textbackslash}textbar {{Science}}},
  urldate = {2021-08-16}
}

@misc{StanfordnlpGloVe2024,
  title = {Stanfordnlp/{{GloVe}}},
  year = {2024},
  month = may,
  urldate = {2024-05-15},
  abstract = {Software in C and data files for the popular GloVe model for distributed word representations, a.k.a. word vectors or embeddings},
  copyright = {Apache-2.0},
  annotation = {Published: Stanford NLP}
}

@misc{StomachGastricCancer,
  title = {Stomach ({{Gastric}}) {{Cancer Stages}} {\textbackslash}textbar {{How Far Has Stomach Cancer Spread}}?},
  urldate = {2024-08-22},
  abstract = {Staging is the process of finding out how far cancer has spread. Learn about the stages of stomach cancer and how It helps determine prognosis and treatment.}
}

@article{subramanianEffectivenessDecentralizedFederated2022,
  title = {Effectiveness of {{Decentralized Federated Learning Algorithms}} in {{Healthcare}}: {{A Case Study}} on {{Cancer Classification}}},
  shorttitle = {Effectiveness of {{Decentralized Federated Learning Algorithms}} in {{Healthcare}}},
  author = {Subramanian, Malliga and Rajasekar, Vani and Sathishkumar, V. E. and Shanmugavadivel, Kogilavani and Nandhini, P. S.},
  year = {2022},
  journal = {Electronics},
  volume = {11},
  number = {24},
  pages = {4117},
  publisher = {MDPI AG},
  address = {Basel, Switzerland},
  doi = {10.3390/electronics11244117},
  urldate = {2024-10-22},
  abstract = {Deep learning-based medical image analysis is an effective and precise method for identifying various cancer types. However, due to concerns over patient privacy, sharing diagnostic images across medical facilities is typically not permitted. Federated learning (FL) tries to construct a shared model across dispersed clients under such privacy-preserving constraints. Although there is a good chance of success, dealing with non-IID (non-independent and identical distribution) client data, which is a typical circumstance in real-world FL tasks, is still difficult for FL. We use two FL algorithms, FedAvg and FedProx, to manage client heterogeneity and non-IID data in a federated setting. A heterogeneous data split of the cancer datasets with three different forms of cancer---cervical, lung, and colon---is used to validate the efficacy of the FL. In addition, since hyperparameter optimization presents new difficulties in an FL setting, we also examine the impact of various hyperparameter values. We use Bayesian optimization to fine-tune the hyperparameters and identify the appropriate values in order to increase performance. Furthermore, we investigate the hyperparameter optimization in both local and global models of the FL environment. Through a series of experiments, we find that FedProx outperforms FedAvg in scenarios with significant levels of heterogeneity.},
  copyright = {{\copyright} 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
  langid = {english},
  keywords = {Algorithms,Artificial intelligence,Autonomous vehicles,Bayesian optimization,Cancer,Collaboration,Datasets,Deep learning,Environment models,Experiments,FedAvg,federated learning,Federated learning,FedProx,heterogeneity,Heterogeneity,Hyperparameter optimization,Image analysis,Image classification,Machine learning,Medical image computing,Medical imaging,non-IID,Optimization,Optimization techniques,Performance evaluation,Privacy},
  file = {/home/james/Zotero/storage/L8G7EM48/Subramanian et al. - 2022 - Effectiveness of Decentralized Federated Learning Algorithms in Healthcare A Case Study on Cancer C.pdf}
}

@article{subramanianEffectivenessDecentralizedFederated2022a,
  title = {Effectiveness of {{Decentralized Federated Learning Algorithms}} in {{Healthcare}}: {{A Case Study}} on {{Cancer Classification}}},
  shorttitle = {Effectiveness of {{Decentralized Federated Learning Algorithms}} in {{Healthcare}}},
  author = {Subramanian, Malliga and Rajasekar, Vani and Sathishkumar, V. E. and Shanmugavadivel, Kogilavani and Nandhini, P. S.},
  year = {2022},
  journal = {Electronics},
  volume = {11},
  number = {24},
  pages = {4117},
  publisher = {MDPI AG},
  address = {Basel, Switzerland},
  doi = {10.3390/electronics11244117},
  urldate = {2024-10-22},
  abstract = {Deep learning-based medical image analysis is an effective and precise method for identifying various cancer types. However, due to concerns over patient privacy, sharing diagnostic images across medical facilities is typically not permitted. Federated learning (FL) tries to construct a shared model across dispersed clients under such privacy-preserving constraints. Although there is a good chance of success, dealing with non-IID (non-independent and identical distribution) client data, which is a typical circumstance in real-world FL tasks, is still difficult for FL. We use two FL algorithms, FedAvg and FedProx, to manage client heterogeneity and non-IID data in a federated setting. A heterogeneous data split of the cancer datasets with three different forms of cancer---cervical, lung, and colon---is used to validate the efficacy of the FL. In addition, since hyperparameter optimization presents new difficulties in an FL setting, we also examine the impact of various hyperparameter values. We use Bayesian optimization to fine-tune the hyperparameters and identify the appropriate values in order to increase performance. Furthermore, we investigate the hyperparameter optimization in both local and global models of the FL environment. Through a series of experiments, we find that FedProx outperforms FedAvg in scenarios with significant levels of heterogeneity.},
  copyright = {{\copyright} 2022 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (https://creativecommons.org/licenses/by/4.0/). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.},
  langid = {english},
  keywords = {Algorithms,Artificial intelligence,Autonomous vehicles,Bayesian optimization,Cancer,Collaboration,Datasets,Deep learning,Environment models,Experiments,FedAvg,federated learning,Federated learning,FedProx,heterogeneity,Heterogeneity,Hyperparameter optimization,Image analysis,Image classification,Machine learning,Medical image computing,Medical imaging,non-IID,Optimization,Optimization techniques,Performance evaluation,Privacy},
  file = {/home/james/Zotero/storage/3ANG3Z78/Subramanian et al. - 2022 - Effectiveness of Decentralized Federated Learning Algorithms in Healthcare A Case Study on Cancer C.pdf}
}

@inproceedings{sudhakaraFishClassificationSystem2023,
  title = {Fish {{Classification System Using Customized Deep Residual Neural Networks}} on {{Small-Scale Underwater Images}}},
  booktitle = {Intelligent {{Computing}} and {{Applications}}},
  author = {Sudhakara, M. and Vijaya Shambhavi, Y. and Obulakonda Reddy, R. and Badrinath, N. and Reddy Madhavi, K.},
  editor = {Rao, B. Narendra Kumar and Balasubramanian, R. and Wang, Shiuh-Jeng and Nayak, Richi},
  year = {2023},
  pages = {327--337},
  publisher = {Springer Nature},
  address = {Singapore},
  doi = {10.1007/978-981-19-4162-7_31},
  abstract = {Recent improvements in marine science research have increased the importance of underwater fish species identification. Using technology to automate fish species identification would positively impact marine biology. Since deep learning techniques, image classification problems have become increasingly popular. Wild natural habitats make it harder to identify fish species because of the complex background and noise in the raw images. Some of the most advanced approaches for categorizing fish species in their natural habitats have been developed in the previous decade. This paper demonstrated an automated approach for classifying fish species based on deep residual networks. Existing transfer learning models do a good job working with smaller datasets, but not so effectively. A novel RESNET model (SmallerRESNET) is developed to reduce the overfitting generated by the standard pre-trained RESNET model. Convolutional and fully linked layers are used in the more straightforward form of the RESNET model. We evaluated and compared six different versions of the RESNET model. In addition to the number of convolutional and fully connected layers, the number of iterations required to achieve 80.56\% accuracy on training data, batch size, and the dropout layer is examined. Compared to the original RESNET model, the proposed and modified RESNET model with fewer layers obtained 90.26\% testing accuracy with a validation loss of 0.0916 on an untrained benchmark fish dataset. The inclusion of a dropout layer enhanced our proposed model's overall performance. It is more efficient with less memory, fewer training photos, and less computing complexity than its predecessor.},
  isbn = {978-981-19416-2-7},
  langid = {english},
  keywords = {Deep networks,Fish classification,RESNET,Uncontrolled habitat,Underwater images},
  file = {/home/james/Zotero/storage/NHTGC7LA/Sudhakara et al. - 2023 - Fish Classification System Using Customized Deep Residual Neural Networks on Small-Scale Underwater.pdf}
}

@misc{sunRevisitingUnreasonableEffectiveness2017,
  title = {Revisiting {{Unreasonable Effectiveness}} of {{Data}} in {{Deep Learning Era}}},
  author = {Sun, Chen and Shrivastava, Abhinav and Singh, Saurabh and Gupta, Abhinav},
  year = {2017},
  month = aug,
  number = {arXiv:1707.02968},
  publisher = {arXiv},
  urldate = {2024-05-22},
  abstract = {The success of deep learning in vision can be attributed to: (a) models with high capacity; (b) increased computational power; and (c) availability of large-scale labeled data. Since 2012, there have been significant advances in representation capabilities of the models and computational capabilities of GPUs. But the size of the biggest dataset has surprisingly remained constant. What will happen if we increase the dataset size by 10{\texttimes} or 100{\texttimes}? This paper takes a step towards clearing the clouds of mystery surrounding the relationship between `enormous data' and visual deep learning. By exploiting the JFT-300M dataset which has more than 375M noisy labels for 300M images, we investigate how the performance of current vision tasks would change if this data was used for representation learning. Our paper delivers some surprising (and some expected) findings. First, we find that the performance on vision tasks increases logarithmically based on volume of training data size. Second, we show that representation learning (or pretraining) still holds a lot of promise. One can improve performance on many vision tasks by just training a better base model. Finally, as expected, we present new state-of-theart results for different vision tasks including image classification, object detection, semantic segmentation and human pose estimation. Our sincere hope is that this inspires vision community to not undervalue the data and develop collective efforts in building larger datasets.},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition}
}

@misc{sydneyUniversityTechnologySydney,
  title = {University of {{Technology Sydney}}},
  author = {Sydney, University of Technology},
  publisher = {University of Technology Sydney},
  urldate = {2021-08-09},
  abstract = {The UTS: Handbook is the authoritative source of information on approved courses and subjects offered at University of Technology Sydney.},
  copyright = {Copyright, University of Technology, Sydney. Refer to the UTSWeb Copyright Statement (https://www.uts.edu.au/copyright.html).}
}

@article{szadkowskaDiagnosisTreatmentPeritoneal2023,
  title = {Diagnosis and {{Treatment}} of {{Peritoneal Carcinomatosis}} -- a {{Comprehensive Overview}}},
  author = {Szadkowska, Ma{\l}gorzata Anna and Pa{\l}ucki, Jakub and Cieszanowski, Andrzej},
  year = {2023},
  month = feb,
  journal = {Polish Journal of Radiology},
  volume = {88},
  pages = {e89-e97},
  issn = {1733-134X},
  doi = {10.5114/pjr.2023.125027},
  urldate = {2024-08-23},
  abstract = {Peritoneal carcinomatosis, which is the most common malignant process of the peritoneal cavity, originates mostly from colorectal, gastric, and gynaecological malignancies. The differential diagnosis is broad and covers primary peritoneal malignancies, as well as many benign disorders such as endometriosis, and inflammatory and infectious diseases. Peritoneal implants tend to locate in the areas of the physiological stasis of the peritoneal fluid: pelvic peritoneal reflections, right and left paracolic gutters, superior part of the sigmoid mesocolon, ileocolic area, and the right subdiaphragmatic space. The 3 most common imaging findings are ascites, nodular implants, and infiltration of the peritoneal fatty tissue. Several imaging modalities may be applied in patients with peritoneal carcinomatosis. Ultrasound has low sensitivity and specificity, and therefore plays only a marginal role. Computed tomography is the method of choice, due to its availability, cost-effectiveness, and relatively high sensitivity. The sensitivity of magnetic resonance imaging depends on the size of peritoneal implants -- in cases of implants larger than 10 mm is comparable to CT. Some studies suggest that PET/CT may be the most sensitive method, yet its usefulness in everyday practice is controversial. The Peritoneal Carcinomatosis Index (PCI) is a scale used to assess the tumour burden in the peritoneum and may serve as a communication tool between clinicians and radiologists. The imaging findings may influence the surgeon's decision on performing cytoreductive surgery, which may be followed by intraperitoneal chemotherapy (HIPEC or EPIC procedures). The introduction of these therapeutic methods has significantly improved the life expectancy of patients with peritoneal carcinomatosis.},
  pmcid = {PMC9995246},
  pmid = {36910885}
}

@misc{szegedyGoingDeeperConvolutions2014,
  title = {Going {{Deeper}} with {{Convolutions}}},
  author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  year = {2014},
  month = sep,
  number = {arXiv:1409.4842},
  publisher = {arXiv},
  urldate = {2024-04-08},
  abstract = {We propose a deep convolutional neural network architecture codenamed "Inception", which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@book{szeliskiComputerVisionAlgorithms2022,
  title = {Computer {{Vision}}: {{Algorithms}} and {{Applications}}},
  shorttitle = {Computer {{Vision}}},
  author = {Szeliski, Richard},
  year = {2022},
  series = {Texts in {{Computer Science}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-34372-9},
  urldate = {2024-08-23},
  copyright = {https://www.springer.com/tdm},
  isbn = {978-3-030-34371-2 978-3-030-34372-9}
}

@misc{tanFederatedLearningPreTrained2022,
  title = {Federated {{Learning}} from {{Pre-Trained Models}}: {{A Contrastive Learning Approach}}},
  shorttitle = {Federated {{Learning}} from {{Pre-Trained Models}}},
  author = {Tan, Yue and Long, Guodong and Ma, Jie and Liu, Lu and Zhou, Tianyi and Jiang, Jing},
  year = {2022},
  month = sep,
  number = {arXiv:2209.10083},
  eprint = {2209.10083},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2209.10083},
  urldate = {2024-09-04},
  abstract = {Federated Learning (FL) is a machine learning paradigm that allows decentralized clients to learn collaboratively without sharing their private data. However, excessive computation and communication demands pose challenges to current FL frameworks, especially when training large-scale models. To prevent these issues from hindering the deployment of FL systems, we propose a lightweight framework where clients jointly learn to fuse the representations generated by multiple fixed pre-trained models rather than training a large-scale model from scratch. This leads us to a more practical FL problem by considering how to capture more client-specific and class-relevant information from the pre-trained models and jointly improve each client's ability to exploit those off-the-shelf models. In this work, we design a Federated Prototype-wise Contrastive Learning (FedPCL) approach which shares knowledge across clients through their class prototypes and builds client-specific representations in a prototype-wise contrastive manner. Sharing prototypes rather than learnable model parameters allows each client to fuse the representations in a personalized way while keeping the shared knowledge in a compact form for efficient communication. We perform a thorough evaluation of the proposed FedPCL in the lightweight framework, measuring and visualizing its ability to fuse various pre-trained models on popular FL datasets.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security,Computer Science - Machine Learning},
  file = {/home/james/Zotero/storage/QW7PNFDD/Tan et al. - 2022 - Federated Learning from Pre-Trained Models A Contrastive Learning Approach.pdf}
}

@article{tangDevelopmentValidationRealtime2020,
  title = {Development and Validation of a Real-Time Artificial Intelligence-Assisted System for Detecting Early Gastric Cancer: {{A}} Multicentre Retrospective Diagnostic Study},
  shorttitle = {Development and Validation of a Real-Time Artificial Intelligence-Assisted System for Detecting Early Gastric Cancer},
  author = {Tang, Dehua and Wang, Lei and Ling, Tingsheng and Lv, Ying and Ni, Muhan and Zhan, Qiang and Fu, Yiwei and Zhuang, Duanming and Guo, Huimin and Dou, Xiaotan and Zhang, Wei and Xu, Guifang and Zou, Xiaoping},
  year = {2020},
  month = dec,
  journal = {EBioMedicine},
  volume = {62},
  pages = {103146},
  issn = {2352-3964},
  doi = {10.1016/j.ebiom.2020.103146},
  abstract = {BACKGROUND: We aimed to develop and validate a real-time deep convolutional neural networks (DCNNs) system for detecting early gastric cancer (EGC). METHODS: All 45,240 endoscopic images from 1364 patients were divided into a training dataset (35823 images from 1085 patients) and a validation dataset (9417 images from 279 patients). Another 1514 images from three other hospitals were used as external validation. We compared the diagnostic performance of the DCNN system with endoscopists, and then evaluated the performance of endoscopists with or without referring to the system. Thereafter, we evaluated the diagnostic ability of the DCNN system in video streams. The accuracy, sensitivity, specificity, positive predictive value, negative predictive value and Cohen's kappa coefficient were measured to assess the detection performance. FINDING: The DCNN system showed good performance in EGC detection in validation datasets, with accuracy (85.1\%-91.2\%), sensitivity (85.9\%-95.5\%), specificity (81.7\%-90.3\%), and AUC (0.887-0.940). The DCNN system showed better diagnostic performance than endoscopists and improved the performance of endoscopists. The DCNN system was able to process oesophagogastroduodenoscopy (OGD) video streams to detect EGC lesions in real time. INTERPRETATION: We developed a real-time DCNN system for EGC detection with high accuracy and stability. Multicentre prospective validation is needed to acquire high-level evidence for its clinical application. FUNDING: This work was supported by the National Natural Science Foundation of China (grant nos. 81672935 and 81871947), Jiangsu Clinical Medical Center of Digestive System Diseases and Gastrointestinal Cancer (grant no. YXZXB2016002), and Nanjing Science and Technology Development Foundation (grant no. 2017sb332019).},
  langid = {english},
  pmcid = {PMC7708824},
  pmid = {33254026},
  keywords = {Adult,Aged,Aged 80 and over,Artificial intelligence,Artificial Intelligence,Convolutional neural network,Detection,Early Detection of Cancer,Early gastric cancer,Endoscopy Gastrointestinal,Female,Humans,Male,Middle Aged,Neoplasm Grading,Neoplasm Staging,Reproducibility of Results,Retrospective Studies,ROC Curve,Stomach Neoplasms,Workflow},
  file = {/home/james/Zotero/storage/AJ5K4L8U/Tang et al. - 2020 - Development and validation of a real-time artificial intelligence-assisted system for detecting earl.pdf}
}

@misc{tanMnasNetPlatformAwareNeural2019,
  title = {{{MnasNet}}: {{Platform-Aware Neural Architecture Search}} for {{Mobile}}},
  shorttitle = {{{MnasNet}}},
  author = {Tan, Mingxing and Chen, Bo and Pang, Ruoming and Vasudevan, Vijay and Sandler, Mark and Howard, Andrew and Le, Quoc V.},
  year = {2019},
  month = may,
  number = {arXiv:1807.11626},
  publisher = {arXiv},
  urldate = {2024-04-20},
  abstract = {Designing convolutional neural networks (CNN) for mobile devices is challenging because mobile models need to be small and fast, yet still accurate. Although significant efforts have been dedicated to design and improve mobile CNNs on all dimensions, it is very difficult to manually balance these trade-offs when there are so many architectural possibilities to consider. In this paper, we propose an automated mobile neural architecture search (MNAS) approach, which explicitly incorporate model latency into the main objective so that the search can identify a model that achieves a good trade-off between accuracy and latency. Unlike previous work, where latency is considered via another, often inaccurate proxy (e.g., FLOPS), our approach directly measures real-world inference latency by executing the model on mobile phones. To further strike the right balance between flexibility and search space size, we propose a novel factorized hierarchical search space that encourages layer diversity throughout the network. Experimental results show that our approach consistently outperforms state-of-the-art mobile CNN models across multiple vision tasks. On the ImageNet classification task, our MnasNet achieves 75.2\% top-1 accuracy with 78ms latency on a Pixel phone, which is 1.8x faster than MobileNetV2 [29] with 0.5\% higher accuracy and 2.3x faster than NASNet [36] with 1.2\% higher accuracy. Our MnasNet also achieves better mAP quality than MobileNets for COCO object detection. Code is at https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
}

@misc{tanNeuralImageCaptioning2019,
  title = {Neural {{Image Captioning}}},
  author = {Tan, Elaina and Sharma, Lakshay},
  year = {2019},
  month = jul,
  number = {arXiv:1907.02065},
  publisher = {arXiv},
  urldate = {2024-05-22},
  abstract = {In recent years, the biggest advances in major Computer Vision tasks, such as object recognition, handwrittendigit identification, facial recognition, and many others., have all come through the use of Convolutional Neural Networks (CNNs). Similarly, in the domain of Natural Language Processing, Recurrent Neural Networks (RNNs), and Long Short Term Memory networks (LSTMs) in particular, have been crucial to some of the biggest breakthroughs in performance for tasks such as machine translation, part-of-speech tagging, sentiment analysis, and many others. These individual advances have greatly benefited tasks even at the intersection of NLP and Computer Vision, and inspired by this success, we studied some existing neural image captioning models that have proven to work well. In this work, we study some existing captioning models that provide near state-of-the-art performances, and try to enhance one such model. We also present a simple image captioning model that makes use of a CNN, an LSTM, and the beam search1 algorithm, and study its performance based on various qualitative and quantitative metrics.},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
}

@article{tanTransferLearningApproach2023,
  title = {A {{Transfer Learning Approach}} to {{Breast Cancer Classification}} in a {{Federated Learning Framework}}},
  author = {Tan, Y. Nguyen and Tinh, Vo Phuc and Lam, Pham Duc and Nam, Nguyen Hoang and Khoa, Tran Anh},
  year = {2023},
  journal = {IEEE Access},
  volume = {11},
  pages = {27462--27476},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2023.3257562},
  urldate = {2024-10-23},
  abstract = {Artificial intelligence (AI) technologies have seen strong development. Many applications now use AI to diagnose breast cancer. However, most new research has only been conducted in centralized learning (CL) environments, which entails the risk of privacy breaches. Moreover, the accurate identification and localization of lesions and tumor prediction using AI technologies is expected to increase patients' likelihood of survival. To address these difficulties, we developed a federated learning (FL) facility that extracts features from participating environments rather than a CL facility. This study's novel contributions include (i) the application of transfer learning to extract data features from the region of interest (ROI) in an image, which aims to enable careful pre-processing and data enhancement for data training purposes; (ii) the use of synthetic minority oversampling technique (SMOTE) to process data, which aims to more uniformly classify data and improve diagnostic prediction performance for diseases; (iii) the application of FeAvg-CNN + MobileNet in an FL framework to ensure customer privacy and personal security; and (iv) the presentation of experimental results from different deep learning, transfer learning and FL models with balanced and imbalanced mammography datasets, which demonstrate that our solution leads to much higher classification performance than other approaches and is viable for use in AI healthcare applications.},
  keywords = {Artificial intelligence,breast cancer,Breast cancer,Cancer,Data models,Feature extraction,federated learning,Federated learning,Sampling methods,synthetic minority oversampling,transfer learning,Transfer learning,Tumors},
  file = {/home/james/Zotero/storage/6JJSXZPI/Tan et al. - 2023 - A Transfer Learning Approach to Breast Cancer Classification in a Federated Learning Framework.pdf}
}

@article{teoFederatedMachineLearning2024,
  title = {Federated Machine Learning in Healthcare: {{A}} Systematic Review on Clinical Applications and Technical Architecture},
  shorttitle = {Federated Machine Learning in Healthcare},
  author = {Teo, Zhen Ling and Jin, Liyuan and Liu, Nan and Li, Siqi and Miao, Di and Zhang, Xiaoman and Ng, Wei Yan and Tan, Ting Fang and Lee, Deborah Meixuan and Chua, Kai Jie and Heng, John and Liu, Yong and Goh, Rick Siow Mong and Ting, Daniel Shu Wei},
  year = {2024},
  month = feb,
  journal = {Cell Reports Medicine},
  volume = {5},
  number = {2},
  pages = {101419},
  issn = {26663791},
  doi = {10.1016/j.xcrm.2024.101419},
  urldate = {2024-10-23},
  langid = {english},
  file = {/home/james/Zotero/storage/AFGS8W87/Teo et al. - 2024 - Federated machine learning in healthcare A systematic review on clinical applications and technical.pdf}
}

@book{teohArtificialIntelligencePython2022,
  title = {Artificial {{Intelligence}} with {{Python}}},
  author = {Teoh, Teik Toe and Rong, Zheng},
  year = {2022},
  series = {Machine {{Learning}}: {{Foundations}}, {{Methodologies}}, and {{Applications}}},
  publisher = {Springer},
  address = {Singapore},
  doi = {10.1007/978-981-16-8615-3},
  urldate = {2024-04-17},
  copyright = {https://www.springer.com/tdm},
  isbn = {9789811686146 9789811686153},
  keywords = {Artificial Intelligence,Data Science,Deep Learning,Machine Learning,Neural Networks,Python}
}

@misc{thomaAreThereAny2016,
  type = {Forum Post},
  title = {Are There Any Image Classification Algorithms Which Are Not Neural Networks?},
  author = {Thoma, Martin},
  year = {2016},
  month = aug,
  journal = {Data Science Stack Exchange},
  urldate = {2024-09-04},
  file = {/home/james/Zotero/storage/66V2SCNU/are-there-any-image-classification-algorithms-which-are-not-neural-networks.html}
}

@misc{tianDropFilterDropoutConvolutions2018,
  title = {{{DropFilter}}: {{Dropout}} for {{Convolutions}}},
  shorttitle = {{{DropFilter}}},
  author = {Tian, Zhengsu Chen Jianwei Niu Qi},
  year = {2018},
  month = oct,
  number = {arXiv:1810.09849},
  publisher = {arXiv},
  urldate = {2024-04-26},
  abstract = {Using a large number of weights, deep neural networks have achieved remarkable performance on computer vision and natural language processing tasks. However deep neural networks usually use lots of parameters and suffer from overfitting. Dropout is a widely use method to deal with overfitting. Although dropout can significantly regularize fully connected layers in neural networks, it usually leads to suboptimal results when used for convolutional layers. To tackle this problem, we propose DropFilter, a dropout method for convolutional layers. DropFilter considers the filters rather than the neural units as the basic data drop units. Because it is observed that co-adaptations are more likely to occur inter rather than intra filters in convolutional layers. Using DropFilter, we remarkably improve the performance of convolutional networks on CIFAR and ImageNet.},
  keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@book{tolbertHybridProjectManagement2020,
  title = {Hybrid {{Project Management}}: {{Using Agile}} with {{Traditional PM Methodologies}} to {{Succeed}} on {{Modern Projects}}},
  shorttitle = {Hybrid {{Project Management}}},
  author = {Tolbert, Mark and Parente, Susan},
  year = {2020},
  publisher = {Business Expert Press},
  address = {New York, UNITED STATES},
  urldate = {2024-10-26},
  abstract = {Compared to a few decades ago, companies today are faced with a much more challenging environment providing successful products and solutions for their customers. They are dealing with global competition, very rapid change in technologies, and tremendous volatility in economic conditions. As project managers, we are helping our companies survive in this difficult landscape. We are "agents of change" and "drivers of change." The most important project management methodology today that will help us deal with this change and this volatility is Agile. However, no one process or project management methodology fits all situations! Agile is not a panacea for all projects. Many times, our projects are large enough and complex enough that some parts of the project are best suited to using a predictive planning approach, and other parts are more suited to using Agile. Therefore, a hybrid approach that mixes the traditional, waterfall approach with Agile is really required in many situations today. The agile community oftentimes has quite a negative view of hybrid approaches. Key writers on Agile often say that attempting to use hybrid will corrupt all attempts to use Agile, and will result in failure. In this book, the argument is made that integrating these methodologies can be done if approached the right way, and in fact, this is necessary today.},
  isbn = {978-1-952538-35-3},
  keywords = {Agile project management.,Project management.},
  file = {/home/james/Zotero/storage/R4QPNLYS/detail.html}
}

@misc{TwitterSociety2014,
  title = {Twitter and {{Society}}},
  year = {2014},
  month = jan,
  urldate = {2021-08-25},
  isbn = {9781453911709}
}

@misc{TypesStomachCancer,
  title = {Types of {{Stomach Cancer}} {\textbackslash}textbar {{Cancer Australia}}},
  urldate = {2024-08-19}
}

@misc{UnderstandingDeepLearning,
  title = {Understanding {{Deep Learning}}},
  urldate = {2024-04-15}
}

@misc{UnderstandingFederatedLearning2020,
  title = {Understanding {{Federated Learning Terminology}}},
  year = {2020},
  month = sep,
  journal = {OpenMined Blog},
  urldate = {2024-09-06},
  abstract = {In this article I'll attempt to untangle and disambiguate some terms that have emerged to describe different Federated Learning scenarios.},
  howpublished = {https://blog.openmined.org/federated-learning-types/},
  langid = {english},
  file = {/home/james/Zotero/storage/GRT7L8V3/federated-learning-types.html}
}

@misc{UsingLeadershipPractices,
  title = {Using the {{Leadership Practices Inventory}} to {{Measure Transformational}} and {{Transactional Leadership}}},
  doi = {10.1177/0013164497057004003},
  urldate = {2024-10-28},
  howpublished = {https://journals.sagepub.com/doi/epdf/10.1177/0013164497057004003},
  langid = {english},
  file = {/home/james/Zotero/storage/L5I8PFLS/Using the Leadership Practices Inventory to Measure Transformational and Transactional Leadership.pdf;/home/james/Zotero/storage/RWSSV7R7/0013164497057004003.html}
}

@article{vermaAutomaticImageCaption2024,
  title = {Automatic {{Image Caption Generation Using Deep Learning}}},
  author = {Verma, Akash and Yadav, Arun Kumar and Kumar, Mohit and Yadav, Divakar},
  year = {2024},
  month = jan,
  journal = {Multimedia Tools and Applications},
  volume = {83},
  number = {2},
  pages = {5309--5325},
  issn = {1573-7721},
  doi = {10.1007/s11042-023-15555-y},
  urldate = {2024-05-16},
  abstract = {Image captioning is an interesting and challenging task with applications in diverse domains such as image retrieval, organizing and locating images of users' interest, etc. It has huge potential for replacing manual caption generation for images and is especially suitable for large-scale image data. Recently, deep neural network based methods have achieved great success in the field of computer vision, machine translation, and language generation. In this paper, we propose an encoder-decoder based model that is capable of generating grammatically correct captions for images. This model makes use of VGG16 Hybrid Places 1365 as an encoder and LSTM as a decoder. To ensure the complete ground truth accuracy, the model is trained on the labeled Flickr8k and MS-COCO Captions datasets., Further, the model is evaluated using all popular standard metrics such as BLEU, METEOR, GLEU, and ROUGE\_L. Experimental results indicate that the proposed model obtained a BLEU-1 score of 0.6666, METEOR score of 0.5060, and GLEU score of 0.2469 on the Flickr8k dataset and BLEU-1 score 0.7350, METEOR score of 0.4768 and GLEU score 0.2798 on MS-COCO Caption dataset. Thus, the proposed method achieved a significant performance as compared to the state-of-art approaches. To evaluate the efficacy of the model further, we also show the results of caption generation from live sample images that reinforce the validity of the proposed approach.},
  keywords = {Caption,CNN (Convolutional Neural Network),Feature extraction,Image,LSTM (Long Short-Term Memory),Neural network,RNN (Recurrent Neural Network)}
}

@article{victorikechukwuResNet50VsVGG192021,
  title = {{{ResNet-50}} vs {{VGG-19}} vs Training from Scratch: {{A}} Comparative Analysis of the Segmentation and Classification of {{Pneumonia}} from Chest {{X-ray}} Images},
  shorttitle = {{{ResNet-50}} vs {{VGG-19}} vs Training from Scratch},
  author = {Victor Ikechukwu, A. and Murali, S. and Deepu, R. and Shivamurthy, R. C.},
  year = {2021},
  month = nov,
  journal = {Global Transitions Proceedings},
  series = {International {{Conference}} on {{Computing System}} and Its {{Applications}} ({{ICCSA-}} 2021)},
  volume = {2},
  number = {2},
  pages = {375--381},
  issn = {2666-285X},
  doi = {10.1016/j.gltp.2021.08.027},
  urldate = {2024-09-04},
  abstract = {In medical imaging, segmentation plays a vital role towards the interpretation of X-ray images where salient features are extracted with the help of image segmentation. Without undergoing surgery, clinicians employ various modalities ranging from X-rays and CT-Scans to ultrasonography, and other imaging techniques to visualise and examine interior human body organ and structures. To ensure appropriate convergence, training a deep convolutional neural network (CNN) from scratch is tough since it requires more computational time, a big amount of labelled training data and a considerable degree of experience. Fine-tuning a CNN that has been pre-trained using, for instance, a huge set of labelled medical datasets, is a viable alternative. In this paper, a comparative study was done using pre-trained models such as VGG-19 and ResNet-50 as against training from scratch. To reduce overfitting, data augmentation and dropout regularization was used. With a recall of 92.03\%, our analysis showed that the pre-trained models with proper finetuning was comparable with Iyke-Net, a CNN trained from scratch.},
  keywords = {Chest X-rays,CNNs,Deep learning,Medical imaging,Pneumonia detection,ResNet-50,Segmentation,VGG-19},
  file = {/home/james/Zotero/storage/LP7NSR9K/Victor Ikechukwu et al. - 2021 - ResNet-50 vs VGG-19 vs training from scratch A comparative analysis of the segmentation and classif.pdf;/home/james/Zotero/storage/DEAA3SR7/S2666285X21000558.html}
}

@article{vosoughiSpreadTrueFalse2018,
  title = {The {{Spread}} of {{True}} and {{False News Online}}},
  author = {Vosoughi, Soroush and Roy, Deb and Aral, Sinan},
  year = {2018},
  pages = {7}
}

@article{wagnerRadiomicsMachineLearning2021,
  title = {Radiomics, {{Machine Learning}}, and {{Artificial Intelligence}}---{{What}} the {{Neuroradiologist Needs}} to {{Know}}},
  author = {Wagner, Matthias W. and Namdar, Khashayar and Biswas, Asthik and Monah, Suranna and Khalvati, Farzad and {Ertl-Wagner}, Birgit B.},
  year = {2021},
  journal = {Neuroradiology},
  volume = {63},
  number = {12},
  pages = {1957--1967},
  issn = {0028-3940},
  doi = {10.1007/s00234-021-02813-9},
  urldate = {2024-08-23},
  abstract = {Purpose Artificial intelligence (AI) is playing an ever-increasing role in Neuroradiology. Methods When designing AI-based research in neuroradiology and appreciating the literature, it is important to understand the fundamental principles of AI. Training, validation, and test datasets must be defined and set apart as priorities. External validation and testing datasets are preferable, when feasible. The specific type of learning process (supervised vs. unsupervised) and the machine learning model also require definition. Deep learning (DL) is an AI-based approach that is modelled on the structure of neurons of the brain; convolutional neural networks (CNN) are a commonly used example in neuroradiology. Results Radiomics is a frequently used approach in which a multitude of imaging features are extracted from a region of interest and subsequently reduced and selected to convey diagnostic or prognostic information. Deep radiomics uses CNNs to directly extract features and obviate the need for predefined features. Conclusion Common limitations and pitfalls in AI-based research in neuroradiology are limited sample sizes (``small-n-large-p problem''), selection bias, as well as overfitting and underfitting.},
  pmcid = {PMC8449698},
  pmid = {34537858}
}

@phdthesis{wangMAXIMIZINGSPEEDINFLUENCE2015,
  type = {Master of {{Science}}},
  title = {{{MAXIMIZING THE SPEED OF INFLUENCE IN SOCIAL NETWORKS}}},
  author = {Wang, Yubo},
  year = {2015},
  month = may,
  address = {San Jose, CA, USA},
  doi = {10.31979/etd.yc7h-kwj6},
  urldate = {2021-08-09},
  abstract = {Influence maximization is the study of seed-node selection in a social network in order to achieve the maximized number of influenced nodes. Previous studies focused on three areas, i.e., designing propagation models, improving seed-node selection algorithms and exploiting the structure of social networks. However, most of these studies ignored the time constraint in influence propagation. Here, I studied how to maximize the speed of influence propagation. I extended the classic Independent Cascade model to a Continuous Dynamic Extended Independent Cascade (CDEIC) model. In addition, I proposed a novel heuristic algorithm and evaluated the algorithm using two large academic collaboration data sets. The new algorithm is 10\%-20\% faster in influence propagation than previous classic heuristic algorithms on the CDE-IC model. Furthermore, I gave solutions to calculate propagation probability between adjacent nodes by exploiting the structure of social network.},
  school = {San Jose State University}
}

@inproceedings{wangMultimodalEmergentFake2021,
  title = {Multimodal {{Emergent Fake News Detection}} via {{Meta Neural Process Networks}}},
  booktitle = {Proceedings of the 27th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} \& {{Data Mining}}},
  author = {Wang, Yaqing and Ma, Fenglong and Wang, Haoyu and Jha, Kishlay and Gao, Jing},
  year = {2021},
  month = aug,
  pages = {3708--3716},
  publisher = {ACM},
  address = {Virtual Event Singapore},
  doi = {10.1145/3447548.3467153},
  urldate = {2024-04-08},
  isbn = {978-1-4503-8332-5}
}

@article{wardleTooLittleToo2021,
  title = {Too {{Little}}, {{Too Late}}: {{Social Media Companies}}' {{Failure}} to {{Tackle Vaccine Misinformation Poses}} a {{Real Threat}}.},
  shorttitle = {Too {{Little}}, {{Too Late}}},
  author = {Wardle, Claire and Singerman, Eric},
  year = {2021},
  journal = {BMJ (Clinical research ed.)},
  volume = {372},
  pages = {n26},
  doi = {http://dx.doi.org.ezproxy.lib.uts.edu.au/10.1136/bmj.n26},
  urldate = {2021-09-13}
}

@book{weinerWhyAIData2021,
  title = {Why {{AI}}/{{Data Science Projects Fail}}: {{How}} to {{Avoid Project Pitfalls}}},
  shorttitle = {Why {{AI}}/{{Data Science Projects Fail}}},
  author = {Weiner, Joyce},
  year = {2021},
  series = {Synthesis {{Lectures}} on {{Computation}} and {{Analytics}}},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-031-01685-1},
  urldate = {2024-08-11},
  copyright = {https://www.springer.com/tdm},
  isbn = {978-3-031-00557-2 978-3-031-01685-1}
}

@book{woodfieldEthicsOnlineResearch2017,
  title = {The {{Ethics}} of {{Online Research}}},
  author = {Woodfield, Kandy},
  year = {2017},
  publisher = {Emerald Publishing Limited},
  address = {Bingley, UNITED KINGDOM},
  urldate = {2021-08-10},
  isbn = {978-1-78714-485-9}
}

@misc{WordEmbeddingOverview,
  title = {Word {{Embedding}} - an {{Overview}} {\textbackslash}textbar {{ScienceDirect Topics}}},
  urldate = {2024-05-22}
}

@article{wuModelbasedFederatedLearning2024,
  title = {Model-Based Federated Learning for Accurate {{MR}} Image Reconstruction from Undersampled k-Space Data},
  author = {Wu, Ruoyou and Li, Cheng and Zou, Juan and Liang, Yong and Wang, Shanshan},
  year = {2024},
  month = sep,
  journal = {Computers in Biology and Medicine},
  volume = {180},
  pages = {108905},
  issn = {0010-4825},
  doi = {10.1016/j.compbiomed.2024.108905},
  urldate = {2024-09-04},
  abstract = {Deep learning-based methods have achieved encouraging performances in the field of Magnetic Resonance (MR) image reconstruction. Nevertheless, building powerful and robust deep learning models requires collecting large and diverse datasets from multiple centers. This raises concerns about ethics and data privacy. Recently, federated learning has emerged as a promising solution, enabling the utilization of multi-center data without the need for data transfer between institutions. Despite its potential, existing federated learning methods face challenges due to the high heterogeneity of data from different centers. Aggregation methods based on simple averaging, which are commonly used to combine the client's information, have shown limited reconstruction and generalization capabilities. In this paper, we propose a Model-based Federated learning framework (ModFed) to address these challenges. ModFed has three major contributions: (1) Different from existing data-driven federated learning methods, ModFed designs attention-assisted model-based neural networks that can alleviate the need for large amounts of data on each client; (2) To address the data heterogeneity issue, ModFed proposes an adaptive dynamic aggregation scheme, which can improve the generalization capability and robustness of the trained neural network models; (3) ModFed incorporates a spatial Laplacian attention mechanism and a personalized client-side loss regularization to capture the detailed information for accurate image reconstruction. The effectiveness of the proposed ModFed is evaluated on three in-vivo datasets. Experimental results show that when compared to six existing state-of-the-art federated learning approaches, ModFed achieves better MR image reconstruction performance with increased generalization capability. Codes will be made available at https://github.com/ternencewu123/ModFed.},
  keywords = {Adaptive dynamic aggregation,Federated learning,Magnetic resonance imaging (MRI),Unfolding neural network}
}

@article{wuModelbasedFederatedLearning2024a,
  title = {Model-Based Federated Learning for Accurate {{MR}} Image Reconstruction from Undersampled k-Space Data},
  author = {Wu, Ruoyou and Li, Cheng and Zou, Juan and Liang, Yong and Wang, Shanshan},
  year = {2024},
  month = sep,
  journal = {Computers in Biology and Medicine},
  volume = {180},
  pages = {108905},
  issn = {00104825},
  doi = {10.1016/j.compbiomed.2024.108905},
  urldate = {2024-09-04},
  langid = {english},
  file = {/home/james/Zotero/storage/D44XRVTE/Wu et al. - 2024 - Model-based federated learning for accurate MR image reconstruction from undersampled k-space data.pdf}
}

@article{yamashitaUltraHighDefinition8K2016,
  title = {Ultra-{{High Definition}} ({{8K UHD}}) {{Endoscope}}: {{Our First Clinical Success}}},
  shorttitle = {Ultra-{{High Definition}} ({{8K UHD}}) {{Endoscope}}},
  author = {Yamashita, Hiromasa and Aoki, Hisae and Tanioka, Kenkichi and Mori, Toshiyuki and Chiba, Toshio},
  year = {2016},
  month = aug,
  journal = {SpringerPlus},
  volume = {5},
  number = {1},
  pages = {1445},
  issn = {2193-1801},
  doi = {10.1186/s40064-016-3135-z},
  urldate = {2024-08-22},
  abstract = {Background We have started clinical application of 8K ultra-high definition (UHD; 7680 {\texttimes} 4320 pixels) imaging technology, which is a 16-fold higher resolution than the current 2K high-definition (HD; 1920 {\texttimes} 1080 pixels) technology, to an endoscope for advanced laparoscopic surgery. Results Based on preliminary testing experience and with subsequent technical and system improvements, we then proceeded to perform two cases of cholecystectomy and were able to achieve clinical success with an 8K UHD endoscopic system, which consisted of an 8K camera, a 30-degrees angled rigid endoscope with a lens adapter, a pair of 300-W xenon light sources, an 85-inch 8K LCD and an 8K video recorder. These experimental and clinical studies revealed the engineering and clinical feasibility of the 8K UHD endoscope, enabling us to have a positive outlook on its prospective use in clinical practice. Conclusions The 8K UHD endoscopy promises to open up new possibilities for intricate procedures including anastomoses of thin nerves and blood vessels as well as more confident surgical resections of a diversity of cancer tissues. 8K endoscopic imaging, compared to imaging by the current 2K imaging technology, is very likely to lead to major changes in the future of medical practice.},
  pmcid = {PMC5005252},
  pmid = {27652021}
}

@misc{yangFederatedMachineLearning2019,
  title = {Federated {{Machine Learning}}: {{Concept}} and {{Applications}}},
  shorttitle = {Federated {{Machine Learning}}},
  author = {Yang, Qiang and Liu, Yang and Chen, Tianjian and Tong, Yongxin},
  year = {2019},
  month = feb,
  journal = {arXiv.org},
  urldate = {2024-09-05},
  abstract = {Today's AI still faces two major challenges. One is that in most industries, data exists in the form of isolated islands. The other is the strengthening of data privacy and security. We propose a possible solution to these challenges: secure federated learning. Beyond the federated learning framework first proposed by Google in 2016, we introduce a comprehensive secure federated learning framework, which includes horizontal federated learning, vertical federated learning and federated transfer learning. We provide definitions, architectures and applications for the federated learning framework, and provide a comprehensive survey of existing works on this subject. In addition, we propose building data networks among organizations based on federated mechanisms as an effective solution to allow knowledge to be shared without compromising user privacy.},
  howpublished = {https://arxiv.org/abs/1902.04885v1},
  langid = {english},
  file = {/home/james/Zotero/storage/BFI6NHUF/Yang et al. - 2019 - Federated Machine Learning Concept and Applications.pdf}
}

@misc{yanhuiAlexNetNASNetBrief2021,
  title = {From {{AlexNet}} to {{NASNet}}: {{A Brief History}} and {{Introduction}} of {{Convolutional Neural Networks}}},
  shorttitle = {From {{AlexNet}} to {{NASNet}}},
  author = {Yanhui, Chen},
  year = {2021},
  month = feb,
  journal = {Medium},
  urldate = {2024-04-15},
  abstract = {With a Simple Implementation of ResNet in Keras}
}

@article{yinComprehensiveSurveyPrivacypreserving2022,
  title = {A {{Comprehensive Survey}} of {{Privacy-preserving Federated Learning}}: {{A Taxonomy}}, {{Review}}, and {{Future Directions}}},
  shorttitle = {A {{Comprehensive Survey}} of {{Privacy-preserving Federated Learning}}},
  author = {Yin, Xuefei and Zhu, Yanming and Hu, Jiankun},
  year = {2022},
  month = jul,
  journal = {ACM Computing Surveys},
  volume = {54},
  number = {6},
  pages = {1--36},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3460427},
  urldate = {2024-10-22},
  abstract = {The past four years have witnessed the rapid development of federated learning (FL). However, new privacy concerns have also emerged during the aggregation of the distributed intermediate results. The emerging privacy-preserving FL (PPFL) has been heralded as a solution to generic privacy-preserving machine learning. However, the challenge of protecting data privacy while maintaining the data utility through machine learning still remains. In this article, we present a comprehensive and systematic survey on the PPFL based on our proposed 5W-scenario-based taxonomy. We analyze the privacy leakage risks in the FL from five aspects, summarize existing methods, and identify future research directions.},
  langid = {english},
  file = {/home/james/Zotero/storage/EA82LTFK/Yin et al. - 2022 - A Comprehensive Survey of Privacy-preserving Federated Learning A Taxonomy, Review, and Future Dire.pdf}
}

@article{yongHistopathologicalGastricCancer2023,
  title = {Histopathological {{Gastric Cancer Detection}} on {{GasHisSDB Dataset Using Deep Ensemble Learning}}},
  author = {Yong, Ming Ping and Hum, Yan Chai and Lai, Khin Wee and Lee, Ying Loong and Goh, Choon-Hian and Yap, Wun-She and Tee, Yee Kai},
  year = {2023},
  month = may,
  journal = {Diagnostics},
  volume = {13},
  number = {10},
  pages = {1793},
  issn = {2075-4418},
  doi = {10.3390/diagnostics13101793},
  urldate = {2024-09-08},
  abstract = {Gastric cancer is a leading cause of cancer-related deaths worldwide, underscoring the need for early detection to improve patient survival rates. The current clinical gold standard for detection is histopathological image analysis, but this process is manual, laborious, and time-consuming. As a result, there has been growing interest in developing computer-aided diagnosis to assist pathologists. Deep learning has shown promise in this regard, but each model can only extract a limited number of image features for classification. To overcome this limitation and improve classification performance, this study proposes ensemble models that combine the decisions of several deep learning models. To evaluate the effectiveness of the proposed models, we tested their performance on the publicly available gastric cancer dataset, Gastric Histopathology Sub-size Image Database. Our experimental results showed that the top 5 ensemble model achieved state-of-the-art detection accuracy in all sub-databases, with the highest detection accuracy of 99.20\% in the 160 {\texttimes} 160 pixels sub-database. These results demonstrated that ensemble models could extract important features from smaller patch sizes and achieve promising performance. Overall, our proposed work could assist pathologists in detecting gastric cancer through histopathological image analysis and contribute to early gastric cancer detection to improve patient survival rates.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/home/james/Zotero/storage/9BAHD7I6/Yong et al. - 2023 - Histopathological Gastric Cancer Detection on GasHisSDB Dataset Using Deep Ensemble Learning.pdf}
}

@article{yongHistopathologicalGastricCancer2023a,
  title = {Histopathological {{Gastric Cancer Detection}} on {{GasHisSDB Dataset Using Deep Ensemble Learning}}},
  author = {Yong, Ming Ping and Hum, Yan Chai and Lai, Khin Wee and Lee, Ying Loong and Goh, Choon-Hian and Yap, Wun-She and Tee, Yee Kai},
  year = {2023},
  month = may,
  journal = {Diagnostics},
  volume = {13},
  number = {10},
  pages = {1793},
  issn = {2075-4418},
  doi = {10.3390/diagnostics13101793},
  urldate = {2024-09-08},
  abstract = {Gastric cancer is a leading cause of cancer-related deaths worldwide, underscoring the need for early detection to improve patient survival rates. The current clinical gold standard for detection is histopathological image analysis, but this process is manual, laborious, and time-consuming. As a result, there has been growing interest in developing computer-aided diagnosis to assist pathologists. Deep learning has shown promise in this regard, but each model can only extract a limited number of image features for classification. To overcome this limitation and improve classification performance, this study proposes ensemble models that combine the decisions of several deep learning models. To evaluate the effectiveness of the proposed models, we tested their performance on the publicly available gastric cancer dataset, Gastric Histopathology Sub-size Image Database. Our experimental results showed that the top 5 ensemble model achieved state-of-the-art detection accuracy in all sub-databases, with the highest detection accuracy of 99.20\% in the 160 {\texttimes} 160 pixels sub-database. These results demonstrated that ensemble models could extract important features from smaller patch sizes and achieve promising performance. Overall, our proposed work could assist pathologists in detecting gastric cancer through histopathological image analysis and contribute to early gastric cancer detection to improve patient survival rates.},
  copyright = {https://creativecommons.org/licenses/by/4.0/},
  langid = {english},
  file = {/home/james/Zotero/storage/A5KUUIMT/Yong et al. - 2023 - Histopathological Gastric Cancer Detection on GasHisSDB Dataset Using Deep Ensemble Learning.pdf}
}

@article{yongHistopathologicalGastricCancer2023b,
  title = {Histopathological {{Gastric Cancer Detection}} on {{GasHisSDB Dataset Using Deep Ensemble Learning}}},
  author = {Yong, Ming Ping and Hum, Yan Chai and Lai, Khin Wee and Lee, Ying Loong and Goh, Choon-Hian and Yap, Wun-She and Tee, Yee Kai},
  year = {2023},
  month = jan,
  journal = {Diagnostics},
  volume = {13},
  number = {10},
  pages = {1793},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2075-4418},
  doi = {10.3390/diagnostics13101793},
  urldate = {2024-09-08},
  abstract = {Gastric cancer is a leading cause of cancer-related deaths worldwide, underscoring the need for early detection to improve patient survival rates. The current clinical gold standard for detection is histopathological image analysis, but this process is manual, laborious, and time-consuming. As a result, there has been growing interest in developing computer-aided diagnosis to assist pathologists. Deep learning has shown promise in this regard, but each model can only extract a limited number of image features for classification. To overcome this limitation and improve classification performance, this study proposes ensemble models that combine the decisions of several deep learning models. To evaluate the effectiveness of the proposed models, we tested their performance on the publicly available gastric cancer dataset, Gastric Histopathology Sub-size Image Database. Our experimental results showed that the top 5 ensemble model achieved state-of-the-art detection accuracy in all sub-databases, with the highest detection accuracy of 99.20\% in the 160 {\texttimes} 160 pixels sub-database. These results demonstrated that ensemble models could extract important features from smaller patch sizes and achieve promising performance. Overall, our proposed work could assist pathologists in detecting gastric cancer through histopathological image analysis and contribute to early gastric cancer detection to improve patient survival rates.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {convolutional neural network,deep learning,ensemble model,gastric cancer,histopathology,transfer learning},
  file = {/home/james/Zotero/storage/XGFYEA2V/Yong et al. - 2023 - Histopathological Gastric Cancer Detection on GasHisSDB Dataset Using Deep Ensemble Learning.pdf}
}

@inproceedings{yongHistopathologicalGastricCancer2023c,
  title = {Histopathological {{Gastric Cancer Detection Using Transfer Learning}}},
  booktitle = {2023 11th {{International Conference}} on {{Bioinformatics}} and {{Computational Biology}} ({{ICBCB}})},
  author = {Yong, Ming Ping and Hum, Yan Chai and Lai, Khin Wee and Goh, Choon Hian and Yap, Wun-She and Tee, Yee Kai},
  year = {2023},
  month = apr,
  pages = {123--129},
  doi = {10.1109/ICBCB57893.2023.10246524},
  urldate = {2024-10-22},
  abstract = {Gastric cancer is a leading cause of cancer-related deaths worldwide, underscoring the need for early detection to improve patient survival rates. Histopathological image analysis (HIA) is the gold standard for this purpose but it is time-consuming and laborious, leading to interest in computer-aided diagnosis to assist pathologists. Deep learning has shown promise in various HIA tasks, but the limited amount of training data in medical imaging has posed a significant obstacle. In this paper, we propose transfer learning-based CNNs for binary classification of gastric cancer patches, overcoming this limitation. We validate our approach on the publicly available GasHisSDB dataset, which includes three sub-databases with patch sizes of 80 x 80 pixels, 120 x 120 pixels, and 160 x 160 pixels. Our experimental results show that the DenseNet121 model achieved the highest accuracy of 98.68 \% and AUC of 98.58\% on the 160-pixels sub-database. These results suggest that our proposed work can assist pathologists in the detection of gastric cancer through histopathological image analysis.},
  keywords = {Biological system modeling,classification,Computational modeling,convolutional neural network,deep learning,Gastric cancer,histopathology,Histopathology,Image analysis,Training,Training data,transfer learning,Transfer learning},
  file = {/home/james/Zotero/storage/GLESSXMT/Yong et al. - 2023 - Histopathological Gastric Cancer Detection Using Transfer Learning.pdf;/home/james/Zotero/storage/HXU3FDV9/10246524.html}
}

@article{yoshidaAutomatedHistologicalClassification2018,
  title = {Automated Histological Classification of Whole-Slide Images of Gastric Biopsy Specimens},
  author = {Yoshida, Hiroshi and Shimazu, Taichi and Kiyuna, Tomoharu and Marugame, Atsushi and Yamashita, Yoshiko and Cosatto, Eric and Taniguchi, Hirokazu and Sekine, Shigeki and Ochiai, Atsushi},
  year = {2018},
  month = mar,
  journal = {Gastric Cancer},
  volume = {21},
  number = {2},
  pages = {249--257},
  issn = {1436-3291, 1436-3305},
  doi = {10.1007/s10120-017-0731-8},
  urldate = {2024-09-08},
  langid = {english},
  file = {/home/james/Zotero/storage/9JEX7L6N/Yoshida et al. - 2018 - Automated histological classification of whole-slide images of gastric biopsy specimens.pdf}
}

@misc{yuanDigitalEthicsFederated2023,
  title = {Digital {{Ethics}} in {{Federated Learning}}},
  author = {Yuan, Liangqi and Wang, Ziran and Brinton, Christopher G.},
  year = {2023},
  month = oct,
  journal = {arXiv.org},
  urldate = {2024-09-04},
  abstract = {The Internet of Things (IoT) consistently generates vast amounts of data, sparking increasing concern over the protection of data privacy and the limitation of data misuse. Federated learning (FL) facilitates collaborative capabilities among multiple parties by sharing machine learning (ML) model parameters instead of raw user data, and it has recently gained significant attention for its potential in privacy preservation and learning efficiency enhancement. In this paper, we highlight the digital ethics concerns that arise when human-centric devices serve as clients in FL. More specifically, challenges of game dynamics, fairness, incentive, and continuity arise in FL due to differences in perspectives and objectives between clients and the server. We analyze these challenges and their solutions from the perspectives of both the client and the server, and through the viewpoints of centralized and decentralized FL. Finally, we explore the opportunities in FL for human-centric IoT as directions for future development.},
  howpublished = {https://arxiv.org/abs/2310.03178v2},
  langid = {english},
  file = {/home/james/Zotero/storage/AE49VPQR/Yuan et al. - 2023 - Digital Ethics in Federated Learning.pdf}
}

@misc{yuanDigitalEthicsFederated2023a,
  title = {Digital {{Ethics}} in {{Federated Learning}}},
  author = {Yuan, Liangqi and Wang, Ziran and Brinton, Christopher G.},
  year = {2023},
  month = oct,
  number = {arXiv:2310.03178},
  eprint = {2310.03178},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.03178},
  urldate = {2024-09-04},
  abstract = {The Internet of Things (IoT) consistently generates vast amounts of data, sparking increasing concern over the protection of data privacy and the limitation of data misuse. Federated learning (FL) facilitates collaborative capabilities among multiple parties by sharing machine learning (ML) model parameters instead of raw user data, and it has recently gained significant attention for its potential in privacy preservation and learning efficiency enhancement. In this paper, we highlight the digital ethics concerns that arise when human-centric devices serve as clients in FL. More specifically, challenges of game dynamics, fairness, incentive, and continuity arise in FL due to differences in perspectives and objectives between clients and the server. We analyze these challenges and their solutions from the perspectives of both the client and the server, and through the viewpoints of centralized and decentralized FL. Finally, we explore the opportunities in FL for human-centric IoT as directions for future development.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Science and Game Theory,Computer Science - Computers and Society,Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Machine Learning},
  file = {/home/james/Zotero/storage/NHIE2D8T/Yuan et al. - 2023 - Digital Ethics in Federated Learning.pdf}
}

@misc{yuanDigitalEthicsFederated2023b,
  title = {Digital {{Ethics}} in {{Federated Learning}}},
  author = {Yuan, Liangqi and Wang, Ziran and Brinton, Christopher G.},
  year = {2023},
  month = oct,
  number = {arXiv:2310.03178},
  eprint = {2310.03178},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-09-04},
  abstract = {The Internet of Things (IoT) consistently generates vast amounts of data, sparking increasing concern over the protection of data privacy and the limitation of data misuse. Federated learning (FL) facilitates collaborative capabilities among multiple parties by sharing machine learning (ML) model parameters instead of raw user data, and it has recently gained significant attention for its potential in privacy preservation and learning efficiency enhancement. In this paper, we highlight the digital ethics concerns that arise when human-centric devices serve as clients in FL. More specifically, challenges of game dynamics, fairness, incentive, and continuity arise in FL due to differences in perspectives and objectives between clients and the server. We analyze these challenges and their solutions from the perspectives of both the client and the server, and through the viewpoints of centralized and decentralized FL. Finally, we explore the opportunities in FL for human-centric IoT as directions for future development.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Science and Game Theory,Computer Science - Computers and Society,Computer Science - Distributed Parallel and Cluster Computing,Computer Science - Machine Learning},
  file = {/home/james/Zotero/storage/UB4PH4YS/Yuan et al. - 2023 - Digital Ethics in Federated Learning.pdf}
}

@article{yuConvolutionalNeuralNetworks2021,
  title = {Convolutional {{Neural Networks}} for {{Medical Image Analysis}}: {{State-of-the-art}}, {{Comparisons}}, {{Improvement}} and {{Perspectives}}},
  shorttitle = {Convolutional {{Neural Networks}} for {{Medical Image Analysis}}},
  author = {Yu, Hang and Yang, Laurence T. and Zhang, Qingchen and Armstrong, David and Deen, M. Jamal},
  year = {2021},
  month = jul,
  journal = {Neurocomputing},
  volume = {444},
  pages = {92--110},
  issn = {0925-2312},
  doi = {10.1016/j.neucom.2020.04.157},
  urldate = {2024-08-20},
  abstract = {Convolutional neural networks, are one of the most representative deep learning models. CNNs were extensively used in many aspects of medical image analysis, allowing for great progress in computer-aided diagnosis in recent years. In this paper, we provide a survey on convolutional neural networks in medical image analysis. First, we review the commonly used CNNs in medical image processing, including AlexNet, GoogleNet, ResNet, R-CNN, and FCNN. Then, we present an overview of the use of CNNs, for image classification, segmentation, detection, and other tasks such as registration, content-based image retrieval, image generation and enhancement, in some typical medical diagnosis areas such as brain, breast, and abdominal. Finally, we discuss the remaining challenges of CNNs in medical image analysis, and accordingly we present some ideas for future research directions.},
  keywords = {Classification,Convolutional neural networks,Medical image analysis,Smart medicine}
}

@misc{yunCutMixRegularizationStrategy2019,
  title = {{{CutMix}}: {{Regularization Strategy}} to {{Train Strong Classifiers}} with {{Localizable Features}}},
  shorttitle = {{{CutMix}}},
  author = {Yun, Sangdoo and Han, Dongyoon and Oh, Seong Joon and Chun, Sanghyuk and Choe, Junsuk and Yoo, Youngjoon},
  year = {2019},
  month = aug,
  number = {arXiv:1905.04899},
  eprint = {1905.04899},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-11-03},
  abstract = {Regional dropout strategies have been proposed to enhance the performance of convolutional neural network classifiers. They have proved to be effective for guiding the model to attend on less discriminative parts of objects (e.g. leg as opposed to head of a person), thereby letting the network generalize better and have better object localization capabilities. On the other hand, current methods for regional dropout remove informative pixels on training images by overlaying a patch of either black pixels or random noise. Such removal is not desirable because it leads to information loss and inefficiency during training. We therefore propose the CutMix augmentation strategy: patches are cut and pasted among training images where the ground truth labels are also mixed proportionally to the area of the patches. By making efficient use of training pixels and retaining the regularization effect of regional dropout, CutMix consistently outperforms the state-of-the-art augmentation strategies on CIFAR and ImageNet classification tasks, as well as on the ImageNet weakly-supervised localization task. Moreover, unlike previous augmentation methods, our CutMix-trained ImageNet classifier, when used as a pretrained model, results in consistent performance gains in Pascal detection and MS-COCO image captioning benchmarks. We also show that CutMix improves the model robustness against input corruptions and its out-of-distribution detection performances. Source code and pretrained models are available at https://github.com/clovaai/CutMix-PyTorch.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/home/james/Zotero/storage/LYLKHDFD/Yun et al. - 2019 - CutMix Regularization Strategy to Train Strong Classifiers with Localizable Features.pdf}
}

@article{yurdemFederatedLearningOverview2024,
  title = {Federated Learning: {{Overview}}, Strategies, Applications, Tools and Future Directions},
  shorttitle = {Federated Learning},
  author = {Yurdem, Betul and Kuzlu, Murat and Gullu, Mehmet Kemal and Catak, Ferhat Ozgur and Tabassum, Maliha},
  year = {2024},
  month = oct,
  journal = {Heliyon},
  volume = {10},
  number = {19},
  pages = {e38137},
  issn = {2405-8440},
  doi = {10.1016/j.heliyon.2024.e38137},
  urldate = {2024-10-22},
  abstract = {Federated learning (FL) is a distributed machine learning process, which allows multiple nodes to work together to train a shared model without exchanging raw data. It offers several key advantages, such as data privacy, security, efficiency, and scalability, by keeping data local and only exchanging model updates through the communication network. This review paper provides a comprehensive overview of federated learning, including its principles, strategies, applications, and tools along with opportunities, challenges, and future research directions. The findings of this paper emphasize that federated learning strategies can significantly help overcome privacy and confidentiality concerns, particularly for high-risk applications.},
  keywords = {Data privacy,Distributed machine learning,Federated learning},
  file = {/home/james/Zotero/storage/8KP9ITZM/Yurdem et al. - 2024 - Federated learning Overview, strategies, applications, tools and future directions.pdf}
}

@misc{zhangDiveDeepLearning2021,
  title = {Dive into {{Deep Learning}}},
  author = {Zhang, Aston and Lipton, Zachary C. and Li, Mu and Smola, Alexander J.},
  year = {2021},
  month = jun,
  number = {arXiv:2106.11342},
  publisher = {arXiv},
  urldate = {2024-04-15},
  abstract = {This open-source book represents our attempt to make deep learning approachable, teaching readers the concepts, the context, and the code. The entire book is drafted in Jupyter notebooks, seamlessly integrating exposition figures, math, and interactive examples with self-contained code. Our goal is to offer a resource that could (i) be freely available for everyone; (ii) offer sufficient technical depth to provide a starting point on the path to actually becoming an applied machine learning scientist; (iii) include runnable code, showing readers how to solve problems in practice; (iv) allow for rapid updates, both by us and also by the community at large; (v) be complemented by a forum for interactive discussion of technical details and to answer questions.},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
}

@misc{zhangMixupEmpiricalRisk2018,
  title = {Mixup: {{Beyond Empirical Risk Minimization}}},
  shorttitle = {Mixup},
  author = {Zhang, Hongyi and Cisse, Moustapha and Dauphin, Yann N. and {Lopez-Paz}, David},
  year = {2018},
  month = apr,
  number = {arXiv:1710.09412},
  eprint = {1710.09412},
  primaryclass = {cs},
  publisher = {arXiv},
  urldate = {2024-11-03},
  abstract = {Large deep neural networks are powerful, but exhibit undesirable behaviors such as memorization and sensitivity to adversarial examples. In this work, we propose mixup, a simple learning principle to alleviate these issues. In essence, mixup trains a neural network on convex combinations of pairs of examples and their labels. By doing so, mixup regularizes the neural network to favor simple linear behavior in-between training examples. Our experiments on the ImageNet-2012, CIFAR-10, CIFAR-100, Google commands and UCI datasets show that mixup improves the generalization of state-of-the-art neural network architectures. We also find that mixup reduces the memorization of corrupt labels, increases the robustness to adversarial examples, and stabilizes the training of generative adversarial networks.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/james/Zotero/storage/A4RF69QQ/Zhang et al. - 2018 - mixup Beyond Empirical Risk Minimization.pdf}
}

@misc{zhangPracticalDataFreeApproach2021,
  title = {A {{Practical Data-Free Approach}} to {{One-shot Federated Learning}} with {{Heterogeneity}}},
  author = {Zhang, Jie and Chen, Chen and Li, Bo and Lyu, Lingjuan and Wu, Shuang and Xu, Jianghe and Ding, Shouhong and Wu, Chao},
  year = {2021},
  month = dec,
  journal = {arXiv.org},
  urldate = {2024-09-05},
  abstract = {One-shot Federated Learning (FL) has recently emerged as a promising approach, which allows the central server to learn a model in a single communication round. Despite the low communication cost, existing one-shot FL methods are mostly impractical or face inherent limitations, e.g., a public dataset is required, clients' models are homogeneous, need to upload additional data/model information. To overcome these issues, we propose a more practical data-free approach named FedSyn for one-shot FL framework with heterogeneity. Our FedSyn trains the global model by a data generation stage and a model distillation stage. To the best of our knowledge, FedSyn is the first method that can be practically applied to various real-world applications due to the following advantages: (1) FedSyn requires no additional information (except the model parameters) to be transferred between clients and the server; (2) FedSyn does not require any auxiliary dataset for training; (3) FedSyn is the first to consider both model and statistical heterogeneities in FL, i.e., the clients' data are non-iid and different clients may have different model architectures. Experiments on a variety of real-world datasets demonstrate the superiority of our FedSyn. For example, FedSyn outperforms the best baseline method Fed-ADI by 5.08\% on CIFAR10 dataset when data are non-iid.},
  howpublished = {https://arxiv.org/abs/2112.12371v1},
  langid = {english},
  file = {/home/james/Zotero/storage/BXBWVP9A/Zhang et al. - 2021 - A Practical Data-Free Approach to One-shot Federated Learning with Heterogeneity.pdf}
}

@misc{zhouDistributedFederatedLearningBased2024,
  title = {Distributed {{Federated Learning-Based Deep Learning Model}} for {{Privacy MRI Brain Tumor Detection}}},
  author = {Zhou, Lisang and Wang, Meng and Zhou, Ning},
  year = {2024},
  month = apr,
  number = {arXiv:2404.10026},
  eprint = {2404.10026},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2404.10026},
  urldate = {2024-10-22},
  abstract = {Distributed training can facilitate the processing of large medical image datasets, and improve the accuracy and efficiency of disease diagnosis while protecting patient privacy, which is crucial for achieving efficient medical image analysis and accelerating medical research progress. This paper presents an innovative approach to medical image classification, leveraging Federated Learning (FL) to address the dual challenges of data privacy and efficient disease diagnosis. Traditional Centralized Machine Learning models, despite their widespread use in medical imaging for tasks such as disease diagnosis, raise significant privacy concerns due to the sensitive nature of patient data. As an alternative, FL emerges as a promising solution by allowing the training of a collective global model across local clients without centralizing the data, thus preserving privacy. Focusing on the application of FL in Magnetic Resonance Imaging (MRI) brain tumor detection, this study demonstrates the effectiveness of the Federated Learning framework coupled with EfficientNet-B0 and the FedAvg algorithm in enhancing both privacy and diagnostic accuracy. Through a meticulous selection of preprocessing methods, algorithms, and hyperparameters, and a comparative analysis of various Convolutional Neural Network (CNN) architectures, the research uncovers optimal strategies for image classification. The experimental results reveal that EfficientNet-B0 outperforms other models like ResNet in handling data heterogeneity and achieving higher accuracy and lower loss, highlighting the potential of FL in overcoming the limitations of traditional models. The study underscores the significance of addressing data heterogeneity and proposes further research directions for broadening the applicability of FL in medical image analysis.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image and Video Processing},
  file = {/home/james/Zotero/storage/3FQHEFAZ/Zhou et al. - 2024 - Distributed Federated Learning-Based Deep Learning Model for Privacy MRI Brain Tumor Detection.pdf;/home/james/Zotero/storage/76UQIE85/2404.html}
}

@misc{zophLearningTransferableArchitectures2018a,
  title = {Learning {{Transferable Architectures}} for {{Scalable Image Recognition}}},
  author = {Zoph, Barret and Vasudevan, Vijay and Shlens, Jonathon and Le, Quoc V.},
  year = {2018},
  month = apr,
  number = {arXiv:1707.07012},
  eprint = {1707.07012},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  urldate = {2024-09-04},
  abstract = {Developing neural network image classification models often requires significant architecture engineering. In this paper, we study a method to learn the model architectures directly on the dataset of interest. As this approach is expensive when the dataset is large, we propose to search for an architectural building block on a small dataset and then transfer the block to a larger dataset. The key contribution of this work is the design of a new search space (which we call the ``NASNet search space'') which enables transferability. In our experiments, we search for the best convolutional layer (or ``cell'') on the CIFAR-10 dataset and then apply this cell to the ImageNet dataset by stacking together more copies of this cell, each with their own parameters to design a convolutional architecture, which we name a ``NASNet architecture''. We also introduce a new regularization technique called ScheduledDropPath that significantly improves generalization in the NASNet models. On CIFAR-10 itself, a NASNet found by our method achieves 2.4\% error rate, which is state-of-the-art. Although the cell is not searched for directly on ImageNet, a NASNet constructed from the best cell achieves, among the published works, state-of-the-art accuracy of 82.7\% top-1 and 96.2\% top-5 on ImageNet. Our model is 1.2\% better in top-1 accuracy than the best human-invented architectures while having 9 billion fewer FLOPS -- a reduction of 28\% in computational demand from the previous state-of-the-art model. When evaluated at different levels of computational cost, accuracies of NASNets exceed those of the state-of-the-art human-designed models. For instance, a small version of NASNet also achieves 74\% top-1 accuracy, which is 3.1\% better than equivalently-sized, state-of-the-art models for mobile platforms. Finally, the image features learned from image classification are generically useful and can be transferred to other computer vision problems. On the task of object detection, the learned features by NASNet used with the Faster-RCNN framework surpass state-of-the-art by 4.0\% achieving 43.1\% mAP on the COCO dataset.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/home/james/Zotero/storage/2CLQURWB/Zoph et al. - 2018 - Learning Transferable Architectures for Scalable Image Recognition.pdf}
}

@book{zotero-111,
  type = {Book}
}

@article{zotero-242,
  type = {Article}
}

@article{zotero-243,
  type = {Article}
}

@book{zotero-66,
  type = {Book}
}
