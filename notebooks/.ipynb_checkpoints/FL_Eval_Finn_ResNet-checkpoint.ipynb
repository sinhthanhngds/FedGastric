{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:35.447042Z",
     "iopub.status.busy": "2024-10-17T07:52:35.446572Z",
     "iopub.status.idle": "2024-10-17T07:52:36.529306Z",
     "shell.execute_reply": "2024-10-17T07:52:36.527924Z",
     "shell.execute_reply.started": "2024-10-17T07:52:35.446999Z"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://sinhthanhngds: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@github.com/data-davey/ilab-07-2.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.532545Z",
     "iopub.status.busy": "2024-10-17T07:52:36.532081Z",
     "iopub.status.idle": "2024-10-17T07:52:36.538359Z",
     "shell.execute_reply": "2024-10-17T07:52:36.537212Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.532475Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.540351Z",
     "iopub.status.busy": "2024-10-17T07:52:36.539920Z",
     "iopub.status.idle": "2024-10-17T07:52:36.551378Z",
     "shell.execute_reply": "2024-10-17T07:52:36.550461Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.540305Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.554757Z",
     "iopub.status.busy": "2024-10-17T07:52:36.554339Z",
     "iopub.status.idle": "2024-10-17T07:52:36.563976Z",
     "shell.execute_reply": "2024-10-17T07:52:36.562913Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.554714Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip -q install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.566170Z",
     "iopub.status.busy": "2024-10-17T07:52:36.565720Z",
     "iopub.status.idle": "2024-10-17T07:52:36.575714Z",
     "shell.execute_reply": "2024-10-17T07:52:36.574837Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.566125Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Subset, ConcatDataset\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "from torchvision import models, datasets\n",
    "#from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.577505Z",
     "iopub.status.busy": "2024-10-17T07:52:36.577136Z",
     "iopub.status.idle": "2024-10-17T07:52:36.591028Z",
     "shell.execute_reply": "2024-10-17T07:52:36.590079Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.577462Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.593436Z",
     "iopub.status.busy": "2024-10-17T07:52:36.592950Z",
     "iopub.status.idle": "2024-10-17T07:52:36.607102Z",
     "shell.execute_reply": "2024-10-17T07:52:36.606179Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.593344Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.609529Z",
     "iopub.status.busy": "2024-10-17T07:52:36.608930Z",
     "iopub.status.idle": "2024-10-17T07:52:36.625357Z",
     "shell.execute_reply": "2024-10-17T07:52:36.624351Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.609484Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def set_random_seed(seed_value=30):\n",
    "    torch.manual_seed(seed_value)           # For CPU\n",
    "    torch.cuda.manual_seed(seed_value)      # For GPU\n",
    "    torch.cuda.manual_seed_all(seed_value)  # If using multi-GPU\n",
    "    np.random.seed(seed_value)              # For NumPy\n",
    "    random.seed(seed_value)                 # For Python's built-in random module\n",
    "\n",
    "    # Ensure deterministic behavior if possible\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False  # To avoid non-deterministic algorithms\n",
    "\n",
    "# Set random seed\n",
    "set_random_seed(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.627558Z",
     "iopub.status.busy": "2024-10-17T07:52:36.627178Z",
     "iopub.status.idle": "2024-10-17T07:52:36.639172Z",
     "shell.execute_reply": "2024-10-17T07:52:36.638196Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.627516Z"
    }
   },
   "outputs": [],
   "source": [
    "class LocalData:\n",
    "    def __init__ (self, clinic_id): #data_range): #data_range will be removed for final code\n",
    "        self.clinic_id = clinic_id\n",
    "        self.path = f'ilab-07-2/120_dataset/{clinic_id}/'\n",
    "        #self.data_range = data_range\n",
    "        \n",
    "    def dataset (self):\n",
    "        transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize images to a fixed size (optional)\n",
    "        transforms.ToTensor(),          # Convert images to PyTorch tensors\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]) \n",
    "        ])\n",
    "\n",
    "# Load the dataset from the train folder\n",
    "        train_dataset = datasets.ImageFolder(root=f'{self.path}', transform=transform)\n",
    "                  \n",
    "        #subset_indices = list(self.data_range)    #remove for final code\n",
    "        #train_dataset = Subset (train_dataset, subset_indices) #remove for final code\n",
    "                  \n",
    "        train_size = int(0.8*len(train_dataset))\n",
    "        val_size = len(train_dataset)-train_size\n",
    "\n",
    "        train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
    "        return train_subset, val_subset\n",
    "    \n",
    "    def dataloader(self):  \n",
    "        train_subset, val_subset = self.dataset()\n",
    "        train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "        print (f'loading {self.clinic_id}')\n",
    "        return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.645239Z",
     "iopub.status.busy": "2024-10-17T07:52:36.644591Z",
     "iopub.status.idle": "2024-10-17T07:52:36.657452Z",
     "shell.execute_reply": "2024-10-17T07:52:36.656515Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.645191Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.659224Z",
     "iopub.status.busy": "2024-10-17T07:52:36.658829Z",
     "iopub.status.idle": "2024-10-17T07:52:36.673898Z",
     "shell.execute_reply": "2024-10-17T07:52:36.672811Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.659191Z"
    }
   },
   "outputs": [],
   "source": [
    "def resnet18 (weights='DEFAULT'): #James\n",
    "    \n",
    "    resnet18 = models.resnet18(weights = weights)#.to(device)\n",
    "    for param in resnet18.parameters():\n",
    "        param.requires_grad = False\n",
    "    resnet18.fc = nn.Sequential (\n",
    "    nn.Linear(in_features = 512, out_features = 256, bias = True),\n",
    "    nn.Dropout(p = 0.5),\n",
    "    nn.Linear(in_features = 256, out_features = 1, bias = True),\n",
    "    nn.Sigmoid()\n",
    "    )\n",
    "    \n",
    "    for param in resnet18.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    resnet18.__class__.__name__ = 'ResNet18'\n",
    "    return resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.675949Z",
     "iopub.status.busy": "2024-10-17T07:52:36.675601Z",
     "iopub.status.idle": "2024-10-17T07:52:36.698836Z",
     "shell.execute_reply": "2024-10-17T07:52:36.697849Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.675901Z"
    }
   },
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, drop_out=0.2):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.drop_out = nn.Dropout(drop_out)\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            out += self.downsample(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.drop_out(out)\n",
    "        return out\n",
    "\n",
    "class CustomResNet18(nn.Module):\n",
    "    def __init__(self, drop_out=0.2):\n",
    "        super(CustomResNet18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # Replace residual blocks with custom BasicBlock including dropout\n",
    "        self.layer1 = self._make_layer(BasicBlock, 64, 2, stride=1, drop_out=drop_out)\n",
    "        self.layer2 = self._make_layer(BasicBlock, 128, 2, stride=2, drop_out=drop_out)\n",
    "        self.layer3 = self._make_layer(BasicBlock, 256, 2, stride=2, drop_out=drop_out)\n",
    "        self.layer4 = self._make_layer(BasicBlock, 512, 2, stride=2, drop_out=drop_out)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, 1000)\n",
    "        \n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride, drop_out):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride, drop_out))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        \n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        \n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "def custom_resnet18(weights='DEFAULT', drop_out=0.2):\n",
    "    custom_resnet18 = CustomResNet18(drop_out=0.2)\n",
    "    #custom_resnet18.load_state_dict(models.resnet18(weights = weights).state_dict(), strict=False)\n",
    "\n",
    "# Then freeze parameters\n",
    "    #for param in custom_resnet18.parameters():\n",
    "    #    param.requires_grad = False\n",
    "    \n",
    "    custom_resnet18.fc = nn.Sequential (\n",
    "    nn.Linear(in_features = 512, out_features =1),\n",
    "    nn.Sigmoid()\n",
    "    )\n",
    "    return custom_resnet18\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.700587Z",
     "iopub.status.busy": "2024-10-17T07:52:36.700207Z",
     "iopub.status.idle": "2024-10-17T07:52:36.713930Z",
     "shell.execute_reply": "2024-10-17T07:52:36.712690Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.700547Z"
    }
   },
   "outputs": [],
   "source": [
    "def vgg16(weights = 'DEFAULT'): #David\n",
    "    vgg16 = models.vgg16(weights=weights).to(device)\n",
    "\n",
    "# Freeze the parameters of the base model\n",
    "    for param in vgg16.features.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Modify the classifier part for binary classification with a varied dropout rate\n",
    "    dropout_rate = 0.5  # Typical value used in the original VGG16 paper\n",
    "\n",
    "    vgg16.classifier = nn.Sequential(\n",
    "    nn.Linear(25088, 4096),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=dropout_rate),  # Dropout after the first fully connected layer\n",
    "    nn.Linear(4096, 2048),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=dropout_rate),  # Dropout after the second fully connected layer\n",
    "    nn.Linear(2048, 1),\n",
    "    nn.Sigmoid()  # Binary classification output\n",
    "    )\n",
    "    \n",
    "    vgg16.__class__.__name__ = 'VGG16'\n",
    "    return vgg16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg19 (weights='DEFAULT'):\n",
    "    vgg19 = models.vgg19 (weights=weights).to(device)\n",
    "    \n",
    "    for param in vgg19.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    vgg19.classifier = nn.Sequential (\n",
    "        nn.Linear(25088, 512),        \n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(512, 1),\n",
    "        nn.Sigmoid()          \n",
    "    )\n",
    "    for param in vgg19.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    vgg19.__class__.__name__ = 'VGG19'\n",
    "    return vgg19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.715748Z",
     "iopub.status.busy": "2024-10-17T07:52:36.715395Z",
     "iopub.status.idle": "2024-10-17T07:52:36.731564Z",
     "shell.execute_reply": "2024-10-17T07:52:36.730454Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.715684Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "def calculate_accuracy(outputs, labels, threshold=0.5):\n",
    "    preds = (outputs > threshold).float()\n",
    "    correct = (preds == labels).float().sum()\n",
    "    accuracy = correct / labels.size(0)\n",
    "    return accuracy\n",
    "\n",
    "def train_local_model(model, train_loader, val_loader, num_epochs=10):\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        total_train = 0\n",
    "        threshold = 0.5\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images).squeeze(1).to(device)\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_accuracy += calculate_accuracy(outputs, labels, threshold)\n",
    "            total_train += 1\n",
    "\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_accuracy = 0.0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images).squeeze(1)\n",
    "                loss = criterion(outputs, labels.float())\n",
    "                val_loss += loss.item()\n",
    "                val_accuracy += calculate_accuracy(outputs, labels, threshold)\n",
    "                total_val += 1\n",
    "\n",
    "        avg_val_loss = val_loss / total_val\n",
    "        avg_val_accuracy = val_accuracy / total_val\n",
    "        print (f\"Epoch {epoch + 1}/{num_epochs}:\\ntrain_loss: {running_loss / total_train}, train_accuracy: {running_accuracy / total_train}\\nValidation Loss: {avg_val_loss:.4f}, Validation Accuracy: {avg_val_accuracy:.4f}\")\n",
    "    \n",
    "    return model, avg_val_loss, avg_val_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.735404Z",
     "iopub.status.busy": "2024-10-17T07:52:36.734560Z",
     "iopub.status.idle": "2024-10-17T07:52:36.745997Z",
     "shell.execute_reply": "2024-10-17T07:52:36.745071Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.735357Z"
    }
   },
   "outputs": [],
   "source": [
    "def federated_averaging (client_weights):\n",
    "    avg_weights = client_weights[0].copy()\n",
    "    \n",
    "    for key in avg_weights.keys():\n",
    "        for key in avg_weights.keys():\n",
    "            for i in range (1, len (client_weights)):\n",
    "                avg_weights[key] += client_weights[i][key]\n",
    "                \n",
    "            avg_weights[key] = avg_weights[key] / len (client_weights)\n",
    "            \n",
    "    return avg_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.747769Z",
     "iopub.status.busy": "2024-10-17T07:52:36.747340Z",
     "iopub.status.idle": "2024-10-17T07:52:36.763652Z",
     "shell.execute_reply": "2024-10-17T07:52:36.762494Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.747735Z"
    }
   },
   "outputs": [],
   "source": [
    "def federated_learning (model, num_clients, num_rounds, train_loaders, val_loaders):\n",
    "    global_model = model('DEFAULT')\n",
    "    global_weights = global_model.state_dict()\n",
    "    \n",
    "    for round_num in range (num_rounds):\n",
    "        print (f'Round {round_num+1}')\n",
    "        \n",
    "        client_weights = []\n",
    "        \n",
    "        for client_id in range (num_clients):\n",
    "            print (f'client {client_id+1} training...')\n",
    "            \n",
    "            local_model = model(None)\n",
    "            local_model.load_state_dict (global_weights)\n",
    "            local_model.to(device)\n",
    "            \n",
    "            client_train_loader = train_loaders[client_id]\n",
    "            client_val_loader = val_loaders[client_id]\n",
    "            \n",
    "            output_model, _, _ = train_local_model (local_model, client_train_loader, client_val_loader)\n",
    "            client_updated_weights = output_model.state_dict()\n",
    "            \n",
    "            client_weights.append (client_updated_weights)\n",
    "            \n",
    "        global_weights = federated_averaging (client_weights)\n",
    "        \n",
    "        global_model.load_state_dict (global_weights)\n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.766941Z",
     "iopub.status.busy": "2024-10-17T07:52:36.766599Z",
     "iopub.status.idle": "2024-10-17T07:52:36.788547Z",
     "shell.execute_reply": "2024-10-17T07:52:36.787534Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.766907Z"
    }
   },
   "outputs": [],
   "source": [
    "#Setting up dataset for training the FL model\n",
    "num_clients = 4\n",
    "\n",
    "num_rounds = 3\n",
    "\n",
    "train_loader_0, val_loader_0 = LocalData('clinic_0').dataloader() #replace range() for testing, and remove when the code is ready for the final run.\n",
    "\n",
    "train_loader_1, val_loader_1 = LocalData('clinic_1').dataloader() #replace range() for testing, and remove when the code is ready for the final run.\n",
    "\n",
    "train_loader_2, val_loader_2 = LocalData('clinic_2').dataloader() #replace range() for testing, and remove when the code is ready for the final run.\n",
    "\n",
    "train_loader_3, val_loader_3 = LocalData('clinic_3').dataloader() #replace range() for testing, and remove when the code is ready for the final run.\n",
    "\n",
    "train_loaders = [train_loader_0, train_loader_1, train_loader_2, train_loader_3]\n",
    "val_loaders = [val_loader_0, val_loader_1, val_loader_2, val_loader_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.790407Z",
     "iopub.status.busy": "2024-10-17T07:52:36.790095Z",
     "iopub.status.idle": "2024-10-17T07:52:36.796929Z",
     "shell.execute_reply": "2024-10-17T07:52:36.795980Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.790369Z"
    }
   },
   "outputs": [],
   "source": [
    "# Metrics\n",
    "def metrics (ground_truths, predictions):\n",
    "    accuracy = accuracy_score(ground_truths, predictions).round(4)\n",
    "    precision = precision_score (ground_truths, predictions).round(4)\n",
    "    recall = recall_score (ground_truths, predictions).round(4)\n",
    "    f1 = f1_score (ground_truths, predictions).round(4)\n",
    "    confusion_ma = confusion_matrix (ground_truths, predictions)\n",
    "    \n",
    "    print ('Accuracy score: ', accuracy)\n",
    "    print ('Precision score: ', precision)\n",
    "    print ('Recall score: ', recall)\n",
    "    print ('F1 score: ', f1)\n",
    "    print ('Confusion Matrix: \\n', confusion_ma)\n",
    "    return accuracy, precision, recall, f1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.798647Z",
     "iopub.status.busy": "2024-10-17T07:52:36.798259Z",
     "iopub.status.idle": "2024-10-17T07:52:36.807211Z",
     "shell.execute_reply": "2024-10-17T07:52:36.806196Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.798592Z"
    }
   },
   "outputs": [],
   "source": [
    "#ROC Curve\n",
    "def roc(ground_truths, output_probs):\n",
    "    fpr, tpr, _ = roc_curve (ground_truths, output_probs)\n",
    "    auc_score = roc_auc_score (ground_truths, output_probs)\n",
    "    return fpr, tpr, auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.809086Z",
     "iopub.status.busy": "2024-10-17T07:52:36.808715Z",
     "iopub.status.idle": "2024-10-17T07:52:36.819349Z",
     "shell.execute_reply": "2024-10-17T07:52:36.818306Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.809053Z"
    }
   },
   "outputs": [],
   "source": [
    "#Train client model on clinic4's train_loader\n",
    "#Make prediction on clinic4's val_loader\n",
    "def evaluation(client_model, val_loader):\n",
    "    client_model.eval()\n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "    output_probs = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output = client_model(images)\n",
    "            output_probs.append (output.cpu())\n",
    "            output = output.round()\n",
    "            predictions.append (output.cpu())\n",
    "            ground_truths.append (labels.cpu())\n",
    "    predictions = np.concatenate (predictions).reshape(-1).astype ('int')\n",
    "    ground_truths = np.concatenate (ground_truths)\n",
    "    output_probs = np.concatenate(output_probs)\n",
    "    \n",
    "    return metrics (ground_truths, predictions), roc(ground_truths, output_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.821366Z",
     "iopub.status.busy": "2024-10-17T07:52:36.820640Z",
     "iopub.status.idle": "2024-10-17T07:52:36.834799Z",
     "shell.execute_reply": "2024-10-17T07:52:36.833901Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.821322Z"
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "auc_results = []\n",
    "client_models = [resnet18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Evaluation on the held-out clinic\n",
    "After several rounds of training, the global model's weights are now used as initiallized weights for a fresh client model. Then, we will use this model to make prediction on the eval dataset on the 5th clinic's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.836663Z",
     "iopub.status.busy": "2024-10-17T07:52:36.836285Z",
     "iopub.status.idle": "2024-10-17T07:52:36.849561Z",
     "shell.execute_reply": "2024-10-17T07:52:36.848496Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.836612Z"
    }
   },
   "outputs": [],
   "source": [
    "#Setting up dataset for evaluation on clinic 5\n",
    "train_loader_clinic5, val_loader_clinic5 = LocalData ('clinic_4').dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.851161Z",
     "iopub.status.busy": "2024-10-17T07:52:36.850688Z",
     "iopub.status.idle": "2024-10-17T07:52:36.856034Z",
     "shell.execute_reply": "2024-10-17T07:52:36.855090Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.851053Z"
    }
   },
   "outputs": [],
   "source": [
    "results_1 = []\n",
    "auc_results_1 = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:36.857682Z",
     "iopub.status.busy": "2024-10-17T07:52:36.857274Z",
     "iopub.status.idle": "2024-10-17T07:52:41.255431Z",
     "shell.execute_reply": "2024-10-17T07:52:41.254341Z",
     "shell.execute_reply.started": "2024-10-17T07:52:36.857649Z"
    }
   },
   "outputs": [],
   "source": [
    "for client_model in client_models:\n",
    "    model_name = client_model().__class__.__name__\n",
    "    client_model = train_local_model (client_model('DEFAULT').to(device), train_loader_clinic5, val_loader_clinic5)[0]\n",
    "    eval_output = evaluation(client_model, val_loader_clinic5)\n",
    "    accuracy, precision, recall, f1 = eval_output[0]\n",
    "    fpr, tpr, auc_score = eval_output[1]\n",
    "    results_1.append ([model_name, accuracy, precision, recall, f1])\n",
    "    auc_results_1[model_name] = {\n",
    "                'fpr' : fpr,\n",
    "                'tpr' : tpr,\n",
    "                'auc_score' : auc_score\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:52:41.257504Z",
     "iopub.status.busy": "2024-10-17T07:52:41.257125Z",
     "iopub.status.idle": "2024-10-17T07:53:08.476043Z",
     "shell.execute_reply": "2024-10-17T07:53:08.474901Z",
     "shell.execute_reply.started": "2024-10-17T07:52:41.257465Z"
    }
   },
   "outputs": [],
   "source": [
    "global_models = []\n",
    "for client_model in client_models:\n",
    "    model_name = f'FedAVG {client_model().__class__.__name__}'\n",
    "    print (model_name)\n",
    "    global_model = federated_learning (client_model, num_clients, 2, train_loaders, val_loaders) #change num_rounds according to your GPU, which mine doesn't have one :<.\n",
    "    model = train_local_model (global_model.to(device), train_loader_clinic5, val_loader_clinic5)[0]\n",
    "    eval_output = evaluation(model, val_loader_clinic5)\n",
    "    accuracy, precision, recall, f1 = eval_output[0]\n",
    "    fpr, tpr, auc_score = eval_output[1]\n",
    "    results_1.append ([model_name, accuracy, precision, recall, f1])\n",
    "    auc_results_1[model_name] = {\n",
    "                'fpr' : fpr,\n",
    "                'tpr' : tpr,\n",
    "                'auc_score' : auc_score\n",
    "        }\n",
    "    global_models.append (global_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:53:08.478736Z",
     "iopub.status.busy": "2024-10-17T07:53:08.478354Z",
     "iopub.status.idle": "2024-10-17T07:53:08.488236Z",
     "shell.execute_reply": "2024-10-17T07:53:08.487106Z",
     "shell.execute_reply.started": "2024-10-17T07:53:08.478695Z"
    }
   },
   "outputs": [],
   "source": [
    "df_eval = pd.DataFrame (columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1'],\n",
    "                       data = results_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:53:08.489831Z",
     "iopub.status.busy": "2024-10-17T07:53:08.489471Z",
     "iopub.status.idle": "2024-10-17T07:53:08.517526Z",
     "shell.execute_reply": "2024-10-17T07:53:08.516438Z",
     "shell.execute_reply.started": "2024-10-17T07:53:08.489789Z"
    }
   },
   "outputs": [],
   "source": [
    "df_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:53:08.523484Z",
     "iopub.status.busy": "2024-10-17T07:53:08.523111Z",
     "iopub.status.idle": "2024-10-17T07:53:08.531706Z",
     "shell.execute_reply": "2024-10-17T07:53:08.530525Z",
     "shell.execute_reply.started": "2024-10-17T07:53:08.523445Z"
    }
   },
   "outputs": [],
   "source": [
    "auc_results_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:53:08.534280Z",
     "iopub.status.busy": "2024-10-17T07:53:08.533769Z",
     "iopub.status.idle": "2024-10-17T07:53:08.883328Z",
     "shell.execute_reply": "2024-10-17T07:53:08.882332Z",
     "shell.execute_reply.started": "2024-10-17T07:53:08.534199Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for key in auc_results_1.keys():\n",
    "    plt.plot (auc_results_1[key]['fpr'],\n",
    "              auc_results_1[key]['tpr'], \n",
    "              label = f\"{key} : {auc_results_1[key]['auc_score']:.3f}\")\n",
    "\n",
    "plt.legend(\n",
    "    loc='center left',              # Place the legend outside the plot\n",
    "    bbox_to_anchor=(1, 0.5),        # Position it to the right of the plot\n",
    "    fancybox=True,                  # Fancy box for aesthetics\n",
    "    shadow=True,                    # Add shadow for visual clarity\n",
    "    ncol=1,                         # Single column\n",
    "    frameon=True,                   # Frame around the legend\n",
    "    borderpad=1,                    # Padding around the border\n",
    "    handletextpad=1.5,              # Padding between legend key and label\n",
    "    prop={'size': 10},              # Font size\n",
    "    labelspacing=1,                 # Space between labels in the legend\n",
    ")\n",
    "\n",
    "# Add the grey diagonal line for reference\n",
    "plt.plot([0, 1], [0, 1], color='grey', lw=1, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "\n",
    "# Adjust the legend location and align text to the right\n",
    "plt.legend(\n",
    "    loc='center left',              # Place the legend outside the plot\n",
    "    bbox_to_anchor=(1, 0.5),        # Position it to the right of the plot\n",
    "    fancybox=True,                  # Fancy box for aesthetics\n",
    "    shadow=True,                    # Add shadow for visual clarity\n",
    "    ncol=1,                         # Single column\n",
    "    frameon=True,                   # Frame around the legend\n",
    "    borderpad=1,                    # Padding around the border\n",
    "    handletextpad=1.5,              # Padding between legend key and label\n",
    "    prop={'size': 10},              # Font size\n",
    "    labelspacing=1,                 # Space between labels in the legend\n",
    ")\n",
    "\n",
    "# Modify alignment for text inside the legend (right-align)\n",
    "for text in plt.gca().get_legend().get_texts():\n",
    "    text.set_ha('right')  # Align the legend text to the right\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Evaluation on each client's validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:53:49.879250Z",
     "iopub.status.busy": "2024-10-17T07:53:49.878459Z",
     "iopub.status.idle": "2024-10-17T07:53:49.883450Z",
     "shell.execute_reply": "2024-10-17T07:53:49.882416Z",
     "shell.execute_reply.started": "2024-10-17T07:53:49.879210Z"
    }
   },
   "outputs": [],
   "source": [
    "results_2 = []\n",
    "auc_results_2 = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:53:50.030836Z",
     "iopub.status.busy": "2024-10-17T07:53:50.030055Z",
     "iopub.status.idle": "2024-10-17T07:54:01.541463Z",
     "shell.execute_reply": "2024-10-17T07:54:01.540611Z",
     "shell.execute_reply.started": "2024-10-17T07:53:50.030796Z"
    }
   },
   "outputs": [],
   "source": [
    "for client_model in client_models:\n",
    "    model_name = client_model().__class__.__name__\n",
    "    auc_results_2[model_name] = dict()\n",
    "    for i in range (4):\n",
    "        local_model = train_local_model (client_model('DEFAULT').to(device), train_loaders[i], val_loaders[i])[0]\n",
    "        eval_model = evaluation (local_model, val_loaders[i])\n",
    "        accuracy, precision, recall, f1 = eval_model[0]\n",
    "        fpr, tpr, auc_score = eval_model[1]\n",
    "        results_2.append ([model_name, f'Clinic_{i}', accuracy, precision, recall, f1])\n",
    "        auc_results_2[model_name][f'Clinic_{i}'] = {\n",
    "            'fpr' : fpr,\n",
    "            'tpr' : tpr,\n",
    "            'auc_score' : auc_score\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:54:01.544265Z",
     "iopub.status.busy": "2024-10-17T07:54:01.543318Z",
     "iopub.status.idle": "2024-10-17T07:54:12.257832Z",
     "shell.execute_reply": "2024-10-17T07:54:12.256782Z",
     "shell.execute_reply.started": "2024-10-17T07:54:01.544222Z"
    }
   },
   "outputs": [],
   "source": [
    "for client_model, global_model in zip(client_models, global_models):\n",
    "    #global_model = federated_learning (client_model, num_clients, 2, train_loaders, val_loaders) #change num_rounds according to your GPU, which mine doesn't have one :<.\n",
    "    model_name = f'FedAVG {client_model().__class__.__name__}'\n",
    "    auc_results_2[model_name] = dict()\n",
    "    for i in range (4):\n",
    "        print (model_name)\n",
    "        model = train_local_model (global_model.to(device), train_loaders[i], val_loaders[i])[0]\n",
    "        eval_model = evaluation(model, val_loaders[i])\n",
    "        accuracy, precision, recall, f1 = eval_model[0]\n",
    "        results_2.append ([model_name, f'Clinic_{i}', accuracy, precision, recall, f1])\n",
    "        \n",
    "        fpr, tpr, auc_score = eval_model[1]\n",
    "        results_2.append ([model_name, f'Clinic_{i}', accuracy, precision, recall, f1])\n",
    "        auc_results_2[model_name][f'Clinic_{i}'] = {\n",
    "            'fpr' : fpr,\n",
    "            'tpr' : tpr,\n",
    "            'auc_score' : auc_score\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:54:12.259607Z",
     "iopub.status.busy": "2024-10-17T07:54:12.259233Z",
     "iopub.status.idle": "2024-10-17T07:54:12.265761Z",
     "shell.execute_reply": "2024-10-17T07:54:12.264611Z",
     "shell.execute_reply.started": "2024-10-17T07:54:12.259569Z"
    }
   },
   "outputs": [],
   "source": [
    "df_eval_2 = pd.DataFrame (columns = ['Model', 'Clinic', 'Accuracy', 'Precision', 'Recall', 'F1'],\n",
    "                         data = results_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:54:12.268384Z",
     "iopub.status.busy": "2024-10-17T07:54:12.268036Z",
     "iopub.status.idle": "2024-10-17T07:54:12.650208Z",
     "shell.execute_reply": "2024-10-17T07:54:12.649175Z",
     "shell.execute_reply.started": "2024-10-17T07:54:12.268348Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "for model in auc_results_2:\n",
    "    for clinic in auc_results_2[model]:\n",
    "        plt.plot(\n",
    "            auc_results_2[model][clinic]['fpr'], \n",
    "            auc_results_2[model][clinic]['tpr'], \n",
    "            label=f\"{model} - {clinic} : {auc_results_2[model][clinic]['auc_score']:.3f}\"\n",
    "        )\n",
    "\n",
    "# Add the grey diagonal line for reference\n",
    "plt.plot([0, 1], [0, 1], color='grey', lw=1, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "# Set plot labels and title\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "\n",
    "# Adjust the legend location and align text to the right\n",
    "plt.legend(\n",
    "    loc='center left',              # Place the legend outside the plot\n",
    "    bbox_to_anchor=(1, 0.5),        # Position it to the right of the plot\n",
    "    fancybox=True,                  # Fancy box for aesthetics\n",
    "    shadow=True,                    # Add shadow for visual clarity\n",
    "    ncol=1,                         # Single column\n",
    "    frameon=True,                   # Frame around the legend\n",
    "    borderpad=1,                    # Padding around the border\n",
    "    handletextpad=1.5,              # Padding between legend key and label\n",
    "    prop={'size': 10},              # Font size\n",
    "    labelspacing=1,                 # Space between labels in the legend\n",
    ")\n",
    "\n",
    "# Modify alignment for text inside the legend (right-align)\n",
    "for text in plt.gca().get_legend().get_texts():\n",
    "    text.set_ha('right')  # Align the legend text to the right\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:54:12.652080Z",
     "iopub.status.busy": "2024-10-17T07:54:12.651635Z",
     "iopub.status.idle": "2024-10-17T07:54:12.668794Z",
     "shell.execute_reply": "2024-10-17T07:54:12.667900Z",
     "shell.execute_reply.started": "2024-10-17T07:54:12.652031Z"
    }
   },
   "outputs": [],
   "source": [
    "df_eval_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-17T07:54:12.671014Z",
     "iopub.status.busy": "2024-10-17T07:54:12.670258Z",
     "iopub.status.idle": "2024-10-17T07:54:12.684960Z",
     "shell.execute_reply": "2024-10-17T07:54:12.684020Z",
     "shell.execute_reply.started": "2024-10-17T07:54:12.670970Z"
    }
   },
   "outputs": [],
   "source": [
    "auc_results_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
