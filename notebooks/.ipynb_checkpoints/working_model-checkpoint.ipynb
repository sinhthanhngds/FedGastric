{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f08026bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T16:25:07.408024Z",
     "iopub.status.busy": "2024-09-22T16:25:07.407159Z",
     "iopub.status.idle": "2024-09-22T16:25:07.413104Z",
     "shell.execute_reply": "2024-09-22T16:25:07.412112Z",
     "shell.execute_reply.started": "2024-09-22T16:25:07.407989Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7950b78a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T16:25:07.415758Z",
     "iopub.status.busy": "2024-09-22T16:25:07.415389Z",
     "iopub.status.idle": "2024-09-22T16:25:07.425669Z",
     "shell.execute_reply": "2024-09-22T16:25:07.424749Z",
     "shell.execute_reply.started": "2024-09-22T16:25:07.415727Z"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa3a2f3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T16:25:07.426981Z",
     "iopub.status.busy": "2024-09-22T16:25:07.426737Z",
     "iopub.status.idle": "2024-09-22T16:25:07.436866Z",
     "shell.execute_reply": "2024-09-22T16:25:07.436035Z",
     "shell.execute_reply.started": "2024-09-22T16:25:07.426960Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Subset, ConcatDataset\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "from torchvision import models, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c034a23f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T16:25:07.438063Z",
     "iopub.status.busy": "2024-09-22T16:25:07.437830Z",
     "iopub.status.idle": "2024-09-22T16:25:07.446852Z",
     "shell.execute_reply": "2024-09-22T16:25:07.445947Z",
     "shell.execute_reply.started": "2024-09-22T16:25:07.438043Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a590cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66d7ae6",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91e83820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalData:\n",
    "    def __init__ (self, clinic_id, data_range): #data_range will be removed for final code\n",
    "        self.clinic_id = clinic_id\n",
    "        self.path = f'../120_dataset/{clinic_id}/'\n",
    "        self.range = data_range #remove for final code\n",
    "        \n",
    "        \n",
    "    def dataset (self):\n",
    "        transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),  # Resize images to a fixed size (optional)\n",
    "        transforms.ToTensor(),          # Convert images to PyTorch tensors\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]) \n",
    "        ])\n",
    "\n",
    "# Load the dataset from the train folder\n",
    "        train_dataset = datasets.ImageFolder(root=f'{self.path}', transform=transform)\n",
    "        subset_indices = list(self.range)    #remove for final code\n",
    "        train_dataset = Subset (train_dataset, subset_indices) #remove for final code\n",
    "\n",
    "        train_size = int(0.8*len(train_dataset))\n",
    "        val_size = len(train_dataset)-train_size\n",
    "\n",
    "        train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
    "        return train_subset, val_subset\n",
    "    \n",
    "    def dataloader(self):  \n",
    "        train_subset, val_subset = self.dataset()\n",
    "        train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "        print (f'loading {self.clinic_id}')\n",
    "        return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223898ea",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0db71a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def resnet18 (weights='DEFAULT'):\n",
    "    \n",
    "    resnet18 = models.resnet18(weights = weights).to(device)\n",
    "    for param in resnet18.parameters():\n",
    "        param.requires_grad = False\n",
    "    resnet18.fc = nn.Sequential (\n",
    "    nn.Linear(in_features = 512, out_features = 256, bias = True),\n",
    "    nn.Dropout(p = 0.5),\n",
    "    nn.Linear(in_features = 256, out_features = 1, bias = True),\n",
    "    nn.Sigmoid()\n",
    "    )\n",
    "    \n",
    "    for param in resnet18.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    return resnet18\n",
    "\n",
    "def vgg16(weights = 'DEFAULT'):\n",
    "    model = models.vgg16(weights=weights).to(device)\n",
    "\n",
    "# Freeze the parameters of the base model\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "# Modify the classifier part for binary classification\n",
    "    model.classifier[6] = nn.Sequential(\n",
    "        nn.Linear(model.classifier[6].in_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(512, 1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "    \n",
    "def vgg19 (weights='DEFAULT'):\n",
    "    vgg19 = models.vgg19 (weights=weights).to(device)\n",
    "    \n",
    "    for param in vgg19.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    vgg19.classifier = nn.Sequential (\n",
    "        nn.Linear(25088, 4096),        \n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(4096, 4096),       \n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(4096, 1),\n",
    "        nn.Sigmoid()          \n",
    "    )\n",
    "    for param in vgg19.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    return vgg19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aea9d2",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81c1f33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm  # Import tqdm for the progress bar\n",
    "from local_data import LocalData\n",
    "from cnn_models import vgg16\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def calculate_accuracy(outputs, labels, threshold=0.5):\n",
    "    preds = (outputs > threshold).float()\n",
    "    correct = (preds == labels).float().sum()\n",
    "    accuracy = correct / labels.size(0)\n",
    "    return accuracy\n",
    "\n",
    "def train_local_model(model, train_loader, val_loader, num_epochs=10):\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        total_train = 0\n",
    "        threshold = 0.5\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images).squeeze(1)\n",
    "            print (outputs)\n",
    "            print (labels)\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_accuracy += calculate_accuracy(outputs, labels, threshold)\n",
    "            total_train += 1\n",
    "\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_accuracy = 0.0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images).squeeze(1)\n",
    "                loss = criterion(outputs, labels.float())\n",
    "                val_loss += loss.item()\n",
    "                val_accuracy += calculate_accuracy(outputs, labels, threshold)\n",
    "                total_val += 1\n",
    "\n",
    "        avg_val_loss = val_loss / total_val\n",
    "        avg_val_accuracy = val_accuracy / total_val\n",
    "        print (f\"Epoch {epoch + 1}/{num_epochs}:\\ntrain_loss: {running_loss / total_train}, train_accuracy: {running_accuracy / total_train}\\nValidation Loss: {avg_val_loss:.4f}, Validation Accuracy: {avg_val_accuracy:.4f}\")\n",
    "    \n",
    "    return model, avg_val_loss, avg_val_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4b634d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4663fae",
   "metadata": {},
   "source": [
    "### Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2841ac0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_averaging (client_weights):\n",
    "    avg_weights = client_weights[0].copy()\n",
    "    \n",
    "    for key in avg_weights.keys():\n",
    "        for key in avg_weights.keys():\n",
    "            for i in range (1, len (client_weights)):\n",
    "                avg_weights[key] += client_weights[i][key]\n",
    "                \n",
    "            avg_weights[key] = avg_weights[key] / len (client_weights)\n",
    "            \n",
    "    return avg_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34dacdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def federated_learning (global_model, local_model, num_clients, num_rounds, train_loaders, val_loaders):\n",
    "    global_model = global_model\n",
    "    global_weights = global_model.state_dict()\n",
    "    \n",
    "    for round_num in range (num_rounds):\n",
    "        print (f'Round {round_num+1}')\n",
    "        \n",
    "        client_weights = []\n",
    "        \n",
    "        for client_id in range (num_clients):\n",
    "            print (f'client {client_id+1} training...')\n",
    "            \n",
    "            local_model = local_model\n",
    "            local_model.load_state_dict (global_weights)\n",
    "            local_model.to(device)\n",
    "            \n",
    "            client_train_loader = train_loaders[client_id]\n",
    "            client_val_loader = val_loaders[client_id]\n",
    "            \n",
    "            output_model, _, _ = train_local_model (local_model, client_train_loader, client_val_loader)\n",
    "            client_updated_weights = output_model.state_dict()\n",
    "            \n",
    "            client_weights.append (client_updated_weights)\n",
    "            \n",
    "        global_weights = federated_averaging (client_weights)\n",
    "        \n",
    "        global_model.load_state_dict (global_weights)\n",
    "        \n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa05b9ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading clinic_0\n",
      "loading clinic_1\n",
      "loading clinic_2\n",
      "loading clinic_3\n"
     ]
    }
   ],
   "source": [
    "num_clients = 4\n",
    "\n",
    "num_rounds = 3\n",
    "\n",
    "train_loader_0, val_loader_0 = LocalData('clinic_0', range(8100, 8300)).dataloader()\n",
    "\n",
    "train_loader_1, val_loader_1 = LocalData('clinic_1', range(8100, 8300)).dataloader()\n",
    "\n",
    "train_loader_2, val_loader_2 = LocalData('clinic_2', range(8100, 8300)).dataloader()\n",
    "\n",
    "train_loader_3, val_loader_3 = LocalData('clinic_3', range(8100, 8300)).dataloader()\n",
    "\n",
    "\n",
    "train_loaders = [train_loader_0, train_loader_1, train_loader_2, train_loader_3]\n",
    "val_loaders = [val_loader_0, val_loader_1, val_loader_2, val_loader_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37fc3081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading clinic_4\n"
     ]
    }
   ],
   "source": [
    "train_loader_clinic5, val_loader_clinic5 = LocalData ('clinic_4', range (7600, 7800)).dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdbcd6eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "client 1 training...\n",
      "Epoch 1/10:\n",
      "Train Loss: 0.7119, Train Accuracy: 0.4875\n",
      "Validation Loss: 0.6993, Validation Accuracy: 0.5000\n",
      "Epoch 2/10:\n",
      "Train Loss: 0.6939, Train Accuracy: 0.5437\n",
      "Validation Loss: 0.6923, Validation Accuracy: 0.5000\n",
      "Epoch 3/10:\n",
      "Train Loss: 0.6878, Train Accuracy: 0.5437\n",
      "Validation Loss: 0.6871, Validation Accuracy: 0.5781\n",
      "Epoch 4/10:\n",
      "Train Loss: 0.6890, Train Accuracy: 0.5000\n",
      "Validation Loss: 0.6862, Validation Accuracy: 0.5156\n",
      "Epoch 5/10:\n",
      "Train Loss: 0.6888, Train Accuracy: 0.5375\n",
      "Validation Loss: 0.6821, Validation Accuracy: 0.6562\n",
      "Epoch 6/10:\n",
      "Train Loss: 0.6646, Train Accuracy: 0.5750\n",
      "Validation Loss: 0.6785, Validation Accuracy: 0.5938\n",
      "Epoch 7/10:\n",
      "Train Loss: 0.6750, Train Accuracy: 0.6000\n",
      "Validation Loss: 0.6760, Validation Accuracy: 0.5781\n",
      "Early stopping triggered. Restoring the best model...\n",
      "client 2 training...\n",
      "Epoch 1/10:\n",
      "Train Loss: 0.7133, Train Accuracy: 0.5125\n",
      "Validation Loss: 0.7013, Validation Accuracy: 0.4844\n",
      "Epoch 2/10:\n",
      "Train Loss: 0.6988, Train Accuracy: 0.4938\n",
      "Validation Loss: 0.6955, Validation Accuracy: 0.4844\n",
      "Epoch 3/10:\n",
      "Train Loss: 0.7016, Train Accuracy: 0.5250\n",
      "Validation Loss: 0.6919, Validation Accuracy: 0.4688\n",
      "Early stopping triggered. Restoring the best model...\n",
      "client 3 training...\n",
      "Epoch 1/10:\n",
      "Train Loss: 0.6763, Train Accuracy: 0.5813\n",
      "Validation Loss: 0.6923, Validation Accuracy: 0.4844\n",
      "Epoch 2/10:\n",
      "Train Loss: 0.6947, Train Accuracy: 0.4813\n",
      "Validation Loss: 0.6908, Validation Accuracy: 0.5625\n",
      "Epoch 3/10:\n",
      "Train Loss: 0.6905, Train Accuracy: 0.5375\n",
      "Validation Loss: 0.6893, Validation Accuracy: 0.5938\n",
      "Epoch 4/10:\n",
      "Train Loss: 0.7101, Train Accuracy: 0.4813\n",
      "Validation Loss: 0.6882, Validation Accuracy: 0.6406\n",
      "Epoch 5/10:\n",
      "Train Loss: 0.6846, Train Accuracy: 0.5375\n",
      "Validation Loss: 0.6867, Validation Accuracy: 0.6094\n",
      "Epoch 6/10:\n",
      "Train Loss: 0.7021, Train Accuracy: 0.5000\n",
      "Validation Loss: 0.6850, Validation Accuracy: 0.5000\n",
      "Early stopping triggered. Restoring the best model...\n",
      "client 4 training...\n",
      "Epoch 1/10:\n",
      "Train Loss: 0.7167, Train Accuracy: 0.5062\n",
      "Validation Loss: 0.6989, Validation Accuracy: 0.4844\n",
      "Epoch 2/10:\n",
      "Train Loss: 0.7258, Train Accuracy: 0.4938\n",
      "Validation Loss: 0.6997, Validation Accuracy: 0.4844\n",
      "Epoch 3/10:\n",
      "Train Loss: 0.6935, Train Accuracy: 0.5125\n",
      "Validation Loss: 0.6885, Validation Accuracy: 0.6094\n",
      "Epoch 4/10:\n",
      "Train Loss: 0.6988, Train Accuracy: 0.5375\n",
      "Validation Loss: 0.6854, Validation Accuracy: 0.5156\n",
      "Epoch 5/10:\n",
      "Train Loss: 0.7065, Train Accuracy: 0.5125\n",
      "Validation Loss: 0.6852, Validation Accuracy: 0.5156\n",
      "Early stopping triggered. Restoring the best model...\n",
      "Round 2\n",
      "client 1 training...\n",
      "Epoch 1/10:\n",
      "Train Loss: 39.0191, Train Accuracy: 0.5375\n",
      "Validation Loss: 50.0000, Validation Accuracy: 0.5000\n",
      "Epoch 2/10:\n",
      "Train Loss: 39.9611, Train Accuracy: 0.5125\n",
      "Validation Loss: 50.0000, Validation Accuracy: 0.5000\n",
      "Epoch 3/10:\n",
      "Train Loss: 35.8888, Train Accuracy: 0.5563\n",
      "Validation Loss: 50.0000, Validation Accuracy: 0.5000\n",
      "Early stopping triggered. Restoring the best model...\n",
      "client 2 training...\n",
      "Epoch 1/10:\n",
      "Train Loss: 34.2917, Train Accuracy: 0.5875\n",
      "Validation Loss: 48.4375, Validation Accuracy: 0.5156\n",
      "Epoch 2/10:\n",
      "Train Loss: 34.6692, Train Accuracy: 0.5687\n",
      "Validation Loss: 48.4375, Validation Accuracy: 0.5156\n",
      "Epoch 3/10:\n",
      "Train Loss: 39.4030, Train Accuracy: 0.5188\n",
      "Validation Loss: 48.0859, Validation Accuracy: 0.5156\n",
      "Early stopping triggered. Restoring the best model...\n",
      "client 3 training...\n",
      "Epoch 1/10:\n",
      "Train Loss: 36.7425, Train Accuracy: 0.5500\n",
      "Validation Loss: 48.4375, Validation Accuracy: 0.5156\n",
      "Epoch 2/10:\n",
      "Train Loss: 45.8791, Train Accuracy: 0.4688\n",
      "Validation Loss: 43.7500, Validation Accuracy: 0.5625\n",
      "Epoch 3/10:\n",
      "Train Loss: 43.3968, Train Accuracy: 0.4562\n",
      "Validation Loss: 48.6004, Validation Accuracy: 0.5000\n",
      "Epoch 4/10:\n",
      "Train Loss: 36.5767, Train Accuracy: 0.5500\n",
      "Validation Loss: 32.0952, Validation Accuracy: 0.5312\n",
      "Early stopping triggered. Restoring the best model...\n",
      "client 4 training...\n",
      "Epoch 1/10:\n",
      "Train Loss: 38.7576, Train Accuracy: 0.5188\n",
      "Validation Loss: 48.4375, Validation Accuracy: 0.5156\n",
      "Epoch 2/10:\n",
      "Train Loss: 45.0859, Train Accuracy: 0.4750\n",
      "Validation Loss: 48.4375, Validation Accuracy: 0.5156\n",
      "Epoch 3/10:\n",
      "Train Loss: 37.9216, Train Accuracy: 0.5375\n",
      "Validation Loss: 48.4375, Validation Accuracy: 0.5156\n",
      "Early stopping triggered. Restoring the best model...\n",
      "Round 3\n",
      "client 1 training...\n",
      "Epoch 1/10:\n",
      "Train Loss: 46.2500, Train Accuracy: 0.5375\n",
      "Validation Loss: 50.0000, Validation Accuracy: 0.5000\n",
      "Epoch 2/10:\n",
      "Train Loss: 46.2500, Train Accuracy: 0.5375\n",
      "Validation Loss: 50.0000, Validation Accuracy: 0.5000\n",
      "Epoch 3/10:\n",
      "Train Loss: 47.5000, Train Accuracy: 0.5250\n",
      "Validation Loss: 50.0000, Validation Accuracy: 0.5000\n",
      "Early stopping triggered. Restoring the best model...\n",
      "client 2 training...\n",
      "Epoch 1/10:\n",
      "Train Loss: 40.0000, Train Accuracy: 0.6000\n",
      "Validation Loss: 48.4375, Validation Accuracy: 0.5156\n",
      "Epoch 2/10:\n",
      "Train Loss: 49.3750, Train Accuracy: 0.5062\n",
      "Validation Loss: 48.4375, Validation Accuracy: 0.5156\n",
      "Epoch 3/10:\n",
      "Train Loss: 51.8750, Train Accuracy: 0.4813\n",
      "Validation Loss: 48.4375, Validation Accuracy: 0.5156\n",
      "Early stopping triggered. Restoring the best model...\n",
      "client 3 training...\n",
      "Epoch 1/10:\n",
      "Train Loss: 57.5000, Train Accuracy: 0.4250\n",
      "Validation Loss: 48.4375, Validation Accuracy: 0.5156\n",
      "Epoch 2/10:\n",
      "Train Loss: 47.5000, Train Accuracy: 0.5250\n",
      "Validation Loss: 48.4375, Validation Accuracy: 0.5156\n",
      "Epoch 3/10:\n",
      "Train Loss: 58.1250, Train Accuracy: 0.4188\n",
      "Validation Loss: 48.4375, Validation Accuracy: 0.5156\n",
      "Early stopping triggered. Restoring the best model...\n",
      "client 4 training...\n",
      "Epoch 1/10:\n",
      "Train Loss: 41.8750, Train Accuracy: 0.5813\n",
      "Validation Loss: 48.4375, Validation Accuracy: 0.5156\n",
      "Epoch 2/10:\n",
      "Train Loss: 39.3750, Train Accuracy: 0.6062\n",
      "Validation Loss: 48.4375, Validation Accuracy: 0.5156\n",
      "Epoch 3/10:\n",
      "Train Loss: 41.2500, Train Accuracy: 0.5875\n",
      "Validation Loss: 48.4375, Validation Accuracy: 0.5156\n",
      "Early stopping triggered. Restoring the best model...\n"
     ]
    }
   ],
   "source": [
    "resnet = federated_learning (resnet18(None), resnet18(None), num_clients, num_rounds, train_loaders, val_loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c75c77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "Train Loss: 56.2500, Train Accuracy: 0.4375\n",
      "Validation Loss: 53.1250, Validation Accuracy: 0.4688\n",
      "Epoch 2/10:\n",
      "Train Loss: 56.8750, Train Accuracy: 0.4313\n",
      "Validation Loss: 53.1250, Validation Accuracy: 0.4688\n",
      "Epoch 3/10:\n",
      "Train Loss: 55.6250, Train Accuracy: 0.4437\n",
      "Validation Loss: 53.1250, Validation Accuracy: 0.4688\n",
      "Early stopping triggered. Restoring the best model...\n"
     ]
    }
   ],
   "source": [
    "clin_5 = train_local_model (resnet, train_loader_clinic5, val_loader_clinic5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b747ffac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "Train Loss: 0.6726, Train Accuracy: 0.6500\n",
      "Validation Loss: 0.7795, Validation Accuracy: 0.5312\n",
      "Epoch 2/10:\n",
      "Train Loss: 0.5756, Train Accuracy: 0.7375\n",
      "Validation Loss: 0.7970, Validation Accuracy: 0.5312\n",
      "Epoch 3/10:\n",
      "Train Loss: 0.5455, Train Accuracy: 0.7375\n",
      "Validation Loss: 0.7619, Validation Accuracy: 0.5312\n",
      "Early stopping triggered. Restoring the best model...\n"
     ]
    }
   ],
   "source": [
    "cl = train_local_model (resnet18(), train_loader_clinic5, val_loader_clinic5)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b9a3a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "Accuracy score:  0.45\n",
      "Precision score:  0.0\n",
      "Recall score:  0.0\n",
      "F1 score:  0.0\n",
      "Confusion Matrix: \n",
      " [[18  0]\n",
      " [22  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "evaluation(clin_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92fde0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8843, 0.6846, 0.6354, 0.6401, 0.7873, 0.7866, 0.8195, 0.7555, 0.8272,\n",
      "        0.7787, 0.7241, 0.6440, 0.7352, 0.7904, 0.7293, 0.7389, 0.5990, 0.6738,\n",
      "        0.7227, 0.7704, 0.6803, 0.8143, 0.6694, 0.7728, 0.8078, 0.5394, 0.7745,\n",
      "        0.7110, 0.7018, 0.7591, 0.7099, 0.7741])\n",
      "tensor([0.7574, 0.8137, 0.7545, 0.7131, 0.6641, 0.8164, 0.7888, 0.7013])\n",
      "Accuracy score:  0.55\n",
      "Precision score:  0.55\n",
      "Recall score:  1.0\n",
      "F1 score:  0.7097\n",
      "Confusion Matrix: \n",
      " [[ 0 18]\n",
      " [ 0 22]]\n"
     ]
    }
   ],
   "source": [
    "evaluation (cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551c035d",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6eedb6",
   "metadata": {},
   "source": [
    "After several rounds of training, the global model's weights are now used as initiallized weights for a fresh client model. Then, we will use this model to make prediction on the 5th clinic's data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "997d7ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 0, 1, 1, 1])\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for item in iter(val_loader_clinic5):\n",
    "    print (item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ce092bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "def metrics (ground_truths, predictions):\n",
    "    accuracy = accuracy_score(ground_truths, predictions).round(4)\n",
    "    precision = precision_score (ground_truths, predictions).round(4)\n",
    "    recall = recall_score (ground_truths, predictions).round(4)\n",
    "    f1 = f1_score (ground_truths, predictions).round(4)\n",
    "    confusion_ma = confusion_matrix (ground_truths, predictions)\n",
    "    \n",
    "    print ('Accuracy score: ',accuracy)\n",
    "    print ('Precision score: ', precision)\n",
    "    print ('Recall score: ', recall)\n",
    "    print ('F1 score: ', f1)\n",
    "    print ('Confusion Matrix: \\n', confusion_ma)\n",
    "    return accuracy, precision, recall, f1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "032dced4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train client model on clinic4's train_loader\n",
    "#Make prediction on clinic4's val_loader\n",
    "def evaluation(client_model):\n",
    "    client_model.eval()\n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader_clinic5:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output = client_model(images)\n",
    "            print (output.reshape(-1))\n",
    "            output = output.round()\n",
    "            predictions.append (output)\n",
    "            ground_truths.append (labels)\n",
    "    predictions = np.concatenate (predictions).reshape(-1).astype ('int')\n",
    "    ground_truths = np.concatenate (ground_truths)\n",
    "    \n",
    "    metrics (ground_truths, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26656434",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet\n",
      "Accuracy score:  0.8\n",
      "Precision score:  0.7667\n",
      "Recall score:  0.8214\n",
      "F1 score:  0.7931\n",
      "Confusion Matrix: \n",
      " [[25  7]\n",
      " [ 5 23]]\n",
      "VGG\n",
      "Accuracy score:  0.8167\n",
      "Precision score:  0.7429\n",
      "Recall score:  0.9286\n",
      "F1 score:  0.8254\n",
      "Confusion Matrix: \n",
      " [[23  9]\n",
      " [ 2 26]]\n",
      "VGG\n",
      "Accuracy score:  0.8167\n",
      "Precision score:  0.7742\n",
      "Recall score:  0.8571\n",
      "F1 score:  0.8136\n",
      "Confusion Matrix: \n",
      " [[25  7]\n",
      " [ 4 24]]\n"
     ]
    }
   ],
   "source": [
    "client_models = [resnet18(), vgg16(), vgg19()]\n",
    "for client_model in client_models:\n",
    "    print (client_model.__class__.__name__)\n",
    "    client_model = train_local_model (client_model, train_loader_clinic5, val_loader_clinic5)[0]\n",
    "\n",
    "    evaluation (client_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3cc9581",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "client 1 training...\n",
      "client 2 training...\n",
      "client 3 training...\n",
      "client 4 training...\n",
      "Round 2\n",
      "client 1 training...\n",
      "client 2 training...\n",
      "client 3 training...\n",
      "client 4 training...\n",
      "Round 3\n",
      "client 1 training...\n",
      "client 2 training...\n",
      "client 3 training...\n",
      "client 4 training...\n",
      "Accuracy score:  0.8667\n",
      "Precision score:  0.8846\n",
      "Recall score:  0.8214\n",
      "F1 score:  0.8519\n",
      "Confusion Matrix: \n",
      " [[29  3]\n",
      " [ 5 23]]\n",
      "Round 1\n",
      "client 1 training...\n",
      "client 2 training...\n",
      "client 3 training...\n",
      "client 4 training...\n",
      "Round 2\n",
      "client 1 training...\n",
      "client 2 training...\n",
      "client 3 training...\n",
      "client 4 training...\n",
      "Round 3\n",
      "client 1 training...\n",
      "client 2 training...\n",
      "client 3 training...\n",
      "client 4 training...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m client_model \u001b[38;5;129;01min\u001b[39;00m client_models:\n\u001b[1;32m      2\u001b[0m     global_model \u001b[38;5;241m=\u001b[39m federated_learning (client_model, num_clients, num_rounds, train_loaders, val_loaders)\n\u001b[0;32m----> 3\u001b[0m     model \u001b[38;5;241m=\u001b[39m train_local_model (global_model, train_loader_clinic5, val_loader_clinic5)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      4\u001b[0m     evaluation (model)\n",
      "Cell \u001b[0;32mIn[18], line 25\u001b[0m, in \u001b[0;36mtrain_local_model\u001b[0;34m(model, train_loader, val_loader, num_epochs)\u001b[0m\n\u001b[1;32m     22\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     26\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/loss.py:621\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(\u001b[38;5;28minput\u001b[39m, target, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:3172\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3169\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3170\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(\u001b[38;5;28minput\u001b[39m, target, weight, reduction_enum)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "for client_model in client_models:\n",
    "    global_model = federated_learning (client_model, num_clients, num_rounds, train_loaders, val_loaders)\n",
    "    model = train_local_model (global_model, train_loader_clinic5, val_loader_clinic5)[0]\n",
    "    evaluation (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f665f782",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model = federated_learning (client_model, num_clients, num_rounds, train_loaders, val_loaders)\n",
    "output_model = client_model.load_state_dict (global_model.state_dict())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5650643,
     "sourceId": 9326939,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
