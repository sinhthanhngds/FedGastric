{
 "cells": [
  {
   "cell_type": "code",
   "id": "30848592",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T16:25:07.408024Z",
     "iopub.status.busy": "2024-09-22T16:25:07.407159Z",
     "iopub.status.idle": "2024-09-22T16:25:07.413104Z",
     "shell.execute_reply": "2024-09-22T16:25:07.412112Z",
     "shell.execute_reply.started": "2024-09-22T16:25:07.407989Z"
    },
    "ExecuteTime": {
     "end_time": "2024-10-10T09:59:12.973152Z",
     "start_time": "2024-10-10T09:59:12.521556Z"
    }
   },
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "1a620ba4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T16:25:07.415758Z",
     "iopub.status.busy": "2024-09-22T16:25:07.415389Z",
     "iopub.status.idle": "2024-09-22T16:25:07.425669Z",
     "shell.execute_reply": "2024-09-22T16:25:07.424749Z",
     "shell.execute_reply.started": "2024-09-22T16:25:07.415727Z"
    },
    "ExecuteTime": {
     "end_time": "2024-10-10T09:59:12.980528Z",
     "start_time": "2024-10-10T09:59:12.978800Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import io\n",
    "import os "
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "0971381c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T16:25:07.426981Z",
     "iopub.status.busy": "2024-09-22T16:25:07.426737Z",
     "iopub.status.idle": "2024-09-22T16:25:07.436866Z",
     "shell.execute_reply": "2024-09-22T16:25:07.436035Z",
     "shell.execute_reply.started": "2024-09-22T16:25:07.426960Z"
    },
    "ExecuteTime": {
     "end_time": "2024-10-10T09:59:14.016885Z",
     "start_time": "2024-10-10T09:59:13.078234Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split, Subset, ConcatDataset\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "from torchvision import models, datasets\n",
    "from torchsummary import summary"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "3fee402d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-22T16:25:07.438063Z",
     "iopub.status.busy": "2024-09-22T16:25:07.437830Z",
     "iopub.status.idle": "2024-09-22T16:25:07.446852Z",
     "shell.execute_reply": "2024-09-22T16:25:07.445947Z",
     "shell.execute_reply.started": "2024-09-22T16:25:07.438043Z"
    },
    "ExecuteTime": {
     "end_time": "2024-10-10T09:59:14.317012Z",
     "start_time": "2024-10-10T09:59:14.022508Z"
    }
   },
   "source": "from sklearn.model_selection import train_test_split",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "efe39a00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T09:59:14.323128Z",
     "start_time": "2024-10-10T09:59:14.321412Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "0ac21804",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "992e8be4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T09:59:14.330129Z",
     "start_time": "2024-10-10T09:59:14.327091Z"
    }
   },
   "source": [
    "class LocalData:\n",
    "    def __init__ (self, clinic_id): #data_range will be removed for final code\n",
    "        self.clinic_id = clinic_id\n",
    "        self.path = f'../120_dataset/{clinic_id}/'\n",
    "        #self.range = data_range #remove for final code\n",
    "        \n",
    "        \n",
    "    def dataset (self):\n",
    "        transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize images to a fixed size (optional)\n",
    "        transforms.ToTensor(),          # Convert images to PyTorch tensors\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]) \n",
    "        ])\n",
    "\n",
    "# Load the dataset from the train folder\n",
    "        train_dataset = datasets.ImageFolder(root=f'{self.path}', transform=transform)\n",
    "        #subset_indices = list(self.range)    #remove for final code\n",
    "        #train_dataset = Subset (train_dataset, subset_indices) #remove for final code\n",
    "\n",
    "        train_size = int(0.8*len(train_dataset))\n",
    "        val_size = len(train_dataset)-train_size\n",
    "\n",
    "        train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
    "        return train_subset, val_subset\n",
    "    \n",
    "    def dataloader(self):  \n",
    "        train_subset, val_subset = self.dataset()\n",
    "        train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "        print (f'loading {self.clinic_id}')\n",
    "        return train_loader, val_loader"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "2c39fc4c",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T09:59:14.345475Z",
     "start_time": "2024-10-10T09:59:14.333990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def resnet18 (weights='DEFAULT'): #James\n",
    "    \n",
    "    resnet18 = models.resnet18(weights = weights).to(device)\n",
    "    for param in resnet18.parameters():\n",
    "        param.requires_grad = False\n",
    "    resnet18.fc = nn.Sequential (\n",
    "    nn.Linear(in_features = 512, out_features = 256, bias = True),\n",
    "    nn.Dropout(p = 0.5),\n",
    "    nn.Linear(in_features = 256, out_features = 1, bias = True),\n",
    "    nn.Sigmoid()\n",
    "    )\n",
    "    \n",
    "    for param in resnet18.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    resnet18.__class__.__name__ = 'ResNet18'\n",
    "    return resnet18"
   ],
   "id": "5975acf4cf8f3ba0",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T09:59:14.361359Z",
     "start_time": "2024-10-10T09:59:14.354545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, drop_out=0.2):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.drop_out = nn.Dropout(drop_out)\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.drop_out(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.downsample:\n",
    "            out += self.downsample(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.drop_out(out)\n",
    "        return out\n",
    "\n",
    "class CustomResNet18(nn.Module):\n",
    "    def __init__(self, drop_out=0.2):\n",
    "        super(CustomResNet18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Replace residual blocks with custom BasicBlock including dropout\n",
    "        self.layer1 = self._make_layer(BasicBlock, 64, 2, stride=1, drop_out=drop_out)\n",
    "        self.layer2 = self._make_layer(BasicBlock, 128, 2, stride=2, drop_out=drop_out)\n",
    "        self.layer3 = self._make_layer(BasicBlock, 256, 2, stride=2, drop_out=drop_out)\n",
    "        self.layer4 = self._make_layer(BasicBlock, 512, 2, stride=2, drop_out=drop_out)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, 1000)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride, drop_out):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride, drop_out))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "def custom_resnet18(weights='DEFAULT', drop_out=0.2):\n",
    "    custom_resnet18 = CustomResNet18(drop_out=0.2)\n",
    "    custom_resnet18.load_state_dict(models.resnet18(weights = weights).state_dict(), strict=False)\n",
    "\n",
    "# Then freeze parameters\n",
    "    for param in custom_resnet18.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    custom_resnet18.fc = nn.Sequential (\n",
    "    nn.Linear(in_features = 512, out_features =1),\n",
    "    nn.Sigmoid()\n",
    "    )\n",
    "    for param in custom_resnet18.fc.parameters():\n",
    "        param.requires_grad = True\n",
    "    return custom_resnet18\n",
    "\n"
   ],
   "id": "99c6da6d2b813c59",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T09:59:14.366742Z",
     "start_time": "2024-10-10T09:59:14.363950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def vgg16(weights = 'DEFAULT'): #David\n",
    "    vgg16 = models.vgg16(weights=weights).to(device)\n",
    "\n",
    "# Freeze the parameters of the base model\n",
    "    for param in vgg16.features.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "# Modify the classifier part for binary classification\n",
    "    vgg16.classifier[6] = nn.Sequential(\n",
    "        nn.Linear(vgg16.classifier[6].in_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(512, 1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "    \n",
    "    vgg16.__class__.__name__ = 'VGG16'\n",
    "    return vgg16\n",
    "\n",
    "    \n",
    "def vgg19 (weights='DEFAULT'):\n",
    "    vgg19 = models.vgg19 (weights=weights).to(device)\n",
    "    \n",
    "    for param in vgg19.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    vgg19.classifier = nn.Sequential (\n",
    "        nn.Linear(25088, 4096),        \n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(4096, 4096),       \n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.5),\n",
    "        nn.Linear(4096, 1),\n",
    "        nn.Sigmoid()          \n",
    "    )\n",
    "    for param in vgg19.classifier.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    vgg19.__class__.__name__ = 'VGG19'\n",
    "    return vgg19"
   ],
   "id": "beeb96054ccdef1d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "2bbb2e3b",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "id": "078c0697",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T09:59:14.377386Z",
     "start_time": "2024-10-10T09:59:14.373209Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Define the device - mps (Metal) for macOS GPU, otherwise default to 'cuda' or 'cpu'\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "def calculate_accuracy(outputs, labels, threshold=0.5):\n",
    "    preds = (outputs > threshold).float()\n",
    "    correct = (preds == labels).float().sum()\n",
    "    accuracy = correct / labels.size(0)\n",
    "    return accuracy\n",
    "\n",
    "def train_local_model(model, train_loader, val_loader, num_epochs=10):\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        total_train = 0\n",
    "        threshold = 0.5\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images).squeeze(1)\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_accuracy += calculate_accuracy(outputs, labels, threshold)\n",
    "            total_train += 1\n",
    "\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_accuracy = 0.0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images).squeeze(1)\n",
    "                loss = criterion(outputs, labels.float())\n",
    "                val_loss += loss.item()\n",
    "                val_accuracy += calculate_accuracy(outputs, labels, threshold)\n",
    "                total_val += 1\n",
    "\n",
    "        avg_val_loss = val_loss / total_val\n",
    "        avg_val_accuracy = val_accuracy / total_val\n",
    "        print (f\"Epoch {epoch + 1}/{num_epochs}:\\ntrain_loss: {running_loss / total_train}, train_accuracy: {running_accuracy / total_train}\\nValidation Loss: {avg_val_loss:.4f}, Validation Accuracy: {avg_val_accuracy:.4f}\")\n",
    "    \n",
    "    return model, avg_val_loss, avg_val_accuracy\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "9a0a219b",
   "metadata": {},
   "source": [
    "### Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "id": "abc5f8be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T09:59:14.383740Z",
     "start_time": "2024-10-10T09:59:14.381822Z"
    }
   },
   "source": [
    "def federated_averaging (client_weights):\n",
    "    avg_weights = client_weights[0].copy()\n",
    "    \n",
    "    for key in avg_weights.keys():\n",
    "        for key in avg_weights.keys():\n",
    "            for i in range (1, len (client_weights)):\n",
    "                avg_weights[key] += client_weights[i][key]\n",
    "                \n",
    "            avg_weights[key] = avg_weights[key] / len (client_weights)\n",
    "            \n",
    "    return avg_weights"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "67862eb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T09:59:14.390260Z",
     "start_time": "2024-10-10T09:59:14.387889Z"
    }
   },
   "source": [
    "def federated_learning (model, num_clients, num_rounds, train_loaders, val_loaders):\n",
    "    global_model = model('DEFAULT')\n",
    "    global_weights = global_model.state_dict()\n",
    "    \n",
    "    for round_num in range (num_rounds):\n",
    "        print (f'Round {round_num+1}')\n",
    "        \n",
    "        client_weights = []\n",
    "        \n",
    "        for client_id in range (num_clients):\n",
    "            print (f'client {client_id+1} training...')\n",
    "            \n",
    "            local_model = model(None)\n",
    "            local_model.load_state_dict (global_weights)\n",
    "            local_model.to(device)\n",
    "            \n",
    "            client_train_loader = train_loaders[client_id]\n",
    "            client_val_loader = val_loaders[client_id]\n",
    "            \n",
    "            output_model, _, _ = train_local_model (local_model, client_train_loader, client_val_loader)\n",
    "            client_updated_weights = output_model.state_dict()\n",
    "            \n",
    "            client_weights.append (client_updated_weights)\n",
    "            \n",
    "        global_weights = federated_averaging (client_weights)\n",
    "        \n",
    "        global_model.load_state_dict (global_weights)\n",
    "    return global_model"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "b8892c88",
   "metadata": {},
   "source": [
    "### Experimental Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f81222",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "id": "80b5b22f",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-10-10T09:59:14.463780Z",
     "start_time": "2024-10-10T09:59:14.395355Z"
    }
   },
   "source": [
    "#Setting up dataset for training the FL model\n",
    "num_clients = 4\n",
    "\n",
    "num_rounds = 3\n",
    "\n",
    "train_loader_0, val_loader_0 = LocalData('clinic_0').dataloader() #replace range() for testing, and remove when the code is ready for the final run.\n",
    "\n",
    "train_loader_1, val_loader_1 = LocalData('clinic_1').dataloader() #replace range() for testing, and remove when the code is ready for the final run.\n",
    "\n",
    "train_loader_2, val_loader_2 = LocalData('clinic_2').dataloader() #replace range() for testing, and remove when the code is ready for the final run.\n",
    "\n",
    "train_loader_3, val_loader_3 = LocalData('clinic_3').dataloader() #replace range() for testing, and remove when the code is ready for the final run.\n",
    "\n",
    "train_loaders = [train_loader_0, train_loader_1, train_loader_2, train_loader_3]\n",
    "val_loaders = [val_loader_0, val_loader_1, val_loader_2, val_loader_3]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading clinic_0\n",
      "loading clinic_1\n",
      "loading clinic_2\n",
      "loading clinic_3\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "3968d970",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T09:59:14.474627Z",
     "start_time": "2024-10-10T09:59:14.472439Z"
    }
   },
   "source": [
    "# Metrics\n",
    "def metrics (ground_truths, predictions):\n",
    "    accuracy = round(accuracy_score(ground_truths, predictions), 4)\n",
    "    precision = round(precision_score(ground_truths, predictions), 4)\n",
    "    recall = round(recall_score(ground_truths, predictions), 4)\n",
    "    f1 = round(f1_score(ground_truths, predictions), 4)\n",
    "    confusion_ma = confusion_matrix (ground_truths, predictions)\n",
    "    \n",
    "    print ('Accuracy score: ', accuracy)\n",
    "    print ('Precision score: ', precision)\n",
    "    print ('Recall score: ', recall)\n",
    "    print ('F1 score: ', f1)\n",
    "    print ('Confusion Matrix: \\n', confusion_ma)\n",
    "    return accuracy, precision, recall, f1\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "7b0f9ec0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T09:59:14.487674Z",
     "start_time": "2024-10-10T09:59:14.485334Z"
    }
   },
   "source": [
    "#Train client model on clinic4's train_loader\n",
    "#Make prediction on clinic4's val_loader\n",
    "def evaluation(client_model):\n",
    "    client_model.eval()\n",
    "    predictions = []\n",
    "    ground_truths = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader_clinic5:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output = client_model(images)\n",
    "            #output = output.round()\n",
    "            predictions.append (output.cpu())\n",
    "            ground_truths.append (labels.cpu())\n",
    "\n",
    "    predictions = np.concatenate (predictions).reshape(-1).astype ('int')\n",
    "    ground_truths = np.concatenate (ground_truths)\n",
    "    \n",
    "    return metrics (ground_truths, predictions)"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "028663bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T09:59:14.498798Z",
     "start_time": "2024-10-10T09:59:14.497339Z"
    }
   },
   "source": [
    "results = []\n",
    "client_models = [custom_resnet18, resnet18, vgg16, vgg19]"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "be6039a3",
   "metadata": {},
   "source": [
    "#### 1. Evaluation on the held-out clinic\n",
    "After several rounds of training, the global model's weights are now used as initiallized weights for a fresh client model. Then, we will use this model to make prediction on the eval dataset on the 5th clinic's data."
   ]
  },
  {
   "cell_type": "code",
   "id": "205a1bef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T09:59:14.521201Z",
     "start_time": "2024-10-10T09:59:14.503323Z"
    }
   },
   "source": [
    "#Setting up dataset for evaluation on clinic 5\n",
    "train_loader_clinic5, val_loader_clinic5 = LocalData ('clinic_4').dataloader()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading clinic_4\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "87970a3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-10T12:18:18.769583Z",
     "start_time": "2024-10-10T09:59:14.527441Z"
    }
   },
   "source": [
    "for client_model in client_models:\n",
    "    model_name = client_model().__class__.__name__\n",
    "    client_model = train_local_model (client_model('DEFAULT'), train_loader_clinic5, val_loader_clinic5)[0]\n",
    "    accuracy, precision, recall, f1 = evaluation (client_model)\n",
    "    results.append ([model_name, accuracy, precision, recall, f1])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:\n",
      "train_loss: 0.6689575953951364, train_accuracy: 0.6005431413650513\n",
      "Validation Loss: 0.6894, Validation Accuracy: 0.5765\n",
      "Epoch 2/10:\n",
      "train_loss: 0.661827098531059, train_accuracy: 0.6045064330101013\n",
      "Validation Loss: 0.6970, Validation Accuracy: 0.5150\n",
      "Epoch 3/10:\n",
      "train_loss: 0.655998528192315, train_accuracy: 0.6089033484458923\n",
      "Validation Loss: 0.6997, Validation Accuracy: 0.5019\n",
      "Epoch 4/10:\n",
      "train_loss: 0.6488239944358415, train_accuracy: 0.617552638053894\n",
      "Validation Loss: 0.6997, Validation Accuracy: 0.5051\n",
      "Epoch 5/10:\n",
      "train_loss: 0.6461738672437547, train_accuracy: 0.6128057837486267\n",
      "Validation Loss: 0.7117, Validation Accuracy: 0.4525\n",
      "Epoch 6/10:\n",
      "train_loss: 0.6430067810453947, train_accuracy: 0.6196293830871582\n",
      "Validation Loss: 0.7154, Validation Accuracy: 0.4326\n",
      "Epoch 7/10:\n",
      "train_loss: 0.6408312579121771, train_accuracy: 0.6237828731536865\n",
      "Validation Loss: 0.7281, Validation Accuracy: 0.4164\n",
      "Epoch 8/10:\n",
      "train_loss: 0.6364408348557316, train_accuracy: 0.6259508728981018\n",
      "Validation Loss: 0.7170, Validation Accuracy: 0.4413\n",
      "Epoch 9/10:\n",
      "train_loss: 0.6358858986368662, train_accuracy: 0.6233872771263123\n",
      "Validation Loss: 0.7180, Validation Accuracy: 0.4461\n",
      "Epoch 10/10:\n",
      "train_loss: 0.6328452917971189, train_accuracy: 0.6259052157402039\n",
      "Validation Loss: 0.7112, Validation Accuracy: 0.4671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidbain/Library/Caches/pypoetry/virtualenvs/ilab-YBgqLwdb-py3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.6149\n",
      "Precision score:  0.0\n",
      "Recall score:  0.0\n",
      "F1 score:  0.0\n",
      "Confusion Matrix: \n",
      " [[1552    0]\n",
      " [ 972    0]]\n",
      "Epoch 1/10:\n",
      "train_loss: 0.45087515482608276, train_accuracy: 0.7904089689254761\n",
      "Validation Loss: 0.3895, Validation Accuracy: 0.8284\n",
      "Epoch 2/10:\n",
      "train_loss: 0.34992549766468095, train_accuracy: 0.8478654026985168\n",
      "Validation Loss: 0.3488, Validation Accuracy: 0.8463\n",
      "Epoch 3/10:\n",
      "train_loss: 0.33216391965935504, train_accuracy: 0.8565679788589478\n",
      "Validation Loss: 0.3155, Validation Accuracy: 0.8626\n",
      "Epoch 4/10:\n",
      "train_loss: 0.32270526895417445, train_accuracy: 0.8629883527755737\n",
      "Validation Loss: 0.3116, Validation Accuracy: 0.8629\n",
      "Epoch 5/10:\n",
      "train_loss: 0.3110676409700249, train_accuracy: 0.868579626083374\n",
      "Validation Loss: 0.3115, Validation Accuracy: 0.8638\n",
      "Epoch 6/10:\n",
      "train_loss: 0.30638605360931986, train_accuracy: 0.8700706362724304\n",
      "Validation Loss: 0.3187, Validation Accuracy: 0.8630\n",
      "Epoch 7/10:\n",
      "train_loss: 0.3010253634869675, train_accuracy: 0.8752509951591492\n",
      "Validation Loss: 0.3015, Validation Accuracy: 0.8673\n",
      "Epoch 8/10:\n",
      "train_loss: 0.2995991924235338, train_accuracy: 0.8754487633705139\n",
      "Validation Loss: 0.3135, Validation Accuracy: 0.8621\n",
      "Epoch 9/10:\n",
      "train_loss: 0.3014898086320373, train_accuracy: 0.8672940135002136\n",
      "Validation Loss: 0.3001, Validation Accuracy: 0.8657\n",
      "Epoch 10/10:\n",
      "train_loss: 0.30106944956262655, train_accuracy: 0.8717973828315735\n",
      "Validation Loss: 0.3135, Validation Accuracy: 0.8652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidbain/Library/Caches/pypoetry/virtualenvs/ilab-YBgqLwdb-py3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.6149\n",
      "Precision score:  0.0\n",
      "Recall score:  0.0\n",
      "F1 score:  0.0\n",
      "Confusion Matrix: \n",
      " [[1552    0]\n",
      " [ 972    0]]\n",
      "Epoch 1/10:\n",
      "train_loss: 0.38672950227237957, train_accuracy: 0.8210123777389526\n",
      "Validation Loss: 0.3326, Validation Accuracy: 0.8591\n",
      "Epoch 2/10:\n",
      "train_loss: 0.2532092814769926, train_accuracy: 0.8944894075393677\n",
      "Validation Loss: 0.3857, Validation Accuracy: 0.8445\n",
      "Epoch 3/10:\n",
      "train_loss: 0.1654463526380213, train_accuracy: 0.929641842842102\n",
      "Validation Loss: 0.4365, Validation Accuracy: 0.8571\n",
      "Epoch 4/10:\n",
      "train_loss: 0.09738125811077512, train_accuracy: 0.9623752236366272\n",
      "Validation Loss: 0.4676, Validation Accuracy: 0.8631\n",
      "Epoch 5/10:\n",
      "train_loss: 0.06704093699853372, train_accuracy: 0.9761669039726257\n",
      "Validation Loss: 0.6019, Validation Accuracy: 0.8564\n",
      "Epoch 6/10:\n",
      "train_loss: 0.05350572473179443, train_accuracy: 0.9792326092720032\n",
      "Validation Loss: 0.7607, Validation Accuracy: 0.8536\n",
      "Epoch 7/10:\n",
      "train_loss: 0.04390847612808965, train_accuracy: 0.9836827516555786\n",
      "Validation Loss: 0.6248, Validation Accuracy: 0.8583\n",
      "Epoch 8/10:\n",
      "train_loss: 0.02849447222661759, train_accuracy: 0.9885284900665283\n",
      "Validation Loss: 0.7948, Validation Accuracy: 0.8591\n",
      "Epoch 9/10:\n",
      "train_loss: 0.02529417204498748, train_accuracy: 0.9900650978088379\n",
      "Validation Loss: 0.9248, Validation Accuracy: 0.8615\n",
      "Epoch 10/10:\n",
      "train_loss: 0.021865031998784246, train_accuracy: 0.9922863841056824\n",
      "Validation Loss: 0.9491, Validation Accuracy: 0.8556\n",
      "Accuracy score:  0.6846\n",
      "Precision score:  0.9944\n",
      "Recall score:  0.1821\n",
      "F1 score:  0.3078\n",
      "Confusion Matrix: \n",
      " [[1551    1]\n",
      " [ 795  177]]\n",
      "Epoch 1/10:\n",
      "train_loss: 0.3846185200765163, train_accuracy: 0.8288704752922058\n",
      "Validation Loss: 0.3080, Validation Accuracy: 0.8630\n",
      "Epoch 2/10:\n",
      "train_loss: 0.24994957667504308, train_accuracy: 0.897798478603363\n",
      "Validation Loss: 0.3183, Validation Accuracy: 0.8686\n",
      "Epoch 3/10:\n",
      "train_loss: 0.17247392344465362, train_accuracy: 0.9310719966888428\n",
      "Validation Loss: 0.3375, Validation Accuracy: 0.8710\n",
      "Epoch 4/10:\n",
      "train_loss: 0.1242220899078382, train_accuracy: 0.9509493708610535\n",
      "Validation Loss: 0.4042, Validation Accuracy: 0.8726\n",
      "Epoch 5/10:\n",
      "train_loss: 0.07566730699080479, train_accuracy: 0.9695943593978882\n",
      "Validation Loss: 0.6874, Validation Accuracy: 0.8328\n",
      "Epoch 6/10:\n",
      "train_loss: 0.06334655393501508, train_accuracy: 0.975969135761261\n",
      "Validation Loss: 0.5176, Validation Accuracy: 0.8683\n",
      "Epoch 7/10:\n",
      "train_loss: 0.04374697837883554, train_accuracy: 0.9838805198669434\n",
      "Validation Loss: 0.6641, Validation Accuracy: 0.8531\n",
      "Epoch 8/10:\n",
      "train_loss: 0.040108937158786634, train_accuracy: 0.9846716523170471\n",
      "Validation Loss: 0.9069, Validation Accuracy: 0.8456\n",
      "Epoch 9/10:\n",
      "train_loss: 0.03326244070438729, train_accuracy: 0.9872428774833679\n",
      "Validation Loss: 0.7137, Validation Accuracy: 0.8737\n",
      "Epoch 10/10:\n",
      "train_loss: 0.01448875255250008, train_accuracy: 0.9947587251663208\n",
      "Validation Loss: 0.8545, Validation Accuracy: 0.8626\n",
      "Accuracy score:  0.708\n",
      "Precision score:  0.9876\n",
      "Recall score:  0.2449\n",
      "F1 score:  0.3924\n",
      "Confusion Matrix: \n",
      " [[1549    3]\n",
      " [ 734  238]]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "1dadd976",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-10-10T12:18:18.808804Z"
    }
   },
   "source": [
    "for client_model in client_models:\n",
    "    global_model = federated_learning (client_model, num_clients, 2, train_loaders, val_loaders) #change num_rounds according to your GPU, which mine doesn't have one :<.\n",
    "    model = train_local_model (global_model, train_loader_clinic5, val_loader_clinic5)[0]\n",
    "    accuracy, precision, recall, f1 = evaluation (model)\n",
    "    model_name = f'FedAVG {client_model().__class__.__name__}'\n",
    "    results.append ([model_name, accuracy, precision, recall, f1])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "client 1 training...\n",
      "Epoch 1/10:\n",
      "train_loss: 0.6521381333516478, train_accuracy: 0.6353521943092346\n",
      "Validation Loss: 0.6375, Validation Accuracy: 0.6345\n",
      "Epoch 2/10:\n",
      "train_loss: 0.6427800775312418, train_accuracy: 0.6351586580276489\n",
      "Validation Loss: 0.6425, Validation Accuracy: 0.6245\n",
      "Epoch 3/10:\n",
      "train_loss: 0.6398949375831675, train_accuracy: 0.6352553963661194\n",
      "Validation Loss: 0.6536, Validation Accuracy: 0.6109\n",
      "Epoch 4/10:\n",
      "train_loss: 0.6360555457256896, train_accuracy: 0.6353521943092346\n",
      "Validation Loss: 0.6761, Validation Accuracy: 0.5693\n",
      "Epoch 5/10:\n",
      "train_loss: 0.6333574067697436, train_accuracy: 0.6369001269340515\n",
      "Validation Loss: 0.6788, Validation Accuracy: 0.5636\n",
      "Epoch 6/10:\n",
      "train_loss: 0.6297193536817474, train_accuracy: 0.6372871398925781\n",
      "Validation Loss: 0.6722, Validation Accuracy: 0.5857\n",
      "Epoch 7/10:\n",
      "train_loss: 0.6290167071870975, train_accuracy: 0.6407701373100281\n",
      "Validation Loss: 0.6827, Validation Accuracy: 0.5511\n",
      "Epoch 8/10:\n",
      "train_loss: 0.623882659540826, train_accuracy: 0.6404798626899719\n",
      "Validation Loss: 0.6864, Validation Accuracy: 0.5415\n",
      "Epoch 9/10:\n",
      "train_loss: 0.6215498803569806, train_accuracy: 0.6399961113929749\n",
      "Validation Loss: 0.6805, Validation Accuracy: 0.5537\n",
      "Epoch 10/10:\n",
      "train_loss: 0.6205528157967901, train_accuracy: 0.6415441036224365\n",
      "Validation Loss: 0.6864, Validation Accuracy: 0.5397\n",
      "client 2 training...\n",
      "Epoch 1/10:\n",
      "train_loss: 0.6574828427250987, train_accuracy: 0.6232903003692627\n",
      "Validation Loss: 0.6519, Validation Accuracy: 0.6078\n",
      "Epoch 2/10:\n",
      "train_loss: 0.6518124753218654, train_accuracy: 0.6228153705596924\n",
      "Validation Loss: 0.6521, Validation Accuracy: 0.6076\n",
      "Epoch 3/10:\n",
      "train_loss: 0.644962636714286, train_accuracy: 0.6238601803779602\n",
      "Validation Loss: 0.6486, Validation Accuracy: 0.6176\n",
      "Epoch 4/10:\n",
      "train_loss: 0.6422053050125262, train_accuracy: 0.6252849698066711\n",
      "Validation Loss: 0.6603, Validation Accuracy: 0.5888\n",
      "Epoch 5/10:\n",
      "train_loss: 0.6403933442834663, train_accuracy: 0.6259498596191406\n",
      "Validation Loss: 0.6636, Validation Accuracy: 0.5824\n",
      "Epoch 6/10:\n",
      "train_loss: 0.6367459563498802, train_accuracy: 0.626329779624939\n",
      "Validation Loss: 0.6788, Validation Accuracy: 0.5666\n",
      "Epoch 7/10:\n",
      "train_loss: 0.633214424446361, train_accuracy: 0.6294642686843872\n",
      "Validation Loss: 0.6780, Validation Accuracy: 0.5656\n",
      "Epoch 8/10:\n",
      "train_loss: 0.6308779024425611, train_accuracy: 0.6299391984939575\n",
      "Validation Loss: 0.6653, Validation Accuracy: 0.5912\n",
      "Epoch 9/10:\n",
      "train_loss: 0.62866799827767, train_accuracy: 0.6334536671638489\n",
      "Validation Loss: 0.6698, Validation Accuracy: 0.5830\n",
      "Epoch 10/10:\n",
      "train_loss: 0.6279663654627409, train_accuracy: 0.6354483366012573\n",
      "Validation Loss: 0.6843, Validation Accuracy: 0.5555\n",
      "client 3 training...\n",
      "Epoch 1/10:\n",
      "train_loss: 0.6588984329287404, train_accuracy: 0.621960461139679\n",
      "Validation Loss: 0.6457, Validation Accuracy: 0.6155\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fee2e0a0",
   "metadata": {},
   "source": [
    "df_eval = pd.DataFrame (columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1'],\n",
    "                       data = results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9dce2018",
   "metadata": {},
   "source": [
    "df_eval"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "14b2878b",
   "metadata": {},
   "source": "# client_models[0]",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2e900e5b",
   "metadata": {},
   "source": [
    "#### 2. Evaluation on each client's validation data"
   ]
  },
  {
   "cell_type": "code",
   "id": "59c154ba",
   "metadata": {},
   "source": [
    "results_2 = []"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "717b5123",
   "metadata": {},
   "source": [
    "\n",
    "for client_model in client_models:\n",
    "    model_name = client_model().__class__.__name__\n",
    "    for i in range (4):\n",
    "        local_model = train_local_model (client_model('DEFAULT'), train_loaders[i], val_loaders[i])[0]\n",
    "        accuracy, precision, recall, f1 = evaluation (local_model)\n",
    "        results_2.append ([model_name, f'Clinic_{i}', accuracy, precision, recall, f1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9dc8208d",
   "metadata": {},
   "source": [
    "for client_model in client_models:\n",
    "    global_model = federated_learning (client_model, num_clients, 2, train_loaders, val_loaders) #change num_rounds according to your GPU, which mine doesn't have one :<.\n",
    "    for i in range (4):\n",
    "        model = train_local_model (global_model, train_loaders[i], val_loaders[i])[0]\n",
    "        accuracy, precision, recall, f1 = evaluation (model)\n",
    "        model_name = f'FedAVG {client_model().__class__.__name__}'\n",
    "        results_2.append ([model_name, f'Clinic_{i}', accuracy, precision, recall, f1])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6e48e6fa",
   "metadata": {},
   "source": [
    "df_eval_2 = pd.DataFrame (columns = ['Model', 'Clinic', 'Accuracy', 'Precision', 'Recall', 'F1'],\n",
    "                         data = results_2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "resnet18()",
   "id": "b60c3510fbeb6a19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "a = [1, 2, 3]\n",
    "b = [4, 5, 6]\n",
    "\n",
    "for c, d in zip (a, b):\n",
    "    print (c, d)"
   ],
   "id": "e26f5d75d91590c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "94e4cfb6",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
