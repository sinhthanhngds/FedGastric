{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6d3d8a",
   "metadata": {},
   "source": [
    "# iLab Project: Group 7-2\n",
    "\n",
    "#### Federated Learning for Gastric Cancer Detection - gashissdb\n",
    "\n",
    "David Bain 91082596"
   ]
  },
  {
   "cell_type": "code",
   "id": "29b2f22d",
   "metadata": {},
   "source": [
    "import io\n",
    "import os.path\n",
    "import random\n",
    "\n",
    "import logging\n",
    "\n",
    "import boto3\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "from typing import Optional\n",
    "from botocore.exceptions import BotoCoreError, ClientError\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as v2\n",
    "import torch\n",
    "from torch.optim import lr_scheduler\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "821f3026",
   "metadata": {},
   "source": [
    "Read in the aws keys to access s3"
   ]
  },
  {
   "cell_type": "code",
   "id": "a28d50a8",
   "metadata": {},
   "source": [
    "key_df = pd.read_csv('../team_user_accessKeys.csv', sep=',')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a43a21fe",
   "metadata": {},
   "source": [
    "Access the s3 bucket with the images and create an s3_client object"
   ]
  },
  {
   "cell_type": "code",
   "id": "bc08410f",
   "metadata": {},
   "source": [
    "# Replace the following values with your access key details\n",
    "AWS_ACCESS_KEY_ID = key_df.iloc[0,0]\n",
    "AWS_SECRET_ACCESS_KEY = key_df.iloc[0,1]\n",
    "region_name = 'ap-southeast-2'\n",
    "\n",
    "# Create an S3 client using the provided access keys\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    region_name=region_name\n",
    ")\n",
    "\n",
    "# List all the buckets\n",
    "buckets = s3_client.list_buckets()\n",
    "for bucket in buckets['Buckets']:\n",
    "    print(bucket['Name'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Read data files from local disk (not AWS)",
   "id": "da18e66d48d01bb3"
  },
  {
   "cell_type": "code",
   "id": "12e626f3",
   "metadata": {},
   "source": [
    "clinic1 = 'clinic1-80'\n",
    "clinic2 = 'clinic2-80'\n",
    "clinic3 = 'clinic3-80'\n",
    "clinic4 = 'clinic4-80'\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b5e8c5f8",
   "metadata": {},
   "source": [
    "[1] Load data from clinic 0"
   ]
  },
  {
   "cell_type": "code",
   "id": "cadb1abe",
   "metadata": {},
   "source": [
    "def list_s3_bucket_images(s3_client: 'boto3.client', bucket_n: str, prefix: str = '') -> List[str]:\n",
    "    \n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    pages = paginator.paginate(Bucket=bucket_n, Prefix=prefix)\n",
    "\n",
    "    image_keys = []\n",
    "    for page in pages:\n",
    "        if 'Contents' in page:\n",
    "            for obj in page['Contents']:\n",
    "                if obj['Key'].lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    image_keys.append(obj['Key'])\n",
    "    return image_keys"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "bucket_image_list = list_s3_bucket_images(s3_client, clinic1, '')",
   "id": "cfd0bd31d4b46ab3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f2cc3b36",
   "metadata": {},
   "source": [
    "[2] Read an image from s3"
   ]
  },
  {
   "cell_type": "code",
   "id": "c8f3603f",
   "metadata": {},
   "source": [
    "def read_image_from_s3(s3_client: 'boto3.client', bucket_n: str, image_key: str) -> Optional[Image]:\n",
    "\n",
    "    try:\n",
    "        obj = s3_client.get_object(Bucket=bucket_n, Key=image_key)\n",
    "        img_data = obj['Body'].read()\n",
    "\n",
    "        # Convert bytes data to a file-like object\n",
    "        img_bytes = io.BytesIO(img_data)\n",
    "\n",
    "        # Use PIL to open the image\n",
    "        image = Image.open(img_bytes).convert('RGB')\n",
    "\n",
    "        return image\n",
    "\n",
    "    # Handle S3 related errors\n",
    "    except (BotoCoreError, ClientError) as e:\n",
    "        print(f\"Error accessing S3 for image {image_key}: {e}\")\n",
    "\n",
    "    # Handle decoding errors\n",
    "    except (ValueError, IOError) as e:\n",
    "        print(f\"Error decoding image {image_key}: {e}\")\n",
    "\n",
    "    return None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a8a51ea4",
   "metadata": {},
   "source": [
    "\n",
    "[3] Process the images from disk without transformation.\n",
    "\n",
    "Resizing depends on the desired neural network architecture which have a min of 32 x 32"
   ]
  },
  {
   "cell_type": "code",
   "id": "3af4a2de",
   "metadata": {},
   "source": [
    "# Read in all images from disk and store in an array. Preprocessing is done later\n",
    "\n",
    "def load_images(s3_client: 'boto3.client', bucket_n: str, prefixes: List[str]) -> List[Tuple[int, Image]]:\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for prefix in prefixes:\n",
    "        print(f\"Processing images for prefix: {prefix}\")\n",
    "        image_keys = list_s3_bucket_images(s3_client, bucket_n, prefix)\n",
    "        \n",
    "        for image_key in image_keys:\n",
    "            try:\n",
    "                image = read_image_from_s3(s3_client, bucket_n, image_key)\n",
    "                if image is not None:\n",
    "                    bin_image_key = image_key.split('/')[1] \n",
    "                    images.append((bin_image_key, image))\n",
    "                     \n",
    "                else:\n",
    "                    print(f\"Failed to load image {image_key}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {image_key}: {e}\")\n",
    "    return images\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b5120254",
   "metadata": {},
   "source": [
    "Define the s3 'prefix' which relates to the directory structure or clinic: 0, 1, 2, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0328d023",
   "metadata": {},
   "source": [
    "Define image preprocessiing"
   ]
  },
  {
   "cell_type": "code",
   "id": "d835e448",
   "metadata": {},
   "source": [
    "def preprocess_images(s3_client: 'boto3.client', bucket_name: str, prefixes: List[str]) -> List[Tuple[int, Image]]:\n",
    "    \n",
    "    # List all image keys\n",
    "    for prefix in prefixes:\n",
    "        print(f\"Listing images for prefixes: {prefix}\")\n",
    "        image_keys = list_s3_bucket_images(s3_client, bucket_name, prefix)\n",
    "        print(f\"Total number of images: {len(image_keys)}\\n\")\n",
    "    \n",
    "    # Process images in memory\n",
    "    loaded_images = load_images(s3_client, bucket_name, prefixes)\n",
    "    print(f\"Total number of loaded images: {len(loaded_images)}\")\n",
    "    \n",
    "    return loaded_images\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "91e805d4",
   "metadata": {},
   "source": [
    "clinic_1_images = preprocess_images(s3_client, clinic1, ['abnormal', 'normal'])\n",
    "#clinic_2_test_images = preprocess_images(s3_client, bucket_name, clinic_0_test_data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a4a770a0",
   "metadata": {},
   "source": [
    "# Print first and last image and classification\n",
    "print(clinic_1_images[0])\n",
    "print(clinic_1_images[-1])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Read from disk",
   "id": "2c4701aa9c327c88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "image_dir = os.path.expanduser('~/Development/GasHisSDB/80/clinic1')\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ],
   "id": "7fd299def6055325",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def read_image_with_label(file_path, label):\n",
    "    try:\n",
    "        with Image.open(file_path) as image:  # Ensure proper file handling\n",
    "            image.load()  # Load image data into memory\n",
    "            return image, label\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading {file_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def process_directory(directory_path, label, batch_size=100):\n",
    "    image_files = [os.path.join(directory_path, f) for f in os.listdir(directory_path)\n",
    "                   if f.endswith('.jpg') or f.endswith('.png')]\n",
    "\n",
    "    images_with_labels = []\n",
    "\n",
    "    for i, file_path in enumerate(image_files):\n",
    "        img, lbl = read_image_with_label(file_path, label)\n",
    "        if img is not None:\n",
    "            images_with_labels.append((img, lbl))\n",
    "\n",
    "        # Process in batches to avoid memory issues\n",
    "        if (i + 1) % batch_size == 0:\n",
    "            #logging.info(f\"Processed {i + 1} / {len(image_files)} images from {directory_path}\")\n",
    "            yield images_with_labels\n",
    "            images_with_labels = []\n",
    "\n",
    "    # Yield remaining images\n",
    "    if images_with_labels:\n",
    "        yield images_with_labels\n",
    "\n",
    "\n",
    "def read_images_for_classification(base_directory, batch_size=100):\n",
    "    abnormal_dir = os.path.join(base_directory, 'abnormal')\n",
    "    normal_dir = os.path.join(base_directory, 'normal')\n",
    "\n",
    "    abnormal_images_batches = process_directory(abnormal_dir, label=1, batch_size=batch_size)\n",
    "    normal_images_batches = process_directory(normal_dir, label=0, batch_size=batch_size)\n",
    "\n",
    "    for abnormal_batch in abnormal_images_batches:\n",
    "        for img, lbl in abnormal_batch:\n",
    "            yield img, lbl\n",
    "\n",
    "    for normal_batch in normal_images_batches:\n",
    "        for img, lbl in normal_batch:\n",
    "            yield img, lbl\n"
   ],
   "id": "8f38c83f928088cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "images = []\n",
    "\n",
    "for img, lbl in read_images_for_classification(image_dir):\n",
    "    # Process each image and label here\n",
    "    images.append((lbl, img))\n"
   ],
   "id": "a8045435684e5267",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5190060d",
   "metadata": {},
   "source": [
    "Define function to print a handful of original images"
   ]
  },
  {
   "cell_type": "code",
   "id": "4aa1ea58",
   "metadata": {},
   "source": [
    "def plot_images(images: List[Image], titles: List[str], rows: int, cols: int) -> None:\n",
    "    \"\"\"\n",
    "    Plot a list of images with their titles using matplotlib.\n",
    "\n",
    "    :param images: List of images to plot\n",
    "    :param titles: List of titles corresponding to the images\n",
    "    :param rows: Number of rows in the plot\n",
    "    :param cols: Number of columns in the plot\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(12, 8))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for img, ax, title in zip(images, axes, titles):\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1dd9b23a",
   "metadata": {},
   "source": [
    "Read images and plot"
   ]
  },
  {
   "cell_type": "code",
   "id": "58359bd5",
   "metadata": {},
   "source": [
    "# Access a random sample of 5 images\n",
    "clinic_1_images = images\n",
    "\n",
    "if clinic_1_images:\n",
    "    random_sample = random.sample(clinic_1_images, min(10, len(clinic_1_images)))\n",
    "    sampled_images = [img_data for label, img_data in random_sample]\n",
    "    sampled_titles = [label for label, img_data in random_sample]\n",
    "\n",
    "    # Display images using matplotlib\n",
    "    num_images = len(sampled_images)\n",
    "    plot_images(sampled_images, sampled_titles, 2, int(np.ceil(num_images / 2)))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "114f8fdc",
   "metadata": {},
   "source": [
    "sampled_images"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ba38e3c7",
   "metadata": {},
   "source": [
    "Resolution of images are small in size and vary. This will limit the transfer learning models used "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72462516",
   "metadata": {},
   "source": [
    "Image Transformation\n",
    "1) Transform to tensor\n",
    "2) Normalise\n",
    "3) Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "id": "f25d3386",
   "metadata": {},
   "source": [
    "def preprocess_images(images: List[Tuple[int, Image]], size: List[int]) -> List[Tuple[int, Image]]:\n",
    "    \n",
    "    transformed_images = []\n",
    "    transform = v2.Compose([\n",
    "        v2.Resize(size, interpolation=Image.BICUBIC),\n",
    "        #v2.RandomRotation(40),\n",
    "        #v2.RandomHorizontalFlip(),\n",
    "        #v2.RandomVerticalFlip(),\n",
    "        v2.ToTensor(),\n",
    "        v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    for label, image in images:\n",
    "        transformed_images.append((label, transform(image)))\n",
    "    \n",
    "    return transformed_images\n",
    "    \n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "128e04f0",
   "metadata": {},
   "source": [
    "#target_size = [32, 32]\n",
    "target_size = [224, 224]\n",
    "\n",
    "clinic_1_ds = preprocess_images(clinic_1_images, target_size)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "clinic_1_ds_trunc = []\n",
    "for label, image in clinic_1_ds:\n",
    "    trunc_label = label.split('-')[0]\n",
    "    if trunc_label == 'Abnormal':\n",
    "        trunc_label = 1\n",
    "    else: \n",
    "        trunc_label = 0\n",
    "    clinic_1_ds_trunc.append((trunc_label, image))"
   ],
   "id": "205aa7598e637877",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(clinic_1_ds[0], clinic_1_ds[-1])",
   "id": "b66d539123a0b37c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_ds_c1, test_ds_c1 = random_split(clinic_1_ds, [int(len(clinic_1_ds) * 0.8), len(clinic_1_ds) - int(len(clinic_1_ds) * 0.8)])",
   "id": "469703516ecdc64e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3a41ca62",
   "metadata": {},
   "source": [
    "Create a custom Dataset for the images"
   ]
  },
  {
   "cell_type": "code",
   "id": "b360c54f",
   "metadata": {},
   "source": [
    "# Create a custom Dataset for the images\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve the item (label, image) from the list\n",
    "        label, image = self.data[idx]\n",
    "        # Return the image and label\n",
    "        return image, label"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "87bca641",
   "metadata": {},
   "source": [
    "Create an instance of the custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "2676fc42",
   "metadata": {},
   "source": [
    "# Create custom datasets\n",
    "\n",
    "train_dataset = CustomDataset(train_ds_c1)\n",
    "test_dataset = CustomDataset(test_ds_c1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "adfe5899",
   "metadata": {},
   "source": [
    "Create a DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "id": "4a9514eb",
   "metadata": {},
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "38d63808",
   "metadata": {},
   "source": [
    "Make sure this runs on Mac GPU"
   ]
  },
  {
   "cell_type": "code",
   "id": "403c3e9b",
   "metadata": {},
   "source": [
    "# Check if MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4c1eb4e0",
   "metadata": {},
   "source": [
    "Define the first Torchvision model: VGG16"
   ]
  },
  {
   "cell_type": "code",
   "id": "b687e928",
   "metadata": {},
   "source": [
    "# Load pre-trained VGG16 model\n",
    "model = models.vgg16(weights='IMAGENET1K_V1')\n",
    "\n",
    "# Freeze the parameters of the base model\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Modify the classifier part for binary classification\n",
    "model.classifier[6] = nn.Sequential(\n",
    "    nn.Linear(model.classifier[6].in_features, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(512, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e4945565",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "id": "ff6ccc97",
   "metadata": {},
   "source": [
    "# Loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Optimiser\n",
    "optimiser = optim.SGD(model.classifier.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        optimiser.zero_grad()  # Zero the parameter gradients\n",
    "\n",
    "        # Removed the torch.no_grad() part from the training loop\n",
    "        features = model.features(inputs)\n",
    "        features_cpu = features.to('cpu')  # Move to CPU for AdaptiveAvgPool2d\n",
    "        pooled_cpu = torch.nn.functional.adaptive_avg_pool2d(features_cpu, model.avgpool.output_size)\n",
    "        pooled = pooled_cpu.to(device)  # Move back to MPS device\n",
    "        outputs = model.classifier(torch.flatten(pooled, 1))\n",
    "\n",
    "        outputs = outputs.view(-1)  # Flatten output to match labels shape        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.type(torch.FloatTensor).to(device)\n",
    "\n",
    "            features = model.features(inputs)\n",
    "            features_cpu = features.to('cpu')  # Move to CPU for AdaptiveAvgPool2d\n",
    "            pooled_cpu = torch.nn.functional.adaptive_avg_pool2d(features_cpu, model.avgpool.output_size)\n",
    "            pooled = pooled_cpu.to(device)  # Move back to MPS device\n",
    "            outputs = model.classifier(torch.flatten(pooled, 1))\n",
    "\n",
    "            outputs = outputs.view(-1)  # Flatten output to match labels shape\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}')\n",
    "\n",
    "# Save the trained model\n",
    "#torch.save(model.state_dict(), 'vgg16_cancer_detection.pth')\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4508cbf9",
   "metadata": {},
   "source": [
    "Test Classification results"
   ]
  },
  {
   "cell_type": "code",
   "id": "ad071d26",
   "metadata": {},
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    incorrect_predictions = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device).float(), labels.to(device).float().unsqueeze(1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = model.features(images)\n",
    "            # Move tensor to CPU for the pooling operation\n",
    "            features_cpu = features.to('cpu')\n",
    "            pooled_cpu = torch.nn.functional.adaptive_avg_pool2d(features_cpu, model.avgpool.output_size)\n",
    "            pooled = pooled_cpu.to(device)  # Move back to device\n",
    "            outputs = model.classifier(torch.flatten(pooled, 1))\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predicted = torch.sigmoid(outputs).round()\n",
    "            total += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "            incorrect_predictions += (predicted != labels).sum().item()\n",
    "\n",
    "    accuracy = correct_predictions / total\n",
    "    print(f\"Correct predictions: {correct_predictions}\")\n",
    "    print(f\"Incorrect predictions: {incorrect_predictions}\")\n",
    "    return total_loss / len(test_loader), accuracy\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8073fb29",
   "metadata": {},
   "source": [
    "# Test the model for accuracy and loss\n",
    "test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
