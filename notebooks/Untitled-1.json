
Viewing Version 9: Save & Run All â€¢ October 19, 2024 at 12:26 PM

Go to Viewer
{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "!git clone https://sinhthanhngds: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@github.com/data-davey/ilab-07-2.git",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:19:19.429418Z",
          "iopub.execute_input": "2024-10-19T01:19:19.430345Z",
          "iopub.status.idle": "2024-10-19T01:19:20.479931Z",
          "shell.execute_reply.started": "2024-10-19T01:19:19.430285Z",
          "shell.execute_reply": "2024-10-19T01:19:20.478798Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "!git --version",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:19:20.482364Z",
          "iopub.execute_input": "2024-10-19T01:19:20.482774Z",
          "iopub.status.idle": "2024-10-19T01:19:21.560805Z",
          "shell.execute_reply.started": "2024-10-19T01:19:20.482736Z",
          "shell.execute_reply": "2024-10-19T01:19:21.559512Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:19:21.562517Z",
          "iopub.execute_input": "2024-10-19T01:19:21.562874Z",
          "iopub.status.idle": "2024-10-19T01:19:21.568101Z",
          "shell.execute_reply.started": "2024-10-19T01:19:21.562839Z",
          "shell.execute_reply": "2024-10-19T01:19:21.567108Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from PIL import Image\nimport numpy as np\nimport io\nimport os ",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:19:21.571125Z",
          "iopub.execute_input": "2024-10-19T01:19:21.571677Z",
          "iopub.status.idle": "2024-10-19T01:19:21.581162Z",
          "shell.execute_reply.started": "2024-10-19T01:19:21.571640Z",
          "shell.execute_reply": "2024-10-19T01:19:21.580437Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#!pip -q install torchsummary",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:19:21.582337Z",
          "iopub.execute_input": "2024-10-19T01:19:21.582618Z",
          "iopub.status.idle": "2024-10-19T01:19:21.593730Z",
          "shell.execute_reply.started": "2024-10-19T01:19:21.582588Z",
          "shell.execute_reply": "2024-10-19T01:19:21.592778Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset, random_split, Subset, ConcatDataset\nfrom torchvision.transforms import transforms\nimport numpy as np\nfrom torchvision import models, datasets\n#from torchsummary import summary",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:19:21.594960Z",
          "iopub.execute_input": "2024-10-19T01:19:21.595380Z",
          "iopub.status.idle": "2024-10-19T01:19:21.604668Z",
          "shell.execute_reply.started": "2024-10-19T01:19:21.595343Z",
          "shell.execute_reply": "2024-10-19T01:19:21.603891Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nimport torch",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:19:21.606001Z",
          "iopub.execute_input": "2024-10-19T01:19:21.606446Z",
          "iopub.status.idle": "2024-10-19T01:19:21.622093Z",
          "shell.execute_reply.started": "2024-10-19T01:19:21.606396Z",
          "shell.execute_reply": "2024-10-19T01:19:21.621165Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import roc_auc_score",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:19:21.623229Z",
          "iopub.execute_input": "2024-10-19T01:19:21.623490Z",
          "iopub.status.idle": "2024-10-19T01:19:21.634203Z",
          "shell.execute_reply.started": "2024-10-19T01:19:21.623461Z",
          "shell.execute_reply": "2024-10-19T01:19:21.633438Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import random\ndef set_random_seed(seed_value=30):\n    torch.manual_seed(seed_value)           # For CPU\n    torch.cuda.manual_seed(seed_value)      # For GPU\n    torch.cuda.manual_seed_all(seed_value)  # If using multi-GPU\n    np.random.seed(seed_value)              # For NumPy\n    random.seed(seed_value)                 # For Python's built-in random module\n\n    # Ensure deterministic behavior if possible\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False  # To avoid non-deterministic algorithms\n\n# Set random seed\nset_random_seed(1)\n",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:19:21.635411Z",
          "iopub.execute_input": "2024-10-19T01:19:21.635713Z",
          "iopub.status.idle": "2024-10-19T01:19:21.646974Z",
          "shell.execute_reply.started": "2024-10-19T01:19:21.635671Z",
          "shell.execute_reply": "2024-10-19T01:19:21.646005Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Load Data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "class LocalData:\n    def __init__ (self, clinic_id): #data_range): #data_range will be removed for final code\n        self.clinic_id = clinic_id\n        self.path = f'ilab-07-2/120_dataset/{clinic_id}/'\n        #self.data_range = data_range\n        \n    def dataset (self):\n        transform = transforms.Compose([\n        transforms.Resize((224, 224)),  # Resize images to a fixed size (optional)\n        transforms.ToTensor(),          # Convert images to PyTorch tensors\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225]) \n        ])\n\n# Load the dataset from the train folder\n        train_dataset = datasets.ImageFolder(root=f'{self.path}', transform=transform)\n                  \n        #subset_indices = list(self.data_range)    #remove for final code\n        #train_dataset = Subset (train_dataset, subset_indices) #remove for final code\n                  \n        train_size = int(0.8*len(train_dataset))\n        val_size = len(train_dataset)-train_size\n\n        train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n        return train_subset, val_subset\n    \n    def dataloader(self):  \n        train_subset, val_subset = self.dataset()\n        train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n        val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n\n        print (f'loading {self.clinic_id}')\n        return train_loader, val_loader",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:19:21.651194Z",
          "iopub.execute_input": "2024-10-19T01:19:21.651569Z",
          "iopub.status.idle": "2024-10-19T01:19:21.661722Z",
          "shell.execute_reply.started": "2024-10-19T01:19:21.651534Z",
          "shell.execute_reply": "2024-10-19T01:19:21.660762Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Models",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:19:21.662969Z",
          "iopub.execute_input": "2024-10-19T01:19:21.663436Z",
          "iopub.status.idle": "2024-10-19T01:19:21.675556Z",
          "shell.execute_reply.started": "2024-10-19T01:19:21.663392Z",
          "shell.execute_reply": "2024-10-19T01:19:21.674599Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def resnet18 (weights='DEFAULT'): #James\n    \n    resnet18 = models.resnet18(weights = weights)#.to(device)\n    for param in resnet18.parameters():\n        param.requires_grad = False\n    resnet18.fc = nn.Sequential (\n    nn.Linear(in_features = 512, out_features = 256, bias = True),\n    nn.Dropout(p = 0.5),\n    nn.Linear(in_features = 256, out_features = 1, bias = True),\n    nn.Sigmoid()\n    )\n    \n    for param in resnet18.fc.parameters():\n        param.requires_grad = True\n        \n    resnet18.__class__.__name__ = 'ResNet18'\n    return resnet18",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:19:21.676680Z",
          "iopub.execute_input": "2024-10-19T01:19:21.677003Z",
          "iopub.status.idle": "2024-10-19T01:19:21.686539Z",
          "shell.execute_reply.started": "2024-10-19T01:19:21.676970Z",
          "shell.execute_reply": "2024-10-19T01:19:21.685681Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import torch\nimport torch.nn as nn\nimport torchvision.models as models\n\nclass BasicBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1, drop_out=0.2):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.drop_out = nn.Dropout(drop_out)\n        self.downsample = None\n        if stride != 1 or in_channels != out_channels:\n            self.downsample = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels)\n            )\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.drop_out(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        if self.downsample:\n            out += self.downsample(x)\n        out = self.relu(out)\n        out = self.drop_out(out)\n        return out\n\nclass CustomResNet18(nn.Module):\n    def __init__(self, drop_out=0.2):\n        super(CustomResNet18, self).__init__()\n        self.in_channels = 64\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        \n        # Replace residual blocks with custom BasicBlock including dropout\n        self.layer1 = self._make_layer(BasicBlock, 64, 2, stride=1, drop_out=drop_out)\n        self.layer2 = self._make_layer(BasicBlock, 128, 2, stride=2, drop_out=drop_out)\n        self.layer3 = self._make_layer(BasicBlock, 256, 2, stride=2, drop_out=drop_out)\n        self.layer4 = self._make_layer(BasicBlock, 512, 2, stride=2, drop_out=drop_out)\n        \n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512, 1000)\n        \n\n    def _make_layer(self, block, out_channels, num_blocks, stride, drop_out):\n        strides = [stride] + [1] * (num_blocks - 1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_channels, out_channels, stride, drop_out))\n            self.in_channels = out_channels\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.maxpool(out)\n        \n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        \n        out = self.avgpool(out)\n        out = out.view(out.size(0), -1)\n        out = self.fc(out)\n        return out\n\ndef custom_resnet18(weights='DEFAULT', drop_out=0.2):\n    custom_resnet18 = CustomResNet18(drop_out=0.2)\n    #custom_resnet18.load_state_dict(models.resnet18(weights = weights).state_dict(), strict=False)\n\n# Then freeze parameters\n    #for param in custom_resnet18.parameters():\n    #    param.requires_grad = False\n    \n    custom_resnet18.fc = nn.Sequential (\n    nn.Linear(in_features = 512, out_features =1),\n    nn.Sigmoid()\n    )\n    return custom_resnet18\n\n",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:19:21.687891Z",
          "iopub.execute_input": "2024-10-19T01:19:21.688288Z",
          "iopub.status.idle": "2024-10-19T01:19:21.714031Z",
          "shell.execute_reply.started": "2024-10-19T01:19:21.688241Z",
          "shell.execute_reply": "2024-10-19T01:19:21.712976Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def vgg16(weights = 'DEFAULT'): #David\n    vgg16 = models.vgg16(weights=weights).to(device)\n\n# Freeze the parameters of the base model\n    for param in vgg16.features.parameters():\n        param.requires_grad = False\n\n# Modify the classifier part for binary classification with a varied dropout rate\n    dropout_rate = 0.5  # Typical value used in the original VGG16 paper\n\n    vgg16.classifier = nn.Sequential(\n    nn.Linear(25088, 4096),\n    nn.ReLU(),\n    nn.Dropout(p=dropout_rate),  # Dropout after the first fully connected layer\n    nn.Linear(4096, 2048),\n    nn.ReLU(),\n    nn.Dropout(p=dropout_rate),  # Dropout after the second fully connected layer\n    nn.Linear(2048, 1),\n    nn.Sigmoid()  # Binary classification output\n    )\n    \n    vgg16.__class__.__name__ = 'VGG16'\n    return vgg16\n\n    \ndef vgg19 (weights='DEFAULT'):\n    vgg19 = models.vgg19 (weights=weights).to(device)\n    \n    for param in vgg19.parameters():\n        param.requires_grad = False\n        \n    vgg19.classifier = nn.Sequential (\n        nn.Linear(25088, 512),        \n        nn.ReLU(inplace=True),\n        nn.Dropout(p=0.5),\n        nn.Linear(512, 1),\n        nn.Sigmoid()          \n    )\n    for param in vgg19.classifier.parameters():\n        param.requires_grad = True\n    \n    vgg19.__class__.__name__ = 'VGG19'\n    return vgg19",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:19:21.715560Z",
          "iopub.execute_input": "2024-10-19T01:19:21.716081Z",
          "iopub.status.idle": "2024-10-19T01:19:21.729965Z",
          "shell.execute_reply.started": "2024-10-19T01:19:21.716015Z",
          "shell.execute_reply": "2024-10-19T01:19:21.729234Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Training",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import torch\nimport torch.optim as optim\nimport copy\n\ndef calculate_accuracy(outputs, labels, threshold=0.5):\n    preds = (outputs > threshold).float()\n    correct = (preds == labels).float().sum()\n    accuracy = correct / labels.size(0)\n    return accuracy\n\ndef train_local_model(model, train_loader, val_loader, num_epochs=20, patience=4, delta=0.001):\n    criterion = torch.nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.00001)\n    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n    \n    best_val_loss = float('inf')\n    best_model_wts = copy.deepcopy(model.state_dict())  # Save the initial model weights\n    epochs_no_improve = 0\n    threshold = 0.5\n\n    for epoch in range(num_epochs):\n        # Training phase\n        model.train()\n        running_loss = 0.0\n        running_accuracy = 0.0\n        total_train = 0\n\n        for images, labels in train_loader:\n            optimizer.zero_grad()\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images).squeeze(1).to(device)\n            # Calculate loss\n            loss = criterion(outputs, labels.float())\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n            running_accuracy += calculate_accuracy(outputs, labels, threshold)\n            total_train += 1\n\n        # Validation phase\n        model.eval()\n        val_loss = 0.0\n        val_accuracy = 0.0\n        total_val = 0\n\n        with torch.no_grad():\n            for images, labels in val_loader:\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images).squeeze(1)\n                loss = criterion(outputs, labels.float())\n                val_loss += loss.item()\n                val_accuracy += calculate_accuracy(outputs, labels, threshold)\n                total_val += 1\n\n        avg_val_loss = val_loss / total_val\n        avg_val_accuracy = val_accuracy / total_val\n        print(f\"Epoch {epoch + 1}/{num_epochs}:\\n\"\n              f\"train_loss: {running_loss / total_train:.4f}, train_accuracy: {running_accuracy / total_train:.4f}\\n\"\n              f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {avg_val_accuracy:.4f}\")\n\n        # Step the learning rate scheduler\n        scheduler.step(avg_val_loss)\n\n        # Print the current learning rate\n        for param_group in optimizer.param_groups:\n            print(f\"Learning Rate: {param_group['lr']}\")\n\n        # Check for improvement and save the best model\n        if avg_val_loss < best_val_loss - delta:\n            best_val_loss = avg_val_loss\n            epochs_no_improve = 0\n            best_model_wts = copy.deepcopy(model.state_dict())  # Save best model weights\n        else:\n            epochs_no_improve += 1\n\n        if epochs_no_improve >= patience:\n            print(f\"Early stopping at epoch {epoch + 1}. No improvement in validation loss for {patience} epochs.\")\n            break\n    \n    # Load the best model weights before returning\n    model.load_state_dict(best_model_wts)\n    return model, best_val_loss, avg_val_accuracy\n",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:24:27.626352Z",
          "iopub.execute_input": "2024-10-19T01:24:27.626773Z",
          "iopub.status.idle": "2024-10-19T01:24:27.644075Z",
          "shell.execute_reply.started": "2024-10-19T01:24:27.626733Z",
          "shell.execute_reply": "2024-10-19T01:24:27.642979Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Federated Learning",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "def federated_averaging (client_weights):\n    avg_weights = client_weights[0].copy()\n    \n    for key in avg_weights.keys():\n        for key in avg_weights.keys():\n            for i in range (1, len (client_weights)):\n                avg_weights[key] += client_weights[i][key]\n                \n            avg_weights[key] = avg_weights[key] / len (client_weights)\n            \n    return avg_weights",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:24:28.302330Z",
          "iopub.execute_input": "2024-10-19T01:24:28.302742Z",
          "iopub.status.idle": "2024-10-19T01:24:28.309408Z",
          "shell.execute_reply.started": "2024-10-19T01:24:28.302704Z",
          "shell.execute_reply": "2024-10-19T01:24:28.308368Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def federated_learning (model, num_clients, num_rounds, train_loaders, val_loaders):\n    global_model = model('DEFAULT')\n    global_weights = global_model.state_dict()\n    \n    for round_num in range (num_rounds):\n        print (f'Round {round_num+1}')\n        \n        client_weights = []\n        \n        for client_id in range (num_clients):\n            print (f'client {client_id+1} training...')\n            \n            local_model = model(None)\n            local_model.load_state_dict (global_weights)\n            local_model.to(device)\n            \n            client_train_loader = train_loaders[client_id]\n            client_val_loader = val_loaders[client_id]\n            \n            output_model, _, _ = train_local_model (local_model, client_train_loader, client_val_loader)\n            client_updated_weights = output_model.state_dict()\n            \n            client_weights.append (client_updated_weights)\n            \n        global_weights = federated_averaging (client_weights)\n        \n        global_model.load_state_dict (global_weights)\n    return global_model",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:24:28.437814Z",
          "iopub.execute_input": "2024-10-19T01:24:28.438535Z",
          "iopub.status.idle": "2024-10-19T01:24:28.446526Z",
          "shell.execute_reply.started": "2024-10-19T01:24:28.438491Z",
          "shell.execute_reply": "2024-10-19T01:24:28.445449Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Experimental Setup",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Evaluation",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Setting up dataset for training the FL model\nnum_clients = 4\n\nnum_rounds = 3\n\ntrain_loader_0, val_loader_0 = LocalData('clinic_0').dataloader() #replace range() for testing, and remove when the code is ready for the final run.\n\ntrain_loader_1, val_loader_1 = LocalData('clinic_1').dataloader() #replace range() for testing, and remove when the code is ready for the final run.\n\ntrain_loader_2, val_loader_2 = LocalData('clinic_2').dataloader() #replace range() for testing, and remove when the code is ready for the final run.\n\ntrain_loader_3, val_loader_3 = LocalData('clinic_3').dataloader() #replace range() for testing, and remove when the code is ready for the final run.\n\ntrain_loaders = [train_loader_0, train_loader_1, train_loader_2, train_loader_3]\nval_loaders = [val_loader_0, val_loader_1, val_loader_2, val_loader_3]",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:24:29.175771Z",
          "iopub.execute_input": "2024-10-19T01:24:29.176697Z",
          "iopub.status.idle": "2024-10-19T01:24:29.187715Z",
          "shell.execute_reply.started": "2024-10-19T01:24:29.176641Z",
          "shell.execute_reply": "2024-10-19T01:24:29.186685Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Metrics\ndef metrics (ground_truths, predictions):\n    accuracy = accuracy_score(ground_truths, predictions).round(4)\n    precision = precision_score (ground_truths, predictions).round(4)\n    recall = recall_score (ground_truths, predictions).round(4)\n    f1 = f1_score (ground_truths, predictions).round(4)\n    confusion_ma = confusion_matrix (ground_truths, predictions)\n    \n    print ('Accuracy score: ', accuracy)\n    print ('Precision score: ', precision)\n    print ('Recall score: ', recall)\n    print ('F1 score: ', f1)\n    print ('Confusion Matrix: \\n', confusion_ma)\n    return accuracy, precision, recall, f1\n    ",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:24:29.452978Z",
          "iopub.execute_input": "2024-10-19T01:24:29.453902Z",
          "iopub.status.idle": "2024-10-19T01:24:29.460619Z",
          "shell.execute_reply.started": "2024-10-19T01:24:29.453858Z",
          "shell.execute_reply": "2024-10-19T01:24:29.459579Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#ROC Curve\ndef roc(ground_truths, output_probs):\n    fpr, tpr, _ = roc_curve (ground_truths, output_probs)\n    auc_score = roc_auc_score (ground_truths, output_probs)\n    return fpr, tpr, auc_score",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:24:29.995813Z",
          "iopub.execute_input": "2024-10-19T01:24:29.996777Z",
          "iopub.status.idle": "2024-10-19T01:24:30.001729Z",
          "shell.execute_reply.started": "2024-10-19T01:24:29.996733Z",
          "shell.execute_reply": "2024-10-19T01:24:30.000569Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#Train client model on clinic4's train_loader\n#Make prediction on clinic4's val_loader\ndef evaluation(client_model, val_loader):\n    client_model.eval()\n    predictions = []\n    ground_truths = []\n    output_probs = []\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            output = client_model(images)\n            output_probs.append (output.cpu())\n            output = output.round()\n            predictions.append (output.cpu())\n            ground_truths.append (labels.cpu())\n    predictions = np.concatenate (predictions).reshape(-1).astype ('int')\n    ground_truths = np.concatenate (ground_truths)\n    output_probs = np.concatenate(output_probs)\n    \n    return metrics (ground_truths, predictions), roc(ground_truths, output_probs)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:24:31.059083Z",
          "iopub.execute_input": "2024-10-19T01:24:31.059510Z",
          "iopub.status.idle": "2024-10-19T01:24:31.067443Z",
          "shell.execute_reply.started": "2024-10-19T01:24:31.059471Z",
          "shell.execute_reply": "2024-10-19T01:24:31.066390Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#set of models we are using - ResNet18, CustomResnet18, VGG16, VGG19\nclient_models = [resnet18]",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:24:31.875779Z",
          "iopub.execute_input": "2024-10-19T01:24:31.876656Z",
          "iopub.status.idle": "2024-10-19T01:24:31.880988Z",
          "shell.execute_reply.started": "2024-10-19T01:24:31.876610Z",
          "shell.execute_reply": "2024-10-19T01:24:31.880003Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### 1. Evaluation on the held-out clinic\nAfter several rounds of training, the global model's weights are now used as initiallized weights for a fresh client model. Then, we will use this model to make prediction on the eval dataset on the 5th clinic's data.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Setting up dataset for evaluation on clinic 5\ntrain_loader_clinic5, val_loader_clinic5 = LocalData ('clinic_4').dataloader()",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:24:33.130263Z",
          "iopub.execute_input": "2024-10-19T01:24:33.131214Z",
          "iopub.status.idle": "2024-10-19T01:24:33.138458Z",
          "shell.execute_reply.started": "2024-10-19T01:24:33.131172Z",
          "shell.execute_reply": "2024-10-19T01:24:33.137258Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "results_1 = []\nauc_results_1 = dict()",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:24:33.140757Z",
          "iopub.execute_input": "2024-10-19T01:24:33.141174Z",
          "iopub.status.idle": "2024-10-19T01:24:33.146488Z",
          "shell.execute_reply.started": "2024-10-19T01:24:33.141134Z",
          "shell.execute_reply": "2024-10-19T01:24:33.145413Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "for client_model in client_models:\n    model_name = client_model().__class__.__name__\n    client_model = train_local_model (client_model('DEFAULT').to(device), train_loader_clinic5, val_loader_clinic5)[0]\n    eval_output = evaluation(client_model, val_loader_clinic5)\n    accuracy, precision, recall, f1 = eval_output[0]\n    fpr, tpr, auc_score = eval_output[1]\n    results_1.append ([model_name, accuracy, precision, recall, f1])\n    auc_results_1[model_name] = {\n                'fpr' : fpr,\n                'tpr' : tpr,\n                'auc_score' : auc_score\n        }",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:24:33.147696Z",
          "iopub.execute_input": "2024-10-19T01:24:33.148048Z",
          "iopub.status.idle": "2024-10-19T01:24:46.680529Z",
          "shell.execute_reply.started": "2024-10-19T01:24:33.147988Z",
          "shell.execute_reply": "2024-10-19T01:24:46.679406Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "global_models = []\nfor client_model in client_models:\n    model_name = f'FedAVG {client_model().__class__.__name__}'\n    print (model_name)\n    global_model = federated_learning (client_model, num_clients, num_rounds, train_loaders, val_loaders) #change num_rounds according to your GPU, which mine doesn't have one :<.\n    model = train_local_model (global_model.to(device), train_loader_clinic5, val_loader_clinic5)[0]\n    eval_output = evaluation(model, val_loader_clinic5)\n    accuracy, precision, recall, f1 = eval_output[0]\n    fpr, tpr, auc_score = eval_output[1]\n    results_1.append ([model_name, accuracy, precision, recall, f1])\n    auc_results_1[model_name] = {\n                'fpr' : fpr,\n                'tpr' : tpr,\n                'auc_score' : auc_score\n        }\n    global_models.append (global_model)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:24:46.682971Z",
          "iopub.execute_input": "2024-10-19T01:24:46.683562Z",
          "iopub.status.idle": "2024-10-19T01:26:18.786908Z",
          "shell.execute_reply.started": "2024-10-19T01:24:46.683507Z",
          "shell.execute_reply": "2024-10-19T01:26:18.785804Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df_eval = pd.DataFrame (columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1'],\n                       data = results_1)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:26:18.788866Z",
          "iopub.execute_input": "2024-10-19T01:26:18.789237Z",
          "iopub.status.idle": "2024-10-19T01:26:18.795648Z",
          "shell.execute_reply.started": "2024-10-19T01:26:18.789197Z",
          "shell.execute_reply": "2024-10-19T01:26:18.794623Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df_eval",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:26:18.796739Z",
          "iopub.execute_input": "2024-10-19T01:26:18.797148Z",
          "iopub.status.idle": "2024-10-19T01:26:18.818676Z",
          "shell.execute_reply.started": "2024-10-19T01:26:18.797106Z",
          "shell.execute_reply": "2024-10-19T01:26:18.817532Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "auc_results_1",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:26:18.821694Z",
          "iopub.execute_input": "2024-10-19T01:26:18.822121Z",
          "iopub.status.idle": "2024-10-19T01:26:18.835372Z",
          "shell.execute_reply.started": "2024-10-19T01:26:18.822079Z",
          "shell.execute_reply": "2024-10-19T01:26:18.834281Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "plt.figure()\nfor key in auc_results_1.keys():\n    plt.plot (auc_results_1[key]['fpr'],\n              auc_results_1[key]['tpr'], \n              label = f\"{key} : {auc_results_1[key]['auc_score']:.3f}\")\n\nplt.legend(\n    loc='center left',              # Place the legend outside the plot\n    bbox_to_anchor=(1, 0.5),        # Position it to the right of the plot\n    fancybox=True,                  # Fancy box for aesthetics\n    shadow=True,                    # Add shadow for visual clarity\n    ncol=1,                         # Single column\n    frameon=True,                   # Frame around the legend\n    borderpad=1,                    # Padding around the border\n    handletextpad=1.5,              # Padding between legend key and label\n    prop={'size': 10},              # Font size\n    labelspacing=1,                 # Space between labels in the legend\n)\n\n# Add the grey diagonal line for reference\nplt.plot([0, 1], [0, 1], color='grey', lw=1, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\n\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\n\n# Adjust the legend location and align text to the right\nplt.legend(\n    loc='center left',              # Place the legend outside the plot\n    bbox_to_anchor=(1, 0.5),        # Position it to the right of the plot\n    fancybox=True,                  # Fancy box for aesthetics\n    shadow=True,                    # Add shadow for visual clarity\n    ncol=1,                         # Single column\n    frameon=True,                   # Frame around the legend\n    borderpad=1,                    # Padding around the border\n    handletextpad=1.5,              # Padding between legend key and label\n    prop={'size': 10},              # Font size\n    labelspacing=1,                 # Space between labels in the legend\n)\n\n# Modify alignment for text inside the legend (right-align)\nfor text in plt.gca().get_legend().get_texts():\n    text.set_ha('right')  # Align the legend text to the right\n\n# Show the plot\nplt.show()\n",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:26:18.837532Z",
          "iopub.execute_input": "2024-10-19T01:26:18.838098Z",
          "iopub.status.idle": "2024-10-19T01:26:19.166642Z",
          "shell.execute_reply.started": "2024-10-19T01:26:18.838044Z",
          "shell.execute_reply": "2024-10-19T01:26:19.165650Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#### 2. Evaluation on each client's validation data",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "results_2 = []\nauc_results_2 = dict()",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:20:36.717578Z",
          "iopub.status.idle": "2024-10-19T01:20:36.717945Z",
          "shell.execute_reply.started": "2024-10-19T01:20:36.717760Z",
          "shell.execute_reply": "2024-10-19T01:20:36.717780Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "for client_model in client_models:\n    model_name = client_model().__class__.__name__\n    auc_results_2[model_name] = dict()\n    for i in range (4):\n        local_model = train_local_model (client_model('DEFAULT').to(device), train_loaders[i], val_loaders[i])[0]\n        eval_model = evaluation (local_model, val_loaders[i])\n        accuracy, precision, recall, f1 = eval_model[0]\n        fpr, tpr, auc_score = eval_model[1]\n        results_2.append ([model_name, f'Clinic_{i}', accuracy, precision, recall, f1])\n        auc_results_2[model_name][f'Clinic_{i}'] = {\n            'fpr' : fpr,\n            'tpr' : tpr,\n            'auc_score' : auc_score\n        }",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:20:36.719454Z",
          "iopub.status.idle": "2024-10-19T01:20:36.719821Z",
          "shell.execute_reply.started": "2024-10-19T01:20:36.719635Z",
          "shell.execute_reply": "2024-10-19T01:20:36.719654Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "for client_model, global_model in zip(client_models, global_models):\n    #global_model = federated_learning (client_model, num_clients, 2, train_loaders, val_loaders) #change num_rounds according to your GPU, which mine doesn't have one :<.\n    model_name = f'FedAVG {client_model().__class__.__name__}'\n    auc_results_2[model_name] = dict()\n    for i in range (4):\n        print (model_name)\n        model = train_local_model (global_model.to(device), train_loaders[i], val_loaders[i])[0]\n        eval_model = evaluation(model, val_loaders[i])\n        accuracy, precision, recall, f1 = eval_model[0]\n        #results_2.append ([model_name, f'Clinic_{i}', accuracy, precision, recall, f1])\n        \n        fpr, tpr, auc_score = eval_model[1]\n        results_2.append ([model_name, f'Clinic_{i}', accuracy, precision, recall, f1])\n        auc_results_2[model_name][f'Clinic_{i}'] = {\n            'fpr' : fpr,\n            'tpr' : tpr,\n            'auc_score' : auc_score\n        }",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:20:36.720854Z",
          "iopub.status.idle": "2024-10-19T01:20:36.721235Z",
          "shell.execute_reply.started": "2024-10-19T01:20:36.721037Z",
          "shell.execute_reply": "2024-10-19T01:20:36.721065Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df_eval_2 = pd.DataFrame (columns = ['Model', 'Clinic', 'Accuracy', 'Precision', 'Recall', 'F1'],\n                         data = results_2)",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:20:36.723993Z",
          "iopub.status.idle": "2024-10-19T01:20:36.724399Z",
          "shell.execute_reply.started": "2024-10-19T01:20:36.724212Z",
          "shell.execute_reply": "2024-10-19T01:20:36.724231Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "plt.figure()\nfor model in auc_results_2:\n    for clinic in auc_results_2[model]:\n        plt.plot(\n            auc_results_2[model][clinic]['fpr'], \n            auc_results_2[model][clinic]['tpr'], \n            label=f\"{model} - {clinic} : {auc_results_2[model][clinic]['auc_score']:.3f}\"\n        )\n\n# Add the grey diagonal line for reference\nplt.plot([0, 1], [0, 1], color='grey', lw=1, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\n\n# Set plot labels and title\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\n\n# Adjust the legend location and align text to the right\nplt.legend(\n    loc='center left',              # Place the legend outside the plot\n    bbox_to_anchor=(1, 0.5),        # Position it to the right of the plot\n    fancybox=True,                  # Fancy box for aesthetics\n    shadow=True,                    # Add shadow for visual clarity\n    ncol=1,                         # Single column\n    frameon=True,                   # Frame around the legend\n    borderpad=1,                    # Padding around the border\n    handletextpad=1.5,              # Padding between legend key and label\n    prop={'size': 10},              # Font size\n    labelspacing=1,                 # Space between labels in the legend\n)\n\n# Modify alignment for text inside the legend (right-align)\nfor text in plt.gca().get_legend().get_texts():\n    text.set_ha('right')  # Align the legend text to the right\n\n# Show the plot\nplt.show()\n",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:20:36.725627Z",
          "iopub.status.idle": "2024-10-19T01:20:36.725980Z",
          "shell.execute_reply.started": "2024-10-19T01:20:36.725800Z",
          "shell.execute_reply": "2024-10-19T01:20:36.725818Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "df_eval_2",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:20:36.727167Z",
          "iopub.status.idle": "2024-10-19T01:20:36.727504Z",
          "shell.execute_reply.started": "2024-10-19T01:20:36.727334Z",
          "shell.execute_reply": "2024-10-19T01:20:36.727352Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "auc_results_2",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:20:36.728952Z",
          "iopub.status.idle": "2024-10-19T01:20:36.729317Z",
          "shell.execute_reply.started": "2024-10-19T01:20:36.729144Z",
          "shell.execute_reply": "2024-10-19T01:20:36.729163Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "!python --version",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:20:36.730503Z",
          "iopub.status.idle": "2024-10-19T01:20:36.730870Z",
          "shell.execute_reply.started": "2024-10-19T01:20:36.730692Z",
          "shell.execute_reply": "2024-10-19T01:20:36.730711Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "!conda install python==3.10.12",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-19T01:20:36.731928Z",
          "iopub.status.idle": "2024-10-19T01:20:36.732334Z",
          "shell.execute_reply.started": "2024-10-19T01:20:36.732150Z",
          "shell.execute_reply": "2024-10-19T01:20:36.732170Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}
Version History
Version 9
Save & Run All â€¢ Diff: +38 -13
Cancelled after 10 hours and 1 minute
11h ago
Version 8
Save & Run All â€¢ Diff: +0 -0
Cancelled after 12 hours
2d ago
Version 7
Save & Run All â€¢ Diff: +182 -27
Cancelled after 3 seconds
2d ago
Version 6
Save & Run All â€¢ GitHub â€¢ Diff: +1 -1
Ran in 2 hours and 10 minutes
6d ago

Version 5
Save & Run All â€¢ Diff: +0 -2
Failed after 1 minute and 1 second
6d ago

Version 4
Save & Run All â€¢ Diff: +29 -14
Failed after 1 minute
6d ago
Version3
Save & Run All â€¢ GitHub â€¢ Diff: +19 -12
Ran in 8 hours and 54 minutes
10d ago

Evaluation1
Save & Run All â€¢ Diff: +1 -5
Failed after 7 hours and 19 minutes
11d ago
Version1
Save & Run All â€¢ Diff: +433 -0
Cancelled after 7 seconds
11d ago
Skip to
content
Kaggle

Create
Home

Competitions

Datasets

Models

Code

Discussions

Learn

More


1
View Active Events

Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.
Learn more.
OK, Got it.
FLeval


File
Edit
View
Run
Settings
Add-ons
Help

Share

Save Version

9






Cancel Run

Code

Draft Session
(7m)
HDD
CPU
RAM
GPU

Notebook
Input

Add Input

Upload

No input attached
Attach a Kaggle dataset, model, or competition

Output (5.7GiB / 19.5GiB)
/kaggle/working

Table of contents
Session options
GPU P100
Accelerator
Quota:11:19 / 30 hrs

Python
Language
No persistence
Persistence
[object Object]
Environment
Always get the latest package versions, but you may have to modify your code. What is a notebook environment?

Internet
Internet on
Tags
GPU
GitHub
Profile picture for undefined
Repository
/data-davey/ilab-07-2

Branch
finn

File
CustomResnet18_Finn.ipynb

Last Push
-

Last Pull
-


Push

Pull
Schedule a notebook to run
Schedule this notebook to run and save a new version on a future date. View all your scheduled notebooks.

Select
Trigger

Save
Code Help

Session started.